СПЕЦИФИКАЦИЯ LiME. Версия 0.dev (в разработке).

									    ЦЕЛЬ

Сделать систему трансляции, которая давала бы программисту несколько
инструментов, которые, как показывает практика современного программирования,
востребованы и позволяют повысить производительность труда:

	- система типов с автоматическим выводом (возможно, в некоторой
	  ограниченной форме);

	- средства определения пользовательские конструкции для управления
	  потоком вычисления, создавать собственные реализации for/if/switch;

	- замыкания, как более гибкую в сравнении с ООП систему декомпозиции и
	  композиции кода (тут можно сослаться на опыт Go);

	- специализацию кода во время исполнения, что, как известно ('C:
	  http://pdos.csail.mit.edu/papers/tickc-poletto-phd.pdf) существенно
	  повышает эффективность программ;

	- императивную семантику, которая предоставляет программисту большую
	  гибкость в построении различных систем событий;

	- модель исполнения ориентированную на процессы, а не на потоки;
	  процессы (в том числе и программно-изолированные) удобнее и
	  эффективнее в задачах управления ресурсами по сравнению с нитями, и не
	  уступают последним в эффективности при выполнении многозадачных
	  вычислений;

	- средства статического анализа кода и верификации;

	- оптимизирующий компилятор, позволяющий разрабатывать
	  высокопроизводительные приложения для супер-компьютеров;

	- основные алгоритмы системы должны быть достаточно простыми для
	  быстрого их переноса на различные платформы, в том числе, с небольшим
	  объёмом оперативной памяти (cкажем, 256KiB).

В той или иной степени некоторые из этих инструментов реализованы в различных
системах программирования, однако все они не собраны ни в одной. Поэтому
возникает идея разработать подобную систему трансляции.

Побочным эффектом при её реализации должна стать возможность достаточно простой
организации frontend-ов некоторых традиционных языков программирования (C99,
Fortran, etc) поверх системы LiME. Определение базовых типов и конструкций для
описания потока управления на уровне пользователя должны свести задачу
построения таких frontend-ов к созданию:

	- кода, переводящего исходный текст программы в исходный текст на LiME,
	  возможно, в несколько оптимизированной форме, сходной с той, что сам
	  LiME (LiME is Metaprogramming Engine, поэтому сам) генерирует на этапе
	  лексического анализа;

	- реализаций тех или иных операторов, если они ещё не реализованы, в
	  рамках семантического движка LiME.

Примерно так.

								  СТРУКТУРА LiME

Здесь описан текущий высокоуровневый взгляд на систему.

LiME состоит из нескольких компонент, каждая из которых внутри между своими
составными частями имеет обратные связи (глупые обозначения английскими буквами
нужны для удобства ссылок, если понадобятся).

	- LX: лексический анализатор с вполне классической структурой, с
	  небольшими отличиями (если не считать ключевые слова) от лексики Си;
	  лексический анализатор передаёт на синтаксическую стадию анализа поток
	  лексем вида («:» - условный разделить, главное, что речь о тройках):

	  	тип лексемы : значение : позиция в тексте;
	
	  под «типом лексемы» понимается:

	  	- идентификатор,
		- константа,
		- одна из групп операторов;
	  
	- SX: синтаксический анализатор простых операторных выражений, для
	  которого тоже достаточно простых алгоритмов; решётка приоритетов
	  операторов похожа на используемую в Go (в Си она слишком большая,
	  часто приходится вспоминать, но это нам не помешает);

	  неклассическая особенность: синтаксический анализатор может
	  «придумывать» некоторые операторы по фиксированной схеме;
	  синтаксический анализатор передаёт в семантический анализатор

	  список «команд» вида: 

		новый номер выражения = атом;

	  	новый номер выражения = унарный оператор : номер подвыражения;

		новый номер левого «вектора»
			= номер левого подвыражения
			: бинарный оператор

		новый номер выражения
			= номер левого «вектора»
			: номер правого подвыражения
		
	  «=» и «:» - это малозначимое форматирование; такой интерфейс не совсем
	  традиционный, но тут всё строго;

	  такие нетрадиционности необходимы, чтобы в LiME можно было
	  программировать, например, такие конструкции (в ней нет ключевых
	  слов и встроенных операторов):

	  	for(var (x.1; x.2) = range2d(0:N-1; 0:M-1))
		(
			sum += field(x.1; x.2)
		)

	  frontend-ы других языков программирования могут взаимодействовать со
	  следующей, основной частью всей системы через генерацию такого вида
	  «команд»;

	- SE: семантический «движок» - основная часть системы, которая на основе
	  команд, описывающих связи выражений с операторами строит промежуточное
	  представление программы, пригодное для генерации кода;
	
	  пока такое промежуточное представление предполагается делать в виде
	  кода из тетрад (в основном), то есть, элементов вида:

	  	код операции «метка» =
			«ссылка на аргумент 1», «ссылка на аргумент 2»

	  это текстовое представление, доступное программисту, поэтому
	  желательно, чтобы оно было таким; метки удобны для программиста,
	  а этот формат удобно разбирать; двоичное представление
	  последовательности таких выражений, конечно, триадное; пример:

	  	a = x + y | z
		
		addr	pa = a;		// идея разделения получения адреса
		addr	px = x;		// значения, его загрузки и собственно
		addr	py = y;		// вычисления взята из LCC; это
		addr	pz = z;		// позволяет упростить кодировку
		ld.u8	vx = px;	// операции (or, add работают только со
		ld.u8	vy = py;	// значениями; addr - с символами;
		ld.u8	vz = pz;	// ld - c адресами; можно проверять
	  	or.u8	t1 = y, z;	// корректность); опыт работы с LCC
		add.u8	t2 = x, t;	// позволяет сказать, что в одну
		st.u8	pa = t2;	// инструкцию всё это свернуть просто
	  
	  задача SE брать такие участки кода, которые в процессе трансляции он
	  же связывает с подвыражениями и, руководствуясь специальными
	  таблицами, используя информацию о типах подвыражений и операторе
	  выводить тип составного выражения и соответствующий ему участок кода;

	  в коде могут быть специальные директивы для самого SE, которые он
	  должен выполнять; например, директивы для введения новых переменных
	  или типов;

	  	.var	a = unsignedlonglong;
	  
	  выполнение этой директивы должно сделать запись о символе a с
	  соответствующим типом в специальных таблицах SE;

	  такое представление программы, в котором большинство конструкций
	  проинтерпретировано должно передаваться дальше; набор необходимых
	  директив нужно обсуждать;

Дальнейшие участки проработаны не так хорошо. Какой-то код сгенерировать
возможно пользуясь опытом, полученным от LCC, так как далеко отходить от
традиционной структуры промежуточного представления не планируется. Но как
сгенерировать более оптимальный код - это вопрос будущего.

	- CHK: где-то здесь должна быть система верификации, которая получает
	  достаточно информации от SE, чтобы выполнить определённые проверки
	  кода; хотя бы на выходы за границы; возможно, эта часть должна быть
	  тесно связана с семантикой, но на сегодняшний день представляется, что
	  информации о размерах типов может быть достаточно для решения проблемы
	  контроля выходов за границы памяти; это место тоже надо обсуждать;

	- OPT: оптимизатор, получающий от FE представление программы в
	  промежуточном виде, в котором нет управляющих директив для
	  семантического движка; например, информации о взаимосвязи типов;
	  предполагается, что оптимизатор не нуждается в информации о том,
	  например, что некая структура данных была выведена из выражения

	  	array(20) list hash(string) int.2 
	  
	  вопрос, одако в том, какие знания о программе необходимы для успешной
	  оптимизации; достаточно ли знать только представление в виде потока
	  данных, из которого можно вывести всё остальное?

	  представляется, что оптимизатору не требуется обратная связь с
	  фасадом;

	- CG: генератор кода для целевой машины; должен получать от FE некоторое
	  описание программы, и генерировать по нему ассемблерный код.

Представляется, что во время runtime-специализации кода его семантика не должна
меняться. То есть, например, в функции вычисления, допустим, факториала целые
числа не должны неожиданно превратится в вещественные.

Хотя, может быть, именно такое поведение и требуется программистам: много раз
приходилось слышать, что eval - это очень хорошо. Это тоже открытый вопрос на
данный момент.

Эти сомнения не влияют на особенности реализации C99 поверх LiME. Это всё более
продвинутые алгоритмы на будущее.

Итак. Теперь к каждой части подробнее. Нужно понимать, что изложенное ниже не
является окончательной версией спецификации. Просто в ходе научных (это следует
подчеркнуть, наука в данном случае - поиск нового) исследований была получена
такая конструкция. Многое может быть изменено в сторону усложнения или
упрощения.

						 ЛЕКСИЧЕСКИЙ АНАЛИЗАТОР (СКАНЕР)

1. Входной алфавит.

Конечно, LX должен поддерживать строковые константы. Строковые константы
интерпретируются как цепочки байтов определённой длинны. Они могут быть
дополнены нулём во время семантического анализа для нужно компилятора Си99, но
на уровне сканера они представляются как массивы байтов определённой длинны.

Внутри строк могут встречаться любые символы (цепочки байтов).
Последовательности байтов могут задаваться и через привычные
escape-последовательности: «\t», «\r», «\n», и т.д. Кроме этого, предлагается
задавать цепочки байтов произвольной длины последовательностью «\x([0-0a-f]+)».
Например:

	uint(40) shasum = '\x(f444e5be3f26f57c4fcfa7d32a0379adf70c9473)'

Лексический анализатор поддерживает однострочные комментарии, начинающиеся
последовательностью «//». В комментарии может встречаться любая
последовательность байтов.

Вне строк и комментариев допустимыми символами считаются лишь следующие из
набора ASCII:

	- TAB - LF 	09 - 0A
	- « » - ! 	20 - 21
	- ' - +		25 - 2B
	- «-» - >	2D - 3E
	- A - Z		41 - 5A
	- ^		5E
	- a - z		61 - 7A
	- |		7C

Некоторых привычных символов здесь нет, можно считать их зарезервированными для
будущих версий, если вдруг понадобятся.

Сканер выделяет в последовательности символов несколько типов лексем:

	- атомы-символы (примитивные идентификаторы): последовательности
	  латинских букв и цифр [a-zA-Z0-9]+; атомы сравниваются с учётом
	  регистра; хотя гуру языков программирования аргументируют за
	  нечувствительность к регистру, практика показывает, что X и x лучше
	  трактовать как разные символы, особенно в вычислительных программах;
	  традиционное _ не включено в алфавит символов, потому что в
	  LiME предусматриваются другие способы давать сложные идентификаторы
	  переменным; например, для описания символов в C99 или во внешних
	  библиотеках можно использовать нечто вроде:

	  	id.'classic_c_symbol_with_a_lot_of_underscores'
		id.cpp.'SomeClass::overloadedMethod(int, ClassY, float)'

	- атомы-константы: строки и целые числа в записи по основаниям 10 и 16;
	  числа передаются лексическим анализатором на другие уровни трансляции
	  в формате длинных чисел без потери разрядов; 

	- операторы различного приоритета; один приоритет - один тип лексемы:

		0 ;
		1 = *= /= %= >>= <<= &= += -= |= ^= ||= &&=
		2 ->
		3 «:»
		4 ||
		5 &&
		6 == != < <= > >=
		7 + - | ^
		8 * / % << >> &
		9
		a !
		b . 
	
	- скобки: ()

1. Немного нетрадиционно обрабатываются вещественные константы. Предполагается
сделать их составными и выводить уже на этапе семантического анализа. Возможно,
не самый лучший дизайн, но константы записываются в коде программы редко, можно
необычность в виде:

	0.6 E(3) * 3.1415 // == 1884.9

и потерпеть. Это сделано для обеспечения двух возможностей. Первая - возможность
давать переменным структурированные имена:

	var (x.1 = 21.3; x.2 = 4; x.4.5 = 3.1415; x.2.alpha = 'alpha');

А потом работать с группами этих переменных. Это часто бывает необходимо в
циклах, когда что-нибудь такое приходится писать:

	x_0 = x_1;
	x_1 = x_2;
	x_2 = next(x_0; x_1; x_2);

В LiME поэтому хочется предусмотреть возможность записи:

	x.(0; 1; 2) = (x.(1; 2); next(x));

Но для этого, чтобы не усложнять семантику и не отказываться от однозначности,
необходимо на общих основаниях воспринимать записи вида:

	12345.6789

деревьями вида

	(. 12345 6789)

Из такой конструкции можно вывести вещественное значение.

Другая составляющая мотивации всегда трактовать точку всегда как оператор и
иметь возможность описывать конструкции вида x.1 коренится в желании обеспечить
программисту конструирование сложных объектов в стиле командной строки UNIX.
Здесь тонкость в том, что конструируется многопараметрический объект, который
громоздко было бы описывать со множеством знаков приминания, при том, что
описание в виде командной строки в виде списка ограниченного набора конструкций
может быть достаточно мощным и адекватным.

Для такого конструирования необходимо без дополнительной (относительно)
пунктуации задавать конструкции, состоящие из основной команды, флагов и пар
(ключ; значение). Например, задающая определённый способ воспроизведения видео
конструкция

	screen -S mp mplayer ~/Downloads/87* \
		-vf crop=280:210,scale=320:240 -ao null -osdlevel 0 \
		-display :32.1 -fixed-vo -loop 0 

в условиях, когда «.» всегда оператор может быть записана с учётом доступных в
LiME синтаксиса и семантики так:

	screen S.mp mplayer '~/Downloads.87*'
		vf(crop(280:210) scale(320:240)) ao.null
		osdlevel.0 display.32.1 vo.fixed loop.0 

Не идеально, но менее громоздко, чем даже вариант с именоваными параметрами для
функций/конструкторов/подобных вещей:

	screen(S = mp; mplayer('~/Downloads.87*';
		vf = (crop(280:210) scale(320:240); ao = null; osdlevel = 0;
		display = '32.1'; vo = fixed; loop = 0))

Возможно, такая обработки «.» плохая идея, но:

	- это никак не повлияет на поведение frontend для C99, который сразу
	  может выдавать значения с привязанным к ним типом, описывающим
	  константы более точно; естественно LiME должен понимать отличия целых
	  чисел от вещественных, и такой механизм возможен;

	- никто не пробовал так делать в языках прогрммирования, поэтому,
	  ответить на вопрос, насколько идея удачна и насколько плоха, сложно, в
	  ней есть недостатки, но и достоинства кроме упомянутых выше; например,
	  можно формировать ip-адреса без дополнительного синтаксиса:

	  	87.224.213.1
	  
	  такие конструкции могут быть однозначно проинтерпретированы в LiME;

	- в Perl не такой же, но похожий механизм есть; Perl спорный, но тем не
	  менее, широко распространённый язык.

Прежде тут был такой пример:

	val x = sin(pi/2);
	val y = cos(pi/6);

	val R matrix = (
		0	-12.4	18.9	11;
		11	-12.5	6	10;
		(x+y)	exp(x)	y	0.1
	);

С упрощением подхода придётся писать так:

	var R matrix =
	(
		(0;	-12.4;	18.9;	11);
		(11;	-12.5;	6;	10);
		(x+y;	exp(x);	y;	0.1)
	)


2. Предполагается различать атомы нестрогим способом. Для синтаксического
анализа, основанного на операторной грамматике, отличать (условно)
идентификаторы от констант не нужно. А семантическому анализатору достаточно
иметь подсказку о том, какой вид имеет атом. Например, если лексический
анализатор подскажет семантическому, что 12345 - последовательность
десятичных цифр, то такая

	var 12345 unsigned int = 20;

конструкция может быть отброшена на этапе семантического анализа с сообщением о
том, что 12345 неподходящий вид атома для идентификатора. Такой подход позволяет
выражать и более сложные константы относительно экономным способом. Например,
ipv6 адреса:

	ping fc00.bad.c0de.0(fill).1

Эта предлагаемая особенность тоже не особо проверенная временем, поэтому выводы
о верности решения можно сделать только после определённой практики, но можно
сказать, что нечто похожее есть в языках для оболочек операционных систем. Когда
записано:

	wget -r --tries=10 http://fly.srk.fer.hr/ -o log

То все выражения получают свой смысл лишь в контексте исполнения wget, оставаясь
до передачи в wget просто строками. В LiME это может быть записано с примерно
той же семантикой в виде:

	wget r tries.10 'http://fly.srk.fer.hr/' o.log

3. IO

На вход сканер получает поток байтов, на выходе генерирует поток команд. В
первых, экспериментальных, версиях системы предлагается пожертвовать скоростью
трансляции в пользу удобства отладки и минимизации доменов ошибок. Поэтому
сканер предлагается сделать отдельным процессом, который передаёт
синтаксическому анализатору команды в виде конструкций (подобраны так, чтобы их
можно было легко читать при помощи scanf):

	строка позиция : описание

Строка и позиция - это координаты лексемы в тексте. Описание может быть двух
видов.

	E.номер | (N.«новый номер» спецификация)

«E» ссылается на уже записанную в таблицу лексем лексему. В записи должны быть
сохранены все параметры для дальнейшей обработки.

«N» должна задавать новую запись в таблице, номер должен быть ранее не
использованным. Тут возможен перекрёстный контроль корректности с проверкой на
стороне потребителя.

Спецификация лексемы должна иметь структуру вида:

	тип уточнение

тип - это число, задающее вид лексемы, для операторов - это класс приоритета (0
до 11), отдельные типы нужно назначить скобкам и атомам. В зависимости от типа,
уточнение может быть разным:

	- для операторов, это дополнительное число, задающее конкретный оператор
	  в свойм классе (от 0 до 12);

	- для скобок и «;» уточнения не требуются; можно потребовать
	  обязательное равенство числу ноль этого поля.

Можно потребовать (для большей читаемости), чтобы в этих случаях сканер
дописывал само обозначение оператора.

	- Для атомов уточнение должно строится так:

		«тип атома».«длина в байтах».«сами байты»

Тип атома задаётся битовой строкой, где каждый бит означает (биты записаны
числами):

	1 - атом может быть строкой
	2 - атом может быть десятичным числом
	4 - атом может быть шестнадцатеричным числом
	8 - атом является строкой

Кажется, обо всех тонкостях сканера сказано.

					      СИНТАКСИЧЕСКИЙ АНАЛИЗАТОР (ПАРСЕР)

В принципе, можно было бы задать синтаксис LiME любой из LL(1), LR(1), LALR(1)
грамматикой, выписать BNF-нотацию и сказать, что вот оно. Но в таком случае
разбор бы зависел от относительно (хотя алгоритмы известны и просты) от
дополнительных программных средств (генераторов парсеров) или от проверки
соответствия реализации данной грамматике, а инструментов такой проверки,
гарантирующих 100% корректность пока не существует. Кроме того, BNF не даст
представления о том, зачем введены те или иные правила.

Поэтому грамматика описывается более «литературно» и алгоритмически, с
пояснениями, зачем вводится тот или иной элемент.

Парсер LiME является синтаксическим анализатором операторной грамматики

	http://en.wikipedia.org/wiki/Operator-precedence_grammar

работающий по стандартному алгоритму разбора со стеком выражения, связанного
бинарными операторами. Это очень простой и эффективный алгоритм, однако,
оригинальный его вариант не позволяет строить достаточно выразительные
конструкции. Поэтому в LiME применяется его модификация:

	- в некоторых случаях парсер воспринимает операторы «-», «+», «^» (для
	  побитового not), «.» как префиксные унарные;

	- в некоторых случаях парсер вставляет в поток лексем вспомогательные
	  лексемы, трактующиеся как бинарные операторы: s-apply и p-apply;

	- парсер замечает то, что называется (за неимением лучшего термина)
	  «левым синтаксическим вектором» (ls-вектором) - это пара из указателя
	  на левое подвыражение при обработке бинарного оператора и сам
	  оператор;

	  реакция на такой ls-вектор в семантическом анализаторе
	  предусматривается для задания контекста в правом подвыражении дерева,
	  то есть, для переопределения привязок операторов к их реализациям в
	  виде наборов тетрадных инструкций.

Эти ухищрения нужны в основном для того, чтобы без лишней пунктуации описывать
сложные типы данных и конструкции управления потоком управления. Примеры:

	- список двумерных массивов из ассоциативных массивов для пар
	  строка : запись о человеке
	  
	  var L list array(20;20) array(string) record(age uint; name string)

	  в Си++ это был бы ужас из угловых скобок;

	- запуск команды через оболочку «естественным» способом (как пример
	  конструирования сложного объекта):
	  
	  val p = unixpipe();
	  val proc = (1=p; ffmpeg f.v4l2 i.'/dev/video0' af.null vf.grayscale);
	  var sum int = 0;
	  p.bytes.foreach(x byte) (sum += x < 20 && x < 40);
	  proc.wait();
	  echo 'число не-таких-уж-ярких-пикселей %d'.fmt(sum);

	- сложные управляющие конструкции:

	  x = switch
	  (
	  	y == a -> b;
		y == z -> (val t = sin(z)/exp(y); pin = t*t + 1);
		false -> 3.1415926
	  )

	- возможно, это поможет писать и SQL запросы без дополнительной
	  пунктуации (LINQ пример востребованности такой техники).

Теперь подробнее о каждой из дополнительных техник в парсере.

1. Унарные операторы

(Вообще, надо сказать, что операторы - это не самый точный термин, но, надеюсь,
всем понятно, что он означает).

Не знаю, насколько это стандартный подход к проблеме, но нам ещё в школе о нём
рассказывали. Некоторые операторы можно трактавать, как унарные, если известно,
что предыдущая лексема была:

	- «начало разбора»
	- «;»
	- «(»
	- оператор

Приоритет этих операторов должен быть равным приоритету «!». На данный момент
предлагается считать возможными унарными операторами «-», «^» (для побитового
not). При необходимости этот набор можно легко расширить.

Классический алгоритм разбора операторной грамматики можно записать так:

0	for(stack.top != '$' || input(ip) != '$') // $ - начало и конец строки
1	(

2		if(P(stack.top) <= P(input(ip)) // P(x) - приоритет x
3		(
4			stack.push(input(ip));
5			ip += 1
6		)

7		else
8			for(P(stack.pop()) > P(stack.top)) ()

9	)

В LiME команды, выдаваемые парсером в семантический движок, нужно выдавать по
событию stack.pop(). Поэтому, цепочка унарных операторов будет сперва накоплена
в стеке в ветви (2:6), а потом в обратном порядке выдана в виде команд для
семантического анализатора в повторениях ветки (7:8), что соответствует
традиционной политике, когда унарные операторы оцениваются справа-налево.
Например (как из учебника):

-	$ x * -^y + z $		- оставшийся вход		
				- стек
				- команды движку (без уточнений)

-	x * -^y + z $
	$


-	* -^y + z $
	$ x


-	-^y + z $
	$ *
	e1 = x; l1 = e1:*
	
-	^y + z $
	$ * u-
	e1 = x; l1 = e1:*

-	y + z $
	$ * u- u^
	e1 = x; l1 = e1:*

-	+ z $
	$ * u- u^ y
	e1 = x; l1 = e1:*

-	+ z $
	$ 
	e1=x l1=e1:* e2=y e3=^:e2 e4=-:e3 e5=l1:e4 l2=e5:+

-	z $
	$ +
	e1=x l1=e1:* e2=y e3=-:e2 e4=-:e3 e5=l1:e4 l2=e5:+

-	$
	$ + z
	e1=x l1=e1:* e2=y e3=-:e2 e4=-:e3 e5=l1:e4 l2=e5:*

-	$
	$
	e1=x l1=e1:* e2=y e3=-:e2 e4=-:e3 e5=l1:e4 l2=e5:* e6=z l3=e6:+ e7=l3:e6

2. Неявные лексемы операторов s-apply и p-apply.

Парсер «замечает» их в потоке операторов по особым правилам.

p-apply (parentheses) вводится:
	- после атома перед «(»;
	- после «)» перед «(»;

s-apply (space):
	- между двумя атомами;
	- после атома перед унарным оператором;
	- после «)» перед атомом.

Приоритет p-apply максимальный и равен приоритету «.». Приоритет s-apply
непосредственно предшествует приоритету унарных операторов.

Благодаря этому выражения вида

	var x array(20) unsigned long int

не требуют специальных синтаксических конструкций для разбора и легко
превращаются в синтаксические деревья «операторного» вида (фактически, в нечто
подобное S-выражениям).

	(s-apply
		(s-apply var x)
		(s-apply
			(p-apply array (20))
			(s-apply (s-apply unsigned long) int)))

Аналогично, выражения вида:

	for(x = 0; x < N; x += 1) (dosomething());

не требуют специального синтаксиса и превращаются в операторные деревья:

	(p-apply (p-apply for (...)) (dosomething()))

То есть, здесь снова не требуется специальный синтаксис для задания этих
конструкций. Если теперь предоставить программисту средство описывать
преобразования над промежуточным кодом, которые должны выполнятся по поступающим
от парсера командам, то можно будет говорить о возможности программирования
конструкций управления потоком управления for, switch и прочих.

3. LS-Векторы.

Фактически все КС-грамматики с просмотром на одну лексему вперёд неявно
выделяют накопленный слева контекст анализа текста так или иначе. Однако, ему не
придаётся особого значения. В LiME предпринимается попытка это значение придать
и воспользоваться им.

Допустим, разбирается конструкция:

	var name int;

Если подходить стандартно к разбору этого выражения (с учётом автоматически
внедрённого в поток лексем s-apply), то сначала надо оценить «var», затем, 
«name», а потом их связку. Но так как name ещё не объявлено, то сложно это
выражение оценить корректно (на самом деле, LiME, конечно же, знает, как это
сделать). Поэтому логичнее включить (в некотором смысле) специальный режим
анализа последующих за (var s-apply) выражений. В более сложном выражении такая
необходимость более очевидна:

	var name.1 int;

Так как int ещё не объявлена, то семантический движок не может верно оценить
выражение «name.1», так как его таблицы на момент объявления не содержат
достаточной для этого информации. Эта информация должна сформироваться в
процессе регистрации новой переменной при помощи конструкции «var». Поэтому
разбор (точнее, накопление) выражения «name.1» должно происходить в специальном
режиме, который может быть включен при обнаружении вектора (var s-apply).

Аналогичная ситуация существует, например, и при трансляции оператора for:

	for(var i int = 0; i < N; i += 1) (sum += i);

Корректный семантический анализ тела цикла невозможен без информации о «i». И
чтобы её распространить, необходимо сперва обработать левую часть выражения:
«for(...)» - которая как раз и определяется ls-вектором, и о которой
семантический анализатор узнаёт через специальную команду.

Аналогично в задающих сложные конструкции выражениях:

	ffmpeg i.'input' c.v(libx264 fast pass.1) an f.mp4 y.'/dev/null'

для корректного разбора этого выражения семантический анализатор должен знать,
что «i», «c», «v», «libx264» и прочие символы следует интерпретировать только
как атомы (ну, или в соответствии с иным смыслом, предписываемым «ffmpeg»). Для
этого необходимо предпринять определённые действия, до того, как начнётся
оценка этих символов, и эти действия можно связать с обнаружением ls-вектора
(ffmpeg s-apply).

LS-Вектор легко сформировать. Он состоит из текущего бинарного оператора и
левого подвыражения. Оператор известен. А подвыражение формируется при
выталкивании терминалов (лексем) из стеках в строках (7:8) классического
алгоритма разбора.

4. Обработка ошибок.

Операторные грамматики хороши ещё и тем, что в них просто локализуются ошибки,
которые к тому же очень сложно допустить при написании текста (речь именно о
синтаксических ошибках; и то, что многие выражения синтаксически корректны,
может быть проблемой; но в случае LiME предполагается глубокий семантический
анализ).

Ситуация синтаксической ошибки при разборе операторного выражения возникает,
когда в потоке лексем встречаются две, которые не могут идти друг за другом,
или, говоря более формально, когда встречаются две несравнимые лексемы A и B,
для которых оба высказывания:

	A > B
	B <= A

будут ложными. Например:

	a + b %|;

Приоритет «|» меньше «%», поэтому, можно было бы считать, что нужно начать
выталкивать из стека предшествующее «|» содержимое. Но это не верно, потому что
«%» и «|» несравнимы. И в этом месте нужно выдавать сообщение об ошибке. Порядок
между лексемами частичный (то есть, некоторые элементы нельзя сравнивать). И
информацию о том, что сравнимо, а что нет, можно сохранить в матрице (если
влезет, можно в битовой).

На первом этапе разработки можно считать любую ошибку фатальной. В дальнейшем
разбор после ошибок можно восстанавливать достаточно просто (пропускать всё до
ближайшей «;» или корректной «)».

5. Некоторые мелкие пояснения.

5.1. Может потребоваться пояснение, почему именно такие приоритеты выбраны для
«->» и «:». Предполагается, что основное место их применения - описание
логических выражений, необходимых в верификации кода. Нечто такое:

	Forall x Someptrset : x.inrange(0:N-2) && x & 1 == 0 ->
		Exists y Intptr :
			y.inrange(1:N-1) && (Exists x Someptrset : y == x - 1)

Другое возможное применение пары этих операторов - конструирование аналога
3-местному оператору «?:» из C. Например:

	fun ceilmax(a Num; b Num) =
		a > b && a < ceil -> a : (b < ceil -> b : ceil);

6. IO

На вход синтаксический анализатор получает поток выражений, описывающих
лексемы. В формате, описанном выше, в разделе IO для сканера. Напоминание:
в первых версиях компоненты системы предлагается разбить на несколько процессов,
чтобы изолировать домены ошибок и добиться между ними минимального
последовательного интерфейса.

Выдаёт он команды для семантического анализатора. Примерно они были указаны
выше, более точное описание ниже. Формат несколько сложнее формата лексем, но
тоже может быть без особого анализа прочитан при помощи нескольких вызовов
scanf. Всего должно быть несколько видов команд:

	- атом;
	- ls-вектор;
	- префиксный унарный оператор;
	- бинарный оператор (ls-вектор и правая часть);
	- открытие нового блока («(»);
	- закрытие текущего блока («)»);
	- постфиксный унарный оператор (пока он один «;» и имеет для
	  семантического анализа особый смысл, но в синтаксисе он может
	  обрабатываться на общих основаниях).

Каждая такая команда вводит новое выражение в левой части, сослаться на которое
можно позже из правой:

	(l|e|b).«новый номер» = описание нового выражения 

«l» для обозначения ls-вектора, «e» - выражения, «o» - блока. Нумерация
векторов, выражений и блоков может быть независимая. Более этого, нумерация
векторов, выражений и блоков в новом блоке может начинаться с 0. Для
перекрёстного контроля корректности и для большего удобства человека при чтении
результатов работы парсера, лучше использовать такую неоднородную схему
нумерации.

Описание каждого нового выражения и команды открытия нового блока будет
содержать описание лексемы: атома, оператора или скобки. Описание этих лексем
может быть точно таким же, как на выходе сканера; то есть в виде «e»-ссылки на
существующую в таблице лексем, либо в виде «n»-введения новой лексемы. Далее,
это описание будет указываться как «lex».

«Невидимые» лексемы p-apply и s-apply можно указывать на общих основаниях с
единственной особенностью в том, что для них нужно «выдумывать» координаты,
которые (достаточно естественно) можно считать равными координатам правой
лексемы.

Теперь команды по видам:

	- атомы
		e.номер = a lex

	- ls-вектор
		l.номер = l e.номер lex

	- префиксный и постфиксный унарный (вся разница и тонкости в lex)
		e.номер = u e.номер lex

	- бинарный
		e.номер = b l.номер e.номер

	- открытие нового блока
		b.номер = lex

	- закрытие :
		e.номер = c b.номер lex

Например, для

	var (x; y) int = (3*4)

должна получится последовательность:

	e.0 = a : 1.1 N.1 13 1.3.var
	l.0 = l e.0 : 1.5 N.2 12 1 p-apply

	b.0 = 1.5 N.3 14 0 (
	e.0 = a : 1.6 N.4 13 1.1.x
	e.1 = u e.0 : 1.7 N.5 0 0 ;
	e.2 = a : 1.9 N.5 13 1.1.y
	e.3 = 


					       СЕМАНТИЧЕСКИЙ АНАЛИЗАТОР (ДВИЖОК)
