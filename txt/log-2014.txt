							     2014-01-13 23:01:44

Адская проблема с цитатой цитат. И вообще сложный вопрос: должен ли генератор
графа программы уметь генерировать новые генераторы программ?

По идее, должен. Это наиболее простой способ разобраться со структурами и
union-ами всякими. Ок. Зафиксируем это. Нам нужна генерация генераторов.

Но как это сделать? Вероятно, имеет смысл размышлять так. Наши программы - это
просто строки. И генераторы - это тоже строки (собственно тут ничего особо
нового, lambda - это тоже строки, поэтому здесь мы с генерального пути не
сходим). Ок.

Но дальше возникает вопрос с подстановками. Если мы хотим генерировать
генераторы, то указания на подстановки не должны выполнятся. Их надо
экранировать.

В lambda это экранируется собственно lambda-ми... Хм. Ну, Ок. И что?

--

C lambda всё хорошо, потому что там последовательность подстановок явно задана
(в обратном порядке) последовательностью lambda-термов. Но если мы хотим нечто
параллельное и событийное, нам нужно отойти от этой упорядоченности.

--

Когда у нас есть L = (lam x (lam y (x y))), то мы последовательно подставляем
другие выражения. При чём явно и последовательно. Сначала вместо x, потому
вместо y.

И делаем мы это явно, записывая ((L a) b). Но это не события, а последовательное
применение.

Если мы хотим событий, то должны писать как-то так: (e1.(signature 1) ...
eN.(signature N) (a.(add e1 e2) (sub a eN))

--

Проблема вот в чём (возможно). Когда мы говорим о лямбда, то у нас есть просто
группоид с аппликацией L1 L2 -> L3. Из одного выражения применением к другому
получается третье. Замечательно. Но в этом месте и различие.

Когда мы говорим о RiDE, то у нас есть некоторый контекст и к нему мы применяем
правило (форму), и получаем новый контекст (или даже новые контексты; но для
простоты можно считать, что он один). И мы должны писать C1 f -> C2.

f, при этом, вносит кусочек своего тела в новый контекст. Хм. Можно сказать, что
это похоже на трассы (trace) из CSP и теории следов (trace). Ок. Замечательно.
Мы пока не далеко ушли от общепринятого.

А. Ну и вот тут, собственно, загвоздка. А как нам превратить контекст в форму?
Это как раз и нужно для формирования форм для обработки структур и функций. Так,
замечательно. Значит, вопрос сводится к более конкретному: как формировать формы
из контекстов.

--

По идее, нам должно помогать то, что и формы, и контексты - это деревья (точнее,
ориентированные графы без циклов, но dag-и не звучит).

В принципе, мы могли бы сделать нечто такое. Вот есть форма - это F-узел с
атрибутами, содержащими некоторое дерево. Допустим, можно сказать, что вот в
этом дереве может быть G-узел, который содержит то дерево, которое пойдёт на
дописывание в контекст. Мы можем добавить парочку узлов, типа GWr, GRd для
обмена с этим поддеревом информацией через специальную таблицу.

Но в итоге это не особо спасёт нас от рекурсии: а что если мы хотим в
результирующий граф как раз и дописать узлы GWr, GRd? И вложенные G до кучи?

И ещё одно contra против подхода: в lambda можно обойтись только lambda.
Z-комбинатор и всё такое прочее.

--

О! А если мы посмотрим так. С логической точки зрения. По идее, форма может
являться конъюнктом, то есть штукой, для которой нужно выполнение всех условий,
чтобы сработать.

Контекст при этом является у нас дизъюнктом (ну, чем-то вроде), который ожидает
срабатывания одного из условий.

Это не изоморфизм, а просто аналогия. В принципе, формы и контексты могут быть
равноправными в том смысле, что мы можем копировать и запоминать в окружениях не
только формы, но и накопленные контексты.

Теоретически, этого может хватить для реализации структур. Ок. Эту мысль надо
развернуть.

P.S. Да, я в курсе, что в lambda все компоненты, необходимые для логики
(константы и операции) выражаются лямбда-термами. Возможно, где-то тут зарыта
тонкость. Потому что lambda всё равно требует вычисления значений всех
переменных. А когда мы говорим о распределённых и параллельных вычислениях, то
для принятия решения об истинности ИЛИ нам необходимо дождаться первого
истинного значения.

--

Тут +1-ом проходит то, что такой контекст мы можем записать в виде формы: в
штуке будет просто много выдачей с разными ключами тех форм, которые составляют
контекст.

Гомоиконичность соблюдается. Генерация такого контекста эквивалентна генерации
такой формы. Ну +\- какие-то детали, но в целом, похоже на правду.

Дальше? А дальше нам нужен конкретный пример. Потому что, возникает вопрос: а
как нам результат эволюции одного контекста приписать к контексту другому.

--

Проблема всё-равно с подстановкой в нужное место. Ну, банальная ситуация: if(a <
b) { c = d; } Накопленный контекст для ветки "c = d" нужно вставить в структуру
блоков, которая соответствует if-у. Так?

Так. Для этого у нас есть Crop. Специально его экранировать не нужно, потому что
он и так внутри формы стоит. Формы в нашем случае это аналоги lambda. Несколько
витиеватые, но сойдут для версии 0.D.

Так. Вроде. Этот вариант должен работать. Тут нет необходимости шаманить с
Quote-ами и eXecute-ами. Вроде, всё понятно и можно сделать без них.

--

По идее, у метода +100500 достоинств.

Формы всегда замкнутые. Мы можем свободно перекидывать их между контекстами без
проверок. Их можно использовать в качестве значений для параметров других форм.
В FOut-ах, то есть.
По узлам всё упрощается существенно. Дополнительная логика, которая потребуется - это Crop + R и всё. То есть, только areaeval без execeval с глючным смыслам.  Сами контексты (R-ы) можно тоже передавать в качестве параметров в формы.  Ну и тут мы ближе к lambda. Не нужно два варианта апликаций и экранов. Хватает
просто форм. От lambda мы отличаемся тем, что умеем явно манипулировать
распределёнными контекстами вывода.

Ок. Принимаем такой вариант. Будем пробовать.

PS: Eureka

							     2014-01-14 09:36:16

Так. В свете этого всего новая последовательность progress должна быть такой:

1.
	ntheval (75, надо немного прокачать Nth, чтобы оно сразу позволяло
	разбирать типы и символы) - подстановки всякие. FIn и Nth

2.
	enveval (100) - надо оценить окружения, нужно быть готовым к тому,
	что формы будут опубликованы в них

3.
	areaeval - оценка областей вывода. R, REnv и Crop получается

Пространство для работы создано

4.
	typeeval (100) - типы, потому что они могут входить в состав ключей

5.
	symeval (100)

6.
	formeval (100) - формы FEnv, FPut

7.
	outeval - обработка FOut

8.
	К следующей итерации алгоритма

							     2014-01-16 12:49:38

Обнаружилась ошибка в алгоритме enveval. Env-узлы обрабатываются позже, чем
узлы, которые они должны помечать. Поэтому в envmarks попадают неверные
отметки.

Для исправления ситуации алгоритм нужно разбить на три части, а не на две
текущие: (1) конструирование, определение (как раз Env) окружений, разметка
узлов на текущем уровне определений; (2) проход на уровень ниже.

Должно быть три части: (1) конструирование и определение окружений на текущем
уровне; (2) разметка узлов на текущем уровне; (3) проход на уровень ниже.

							     2014-01-16 14:03:53

Видимо, имеет смысл области вывода делать тоже списками из нескольких массивов.
Типа, areacurrent, areaforward и areadag. Чтобы не заморачиваться с управлением
памятью.

Так. Но что-то тут не так, как надо. Потому что области должны уметь ссылаться
друг на дружку.

И makepath для них тоже должен работать.

Поэтому, области - это keymap-ы, получается. И у них должно быть 3 поля. Это
связки с другими keymap-ами. Ну ладно. Плюс информация о том, чего там накоплено
к настоящему моменту.

Ну, хорошо. А как понять... Да, вроде, всё должно работать.

							     2014-01-16 16:13:00

Ага. Вопрос был о том, а как понять, можем ли мы собирать (Crop) контекст.
Ссылки же могут быть двусторонние. По идее, в полноценной реализации мы просто
понимаем, что все каналы закрыты и тогда контекст можно закрывать, если он сам
не проявляет активность.

Область и контекст - это одно и то же. Ну, супер. И что?

Другие варианты:
	
	- контекст может сам себя закрыть;
	- контекст может закрыть все свои каналы;

Вата. Закрывать по одному каналу тяжко. А что делать с закрытыми областями? Мы
их можем собрать и тогда освободить структуры. А если он закрылся, и никто его
не хочет собирать?

Хорошо. Он закрылся. А ссылка на него висит, например.

							     2014-01-27 18:10:54

Чёртов exprewrite. assert-ится. Правильно делает, конечно. Но мать его за ногу.
Что делать в этом месте? Можно включить в обработку определения узлов, так?
Чтобы он просто пропускал узлы, которые во что-то отображаются. И ходил по
атрибутам простых узлов.

Вероятно, это более предпочтительный вариант в сравнении с последующей сборкой
мусора. Выглядит аккуратно. Только ещё надо учесть тонкость: если мы
переписываем узел на него же самого, то это означает, что его надо оставить.

Частные случаи, чёрт их.

Ну получается же, что нам надо делать нечто похожее на forkdag. Странно как-то
получается.

Нет. Не forkdag. У нас в exprewrite может быть ещё допустимая ссылка на не
понять куда. Получается, forkref-ом тоже не получится в полной мере
воспользоваться. Гадость.

Эх, реально же гадость. Получается, что надо повторить структуру forkdag с
учётом всяких разных тонкостей.

И что с этим делать? forkref переписать что ли? Не, не пойдёт. Значит,
exprewrite жертва. Поехали

							     2014-01-27 21:24:53

Собственно, exprewrite так и устроен. Только вот forkref не работает в этом
случае. Там должен быть rewrite, видимо

							     2014-01-28 08:11:12

Эх. То nodemap, которое в exprewrite это совсем не то nodemap, которое нужно.
Вообще, получается какая-то странная логика.

Ещё раз. exprewrite берёт на вход выражение в виде графа. Берёт отображение
узлов этого графа в другие выражения (возможно, другие графы) и берёт verbs-ы
тех узлов, которые надо переводить в новые значения.

Так. Nodemap - это внутреннее отображение, используемое для forkref на тот
случай, если подставлять придётся графы целиком.

forkdag выглядит вот как, если что:

	Ref forkdag(const Ref dag)
	{
		Array *const M = newkeymap();
		const Ref r = forkref(dag, M);
		freekeymap(M);

		return r;
	}   

Ок. Но, значит, если мы при переписывание узлов копируем определения... Нам же
надо сохранить целостность ссылок. И чего делать?

Мы же должны сохранить ссылки

							     2014-01-28 13:15:06

Продолжение о exprewrite.

1.
	В реализации у нас есть nodemap для forkref-ов. Можно отображать копии
	узлов исходного выражения в этой nodemap. По идее, чисто внешне, эти
	узлы не должны пересекаться с узлами в обрабатываемой форме (откуда тот,
	кто сотворил подстановки может знать о форме, которая сама была
	скопирована, чёрт знает откуда.

2.
	В принципе, можно сделать два разных прохода. Отдельный проход
	подстановки, а потом собрать мусор. Но это не решение проблемы. Косяки
	тут те же самые, потому что основная проблема не в мусоре, а в
	подстановках.

Поэтому продолжаем мысль

1.
	В NM (nodemap) не должно быть пересечений с текущей формой. Но они могут
	возникнуть из (а могут ли? нужно учитывать, что каждое определение
	живого узла относительно уникально, занимает свой набор ячеек в памяти):

	1.1.
		NM дописывается в forkref при подстановке значения из map. Это
		дописывается в том случае если в значении встретилось
		определение узла, и этот узел был скопирован. И дальнейшие
		ссылки на него транслируются через эту трансляцию.

	1.2.
		NM может дописаться при активности в exprewrite при дублировании
		исходной формы.

	1.1. и 1.2. могут пересекаться в случае, если в map упомянуто как-то
	определение узла из обрабатываемой формы. А это может произойти, если в
	map в качестве значения стоит сама форма.

	А при нормальном течении алгоритма такого быть не может, по идее. Формы
	перед обработкой копируются из хранилищ. Ок.

3.
	На случай пересечения у нас может быть два решения. На самом деле, там
	надо решать проблему ещё с несколькими forkref-ами в течении одной
	подстановки. Они тоже могут пересекаться своими определениями.

	3.1.
		Можно каждый раз брать свою keymap. И для forkref, и для
		основного процесса exprewrite. Но это плохо, ибо незамеченными
		могут оказаться самые разные косяки. И потом, не понятно, а если
		пользователь захочет добиться связи разных значений в одно
		целое? То есть, чтобы ссылка на один и тот же узел
		была подставлена корректно? Поэтому НЕ ВАРИАНТ, хоть и какое-то
		решение.

	3.2.
		Нужно делать через одну NM для всех. Грабли начнут вылезать,
		если отклонимся от основного хода алгоритма. Но это, вроде, и
		полезно, чтобы они повылезали.
	
Вооружаемся вариантом 3.2.

Перепланирование:

1.
	Надо включить копирование определений узлов в exprewrite.

2.
	Надо научить сборку выражения пропускать ссылки, у которых
	(Ref.code == FREE).

3.
	Не забыть о тонкости, когда в map узел указывает сам на себя. Такой узел
	надо оставить в итоговом графе.

4.
	Проверить.

							     2014-01-28 16:41:53

В процессе:

П:1.
	Надо включить копирование определений узлов в exprewrite.

П:3.
	Не забыть о тонкости, когда в map узел указывает сам на себя. Такой узел
	надо оставить в итоговом графе.

П:4.
	Проверить.

Готово:

П:2.
	Надо научить сборку выражения пропускать ссылки, у которых
	(Ref.code == FREE).

Проблемы теперь с пунктом три. Что делать с узлами, которые хотят оцениваться
сами в себя? Потому что, если мы вдруг хотим скопировать такой узел, то в map-то
останется прежняя ассоциация.

Варианты решения проблемы:

1.
	Грязным хаком подменить ассоциацию в map.

2.
	assert-ится на таких ассоциациях, как на бессмысленных.

Грязный хак - это плохой вариант. Map может быть использована повторно. Поэтому
пойдём по варианту 2. Для этого нужно:

П:5.
	Нужно сразу же превращать Ref-у на узел в Ref-у через map. И сразу
	проверять, что нам не подсовывают "тавтологию".

Только это, всё равно, не спасает гигантов мысли. Ссылка может быть указана
через какой-нибудь уровень вложенности. И хрен её тогда поймаешь. Нужен более
общий подход.

							     2014-01-28 18:12:01

В общем, надо менять стратегию. Нужно отказаться от попыток всё сделать в одном
проходе. Прохода должно быть два. Один - «раскопирование» графа для создания
места для подстановок, а потом «починка» этого графа с правкой ссылок на
исходные узлы в ссылки на узлы новые.

Определения при этом можно оставить на месте.

Логика с использованием общей nodemap здесь не меняется. Пускай будет для
надёжности.

ИЗ ЗАНЯТНОГО:
	
	За один проход, с созданием новых узлов и переписыванием ссылок мы не
	сможем корректно построить новый граф. Но за два прохода: copy и fix -
	можем.
	
	Q:
		Должны ли мы рассматривать копирование, как процесс создания
		места для вычисления новой фиксированной точки, а переименование
		узлов, собственно, как само вычисление?
	
	Q:
		Может ли на самом деле процесс «затягивания узлов» из мира ФП и
		рекурсии быть процессом отождествления?

							     2014-01-28 19:16:00

В общем, видимо, из той же оперы: мы не можем определить то, оставлять ли
какой-то узел в выражении или нет, потому что, фиг знает, когда на него всплывёт
ссылка. В принципе, можно сконструировать разные варианты.

Для надёжности надо собирать мусор уже после copy-fix. В итоге всё превращается
в четыре стадии:

	eval:
		Написано, не проверено

	exprewrite:
		copy:
			Написано, но надо выделить

		fix:
			Написано, но надо выделить

	GC:
		Написано

Так. Ладно. Замечательно. Потом тогда надо будет сделать финт ушами и заменить
forkref на exprewrite с нулевыми отображениями узлов на значения (map) и verbs.

							     2014-01-30 12:08:34

Блин. Аккуратнее надо. Так.

1.
	Не надо пытаться пропускать Ref.code == free (готово).

2.
	Так. В проходе copy мы не транслируем ссылки, потому то бессысленно
	(готово).

4.
	Надо смягчить политику forkref. Потому что в текущем варианте он будет
	вылетать с assert-ами, потому что не будет знать, куда отображать
	ссылки (готово).

5.
	Переопределения узлов надо сложить в nodemap. При это надо рекурсивно
	пройтись по атрибутам (готово).

							     2014-02-01 14:08:07

exprewrite, вроде как, снова готова. Надо теперь выполнить проверку. Оценка и
копирование.

Эх. А потом ещё надо будет собрать мусор
