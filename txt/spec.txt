СПЕЦИФИКАЦИЯ LiME. Версия 1.dev (в разработке).

									    ЦЕЛЬ

Сделать систему трансляции, которая давала бы программисту несколько
инструментов, которые, как показывает практика современного программирования,
востребованы и позволяют повысить производительность труда:

	- система типов с автоматическим выводом (возможно, в некоторой
	  ограниченной форме);

	- средства определения пользовательские конструкции для управления
	  потоком вычисления (чтобы создавать собственные реализации
	  for/if/switch, что может быть полезно в разработке приложений для
	  неоднородных систем);

	- замыкания, как более гибкую в сравнении с ООП систему декомпозиции и
	  композиции кода (тут можно сослаться на опыт Go);

	- специализацию кода во время исполнения, что, как известно ('C:
	  http://pdos.csail.mit.edu/papers/tickc-poletto-phd.pdf) существенно
	  повышает эффективность программ;

	- императивную семантику, которая предоставляет программисту большую
	  гибкость в построении различных структур событий (имеется в виду
	  математический аппарат для описания вычислительных процессов);

	- модель исполнения ориентированную на процессы, а не на потоки;
	  процессы (в том числе и программно-изолированные) удобнее и
	  эффективнее в задачах управления ресурсами по сравнению с нитями, и не
	  уступают последним в эффективности при выполнении многозадачных
	  вычислений;

	- средства статического анализа кода и верификации;

	- оптимизирующий компилятор, позволяющий разрабатывать
	  высокопроизводительные приложения для супер-компьютеров;

	- основные алгоритмы системы должны быть достаточно простыми для
	  быстрого их переноса на различные платформы, в том числе, с небольшим
	  объёмом оперативной памяти (cкажем, 256KiB); основными названы те, что
	  позволяют получить из исходного кода машинный.

В той или иной степени некоторые из этих инструментов реализованы в различных
системах программирования, однако все они не собраны ни в одной. Поэтому
возникает идея разработать подобную систему трансляции.

Побочным эффектом при её реализации должна стать возможность достаточно простой
организации frontend-ов некоторых традиционных языков программирования (C99,
Fortran, etc) поверх системы LiME. Определение базовых типов и конструкций для
описания потока управления на уровне пользователя должны свести задачу
построения таких frontend-ов к созданию:

	- кода, переводящего исходный текст программы в исходный текст на LiME,
	  возможно, в несколько оптимизированной форме, сходной с той, что сам
	  LiME (LiME is Metaprogramming Engine, поэтому сам) генерирует на этапе
	  синтаксического анализа;

	- реализаций тех или иных операторов, если они ещё не реализованы, в
	  рамках семантического движка LiME.

Примерно так.

								  СТРУКТУРА LiME

Здесь описан текущий высокоуровневый взгляд на систему.

LiME состоит из нескольких компонент, каждая из которых между своими
составными частями имеет обратные связи.

	- сканер: лексический анализатор с вполне классической структурой, с
	  небольшими отличиями (если не считать ключевые слова) от лексики Си;
	  лексический анализатор передаёт на синтаксическую стадию анализа поток
	  лексем вида («:» - условный разделить, главное, что речь о тройках):

	  	тип лексемы : значение : позиция в тексте;

	  под «типом лексемы» понимается:

	  	- идентификатор,
		- константа,
		- одна из групп операторов;

	- парсер: синтаксический анализатор простых операторных выражений, для
	  которого тоже достаточно простых алгоритмов; решётка приоритетов
	  операторов похожа на используемую в Go (в Си она слишком большая,
	  часто приходится вспоминать, но это нам не помешает);

	  неклассическая особенность: синтаксический анализатор может
	  «придумывать» некоторые операторы по фиксированной схеме;
	  синтаксический анализатор передаёт в семантический анализатор

	  список «команд» примерно такого вида:

		новый номер выражения = атом;

	  	новый номер выражения = унарный оператор : номер подвыражения;

		новый номер левого «вектора»
			= номер левого подвыражения
			: бинарный оператор

		новый номер выражения
			= номер левого «вектора»
			: номер правого подвыражения

	  «=» и «:» - это малозначимое форматирование; такой интерфейс не совсем
	  традиционный, но тут всё строго;

	  такие нетрадиционности необходимы, чтобы в LiME можно было
	  программировать, например, такие конструкции (в ней нет ключевых
	  слов и встроенных операторов):

	  	for(var (x.1; x.2) = range2d(0:N-1; 0:M-1))
		(
			sum += field(x.1; x.2)
		)

	  frontend-ы других языков программирования могут взаимодействовать со
	  следующей, основной частью всей системы через генерацию такого вида
	  «команд»;

	- движок: семантический анализатор - основная часть системы, которая на
	  основе команд, описывающих связи выражений с операторами строит
	  промежуточное представление программы, пригодное для генерации кода;

	  пока такое промежуточное представление предполагается делать в виде
	  кода из тетрад (в основном), то есть, элементов вида:

	  	код операции «метка» =
			«ссылка на аргумент 1» «ссылка на аргумент 2»

	  это текстовое представление, доступное программисту, поэтому
	  желательно, чтобы оно было таким; метки удобны для программиста,
	  а этот формат удобно разбирать; двоичное представление
	  последовательности таких выражений, конечно, триадное; пример:

	  	a = x + y | z

		addr	pa = a;		// идея разделения получения адреса
		addr	px = x;		// значения, его загрузки и собственно
		addr	py = y;		// вычисления взята из LCC; это
		addr	pz = z;		// позволяет упростить кодировку
		ld.u8	vx = px;	// операции (or, add работают только со
		ld.u8	vy = py;	// значениями; addr - с символами;
		ld.u8	vz = pz;	// ld - c адресами; можно проверять
	  	or.u8	t1 = y, z;	// корректность); опыт работы с LCC
		add.u8	t2 = x, t;	// позволяет сказать, что в одну
		st.u8	pa = t2;	// инструкцию всё это свернуть просто

	  задача движка брать такие участки кода, которые в процессе трансляции
	  он же связывает с подвыражениями и, руководствуясь специальными
	  таблицами, используя информацию о типах подвыражений и операторе
	  выводить тип составного выражения и соответствующий ему участок кода;

	  в коде могут быть специальные директивы для самого синтаксического
	  анализатор, которые он должен выполнять; например, директивы для
	  введения новых переменных или типов;

	  	.var	a = unsignedlonglong;

	  выполнение этой директивы должно сделать запись о символе a с
	  соответствующим типом в специальных таблицах SE;

	  такое представление программы, в котором большинство конструкций
	  проинтерпретировано должно передаваться дальше; набор необходимых
	  директив нужно обсуждать;

Дальнейшие участки проработаны не так хорошо. Какой-то код сгенерировать
возможно пользуясь опытом, полученным от LCC, так как далеко отходить от
традиционной структуры промежуточного представления не планируется. Но как
сгенерировать более оптимальный код - это вопрос будущего.

	- верификатор: где-то здесь должна быть система верификации, которая
	  получает достаточно информации от SE, чтобы выполнить определённые
	  проверки кода; хотя бы на выходы за границы; возможно, эта часть
	  должна быть тесно связана с семантикой, но на сегодняшний день
	  представляется, что информации о размерах типов может быть достаточно
	  для решения проблемы контроля выходов за границы памяти; это место
	  тоже надо обсуждать;

	- оптимизатор, получающий от FE представление программы в промежуточном
	  виде, в котором нет управляющих директив для семантического движка;
	  например, информации о взаимосвязи типов; предполагается, что
	  оптимизатор не нуждается в информации о том, например, что некая
	  структура данных была выведена из выражения

	  	array(20) list hash(string) int.2

	  вопрос, одако в том, какие знания о программе необходимы для успешной
	  оптимизации; достаточно ли знать только представление в виде потока
	  данных, из которого можно вывести всё остальное?

	  представляется, что оптимизатору не требуется обратная связь с
	  фасадом;

	- генератор кода для целевой машины; должен получать от FE некоторое
	  описание программы, и генерировать по нему ассемблерный код.

Представляется, что во время runtime-специализации кода его семантика не должна
меняться. То есть, например, в функции вычисления, допустим, факториала целые
числа не должны неожиданно превратится в вещественные.

Хотя, может быть, именно такое поведение и требуется программистам: много раз
приходилось слышать, что eval - это очень хорошо. Это тоже открытый вопрос на
данный момент.

Эти сомнения не влияют на особенности реализации C99 поверх LiME. Это всё более
продвинутые алгоритмы на будущее.

Итак. Теперь к каждой части подробнее. Нужно понимать, что изложенное ниже не
является окончательной версией спецификации. Просто в ходе научных (это следует
подчеркнуть, наука в данном случае - поиск нового) исследований была получена
такая конструкция. Многое может быть изменено в сторону усложнения или
упрощения.

						 ЛЕКСИЧЕСКИЙ АНАЛИЗАТОР (СКАНЕР)

1. Входной алфавит.

Конечно, сканер должен поддерживать строковые константы. Строковые константы
интерпретируются как цепочки байтов определённой длинны. Они могут быть
дополнены нулём во время семантического анализа для нужд компилятора Си99, но
на уровне сканера они представляются как массивы байтов определённой длинны.

Внутри строк могут встречаться любые символы (цепочки байтов).
Последовательности байтов могут задаваться и через привычные
escape-последовательности: «\t», «\r», «\n», и т.д. Кроме этого, предлагается
задавать цепочки байтов произвольной длины последовательностью «\x([0-0a-f]+)».
Например:

	uint(40) shasum = "\x(f444e5be3f26f57c4fcfa7d32a0379adf70c9473)"

Лексический анализатор поддерживает однострочные комментарии, начинающиеся
последовательностью «//». В комментарии может встречаться любая
последовательность байтов.

Вне строк и комментариев допустимыми символами считаются лишь следующие из
набора ASCII:

	- TAB - LF 	09 - 0A
	- « » - " 	20 - 22
	- +		2B
	- «-» - >	2D - 3E
	- A - Z		41 - 5A
	- ^		5E
	- a - z		61 - 7A
	- |		7C

Некоторых привычных символов здесь нет, можно считать их зарезервированными для
будущих версий, если вдруг понадобятся.

Сканер выделяет в последовательности символов несколько типов лексем:

	- атомы-символы (примитивные идентификаторы): последовательности
	  латинских букв и цифр [a-zA-Z0-9]+; атомы сравниваются с учётом
	  регистра; хотя гуру языков программирования аргументируют за
	  нечувствительность к регистру, практика показывает, что X и x лучше
	  трактовать как разные символы, особенно в вычислительных программах;
	  традиционное _ не включено в алфавит символов, потому что в
	  LiME предусматриваются другие способы давать сложные идентификаторы
	  переменным; например, для описания символов в C99 или во внешних
	  библиотеках можно использовать нечто вроде:

	  	id."classic_c_symbol_with_a_lot_of_underscores"
		id.cpp."SomeClass::overloadedMethod(int, ClassY, float)"

	- атомы-константы: строки и целые числа в записи по основаниям 10 и 16;
	  числа передаются лексическим анализатором на другие уровни трансляции
	  в формате длинных чисел без потери разрядов;

	- операторы различного приоритета:

									     Т.1
		0 ;
		1 = *= /= %= >>= <<= &= += -= |= ^= ||= &&=
		2 ->
		3 «:»
		4 ||
		5 &&
		6 == != < <= > >=
		7 + - | ^
		8 * / % << >> &
		9
		a !
		b .

	- скобки: ()

Некоторые особенности.

1. Немного нетрадиционно обрабатываются вещественные константы. Предполагается
сделать их составными и выводить уже на этапе семантического анализа. Возможно,
не самый лучший дизайн, но константы записываются в коде программы редко, можно
необычность в виде:

	0.6 E(3) * 3.1415 // == 1884.9

и потерпеть. Это сделано для обеспечения двух возможностей. Первая - возможность
давать переменным структурированные имена:

	var (x.1 = 21.3; x.2 = 4; x.4.5 = 3.1415; x.2.alpha = "alpha");

А потом работать с группами этих переменных. Это часто бывает необходимо в
циклах, когда что-нибудь такое приходится писать:

	x_0 = x_1;
	x_1 = x_2;
	x_2 = next(x_0; x_1; x_2);

В LiME поэтому хочется предусмотреть возможность записи:

	x.(0; 1; 2) = (x.(1; 2); next(x));

Но для этого, чтобы не усложнять семантику и не отказываться от однозначности,
необходимо на общих основаниях воспринимать записи вида:

	12345.6789

деревьями вида

	(. 12345 6789)

Из такой конструкции можно вывести вещественное значение.

Другая составляющая мотивации всегда трактовать точку всегда как оператор и
иметь возможность описывать конструкции вида x.1 коренится в желании обеспечить
программисту конструирование сложных объектов в стиле командной строки UNIX.
Здесь тонкость в том, что конструируется многопараметрический объект, который
громоздко было бы описывать со множеством знаков препинания, при том, что
описание в виде командной строки в виде списка ограниченного набора конструкций
может быть достаточно мощным и адекватным.

Для такого конструирования необходимо без дополнительной (относительно)
пунктуации задавать конструкции, состоящие из основной команды, флагов и пар
(ключ; значение). Например, задающая определённый способ воспроизведения видео
конструкция

	screen -S mp mplayer ~/Downloads/87* \
		-vf crop=280:210,scale=320:240 -ao null -osdlevel 0 \
		-display :32.1 -fixed-vo -loop 0

в условиях, когда «.» всегда оператор может быть записана с учётом доступных в
LiME синтаксиса и семантики так:

	screen S.mp mplayer "~/Downloads.87*"
		vf(crop(280:210) scale(320:240)) ao.null
		osdlevel.0 display.32.1 vo.fixed loop.0

Не идеально, но менее громоздко, чем даже вариант с именоваными параметрами для
функций/конструкторов/подобных вещей:

	screen(S = mp; mplayer("~/Downloads.87*";
		vf = (crop(280:210) scale(320:240); ao = null; osdlevel = 0;
		display = "32.1"; vo = fixed; loop = 0))

Возможно, такая обработка «.» плохая идея, но:

	- это никак не повлияет на поведение frontend для C99, который сразу
	  может выдавать значения с привязанным к ним типом, описывающим
	  константы более точно; естественно LiME должен понимать отличия целых
	  чисел от вещественных, и такой механизм возможен;

	- никто не пробовал так делать в языках программирования, поэтому,
	  ответить на вопрос, насколько идея удачна и насколько плоха, сложно, в
	  ней есть недостатки, но и достоинства кроме упомянутых выше; например,
	  можно формировать ip-адреса без дополнительного синтаксиса:

	  	87.224.213.1

	  такие конструкции могут быть однозначно интерпретированы в LiME;

	- в Perl не такой же, но похожий механизм есть; Perl спорный, но тем не
	  менее, широко распространённый язык.

2. Предполагается различать атомы нестрогим способом. Для синтаксического
анализа, основанного на операторной грамматике, отличать (условно)
идентификаторы от констант не нужно. А семантическому анализатору достаточно
иметь подсказку о том, какой вид имеет атом. Например, если лексический
анализатор подскажет семантическому, что 12345 - последовательность
десятичных цифр, то такая

	var 12345 unsigned int = 20;

конструкция может быть отброшена на этапе семантического анализа с сообщением о
том, что 12345 неподходящий вид атома для идентификатора. Такой подход позволяет
выражать и более сложные константы относительно экономным способом. Например,
ipv6 адреса:

	ping fc00.bad.c0de.0(fill).1

Эта предлагаемая особенность тоже не особо проверенная временем, поэтому выводы
о верности решения можно сделать только после определённой практики, но можно
сказать, что нечто похожее есть в языках для оболочек операционных систем. Когда
записано:

	wget -r --tries=10 http://fly.srk.fer.hr/ -o log

То все выражения получают свой смысл лишь в контексте исполнения wget, оставаясь
до передачи в wget просто строками. В LiME это может быть записано с примерно
той же семантикой в виде:

	wget r tries.10 "http://fly.srk.fer.hr/" o.log

3. IO

На вход сканер получает поток байтов, на выходе генерирует поток команд. В
первых, экспериментальных, версиях системы предлагается пожертвовать скоростью
трансляции в пользу удобства отладки и минимизации доменов ошибок. Поэтому
сканер предлагается сделать отдельным процессом, который передаёт
синтаксическому анализатору команды в виде конструкций (подобраны так, чтобы их
можно было легко читать при помощи scanf):

	- F «описание файла» для указания очередного файла с исходным текстом;
	- (E.номер|N.«новый номер») l.c «спецификация» для указания очередной
	  лексемы.

«Описание файла» может иметь такой вид:

	«длина пути в байтах»."«сами задающие путь байты»"

«l.c» - это координаты лексемы в виде +l строк +c байтов относительно
предыдущей лексемы или начала файла.

Описание лексемы может начинаться двумя способами:

	E.номер
	N.«новый номер»

«E» ссылается на уже записанную в таблицу лексем лексему. В записи должны быть
сохранены все параметры из полной спецификации, необходимые для дальнейшей
обработки. В «E»-случае спецификация лексемы должна состоять из сторокового представления лексемы.

«N» должна задавать новую запись в таблице, номер должен быть ранее не
использованным. Тут возможен перекрёстный контроль корректности с проверкой на
стороне потребителя.

Спецификация лексемы должна иметь структуру вида:

	тип уточнение

тип - число, задающее вид лексемы:

	- для операторов - это номер:


		 0	;

		 1	=
		 2	*=
		 3	/=
		 4	%=
		 5	>>=
		 6	<<=
		 7	&=
		 8	+=
		 9	-=
		10	|=
		11	^=
		12	||=
		13	&&=

		14	->

		15	:

		16	||

		17	&&

		18	==
		19	!=
		20	<
		21	<=
		22	>
		23	>=

		24	+
		25	-
		26	|
		27	^

		28	*
		29	/
		30	%
		31	<<
		32	>>
		33	&

		34	@		- s-apply, вводится парсером

		35	!
		36	-		- унарный, вводится парсером
		37	^		- унарный, вводится парсером

		38	.
		39	@p		- p-apply, вводится парсером

		40	(
		41	)

	- для атомов - это 42		- вот теперь хорошо.

Уточнение - дополнительная информация. Для операторов - это строковое (в «"»)
представление этого оператора для перекрёстной проверки корректности и
читаемости. Для атомов - это такая структура:

		«тип атома».«длина в байтах»."«сами байты»"

Тип атома задаётся битовой строкой, где каждый бит означает (биты записаны
числами):

	1 - атом может быть строкой
	2 - атом может быть десятичным числом
	4 - атом может быть шестнадцатеричным числом
	8 - атом является строкой

Например:

	src/somefile
	x x

	F 12."src/somefile"
	N.0 0.0 41 1.1."x"
	E.0 0.2 "x"

Кажется, обо всех тонкостях сканера сказано.

					      СИНТАКСИЧЕСКИЙ АНАЛИЗАТОР (ПАРСЕР)

Можно было бы задать грамматику LiME в виде BNF и сказать, что вот она и есть.
Что можно её использовать для автоматического построения синтаксического
анализатора при помощи средств, генерирующих LL(1), LR(1) или LALR(1)
анализаторы. Но в таком случае разбор бы зависел от относительно (хоть алгоритмы
известны) сложных дополнительных программных средств. Кроме того, для увеличения
выразительности и «мощности» семантического анализа необходимо добится
определённых свойств в порядке свёрток. А BNF сама по себе не даст представления
о том, почему правила именно такие.

Поэтому хочется подвести к формальной грамматике LiME неформальным и более
содержательным описанием через определение необходимых деталей алгоритма. После
чего, грамматика будет формализована «естественным» образом.

Парсер LiME основан на разборе с переносом-свёрткой при помощи стека. За основу
алгоритма взят классический алгоритм (Fortran) разбора по граматике операторного
предшествования.

	http://en.wikipedia.org/wiki/Operator-precedence_grammar

Это очень простой и эффективный алгоритм, однако, оригинальный его вариант не
позволяет строить достаточно выразительные конструкции. Поэтому в LiME
применяется его модификация:

	- в некоторых случаях парсер воспринимает операторы «-», «^» (для
	  побитового not) как префиксные унарные;

	- в некоторых случаях парсер вставляет в поток лексем вспомогательные
	  лексемы, трактующиеся как бинарные операторы: «@» (space apply) и
  	  «@p» (parentheses apply);

	- парсер замечает то, что называется (за неимением лучшего термина)
	  «левой основной» (l-основой) - это пара из указателя на левое
	  подвыражение при обработке бинарного оператора и сам оператор;

	  реакция на такую l-основу в семантическом анализаторе
	  предусматривается для задания контекста в правом подвыражении дерева,
	  то есть, для переопределения привязок операторов к их реализациям в
	  виде наборов тетрадных инструкций.

Эти ухищрения нужны в основном для того, чтобы без лишней пунктуации описывать
сложные типы данных и конструкции управления потоком управления. Примеры:

	- список двумерных массивов из ассоциативных массивов для пар
	  строка : запись о человеке

	  var L list array(20;20) array(string) record(age uint; name string)

	  в Си++ это был бы ужас из угловых скобок;

	- запуск команды через оболочку «естественным» способом (как пример
	  конструирования сложного объекта):

	  val p = unixpipe();
	  val proc = (1=p; ffmpeg f.v4l2 i."/dev/video0" af.null vf.grayscale);
	  var sum int = 0;
	  p.bytes.foreach(x byte) (sum += x < 20 && x < 40);
	  proc.wait();
	  echo "число не-таких-уж-ярких-пикселей %d".fmt(sum)

	- сложные управляющие конструкции:

	  x = switch
	  (
	  	y == a -> b;
		y == z -> (val t = sin(z)/exp(y); pin = t*t + 1);
		false -> 3.1415926
	  )

	- возможно, это поможет писать и SQL запросы без дополнительной
	  пунктуации (LINQ пример востребованности такой техники).

Теперь подробнее о каждом элементе синтаксического анализатора LiME.

			  1.  Базовый алгоритм разбора

Алгоритм (далее так и буду на него ссылаться) разбора по оператороной грамматике
можно записать так:

0	for(stack.top != "$" || input(ip) != "$")
1	(

2		if(stack.top <∙=∙ input(ip))
3		(
4			stack.push(input(ip));
5			ip += 1
6		)

7		else if(stack.top ∙> input(ip))
8		(
9			for(var R = true)
10			(
11				var t = stack.pop();
12				R = stack.top <∙=∙ t
13			)
14		)

15		else (error())
16	)

Отношения <∙, =∙, ∙> - это отношения между символами, которые показывают, какое
выражение должно выделятся из потока лексем первым. Это три отдельных
отношения, поэтому может быть так, что A <∙ B, но при этом не выполнятся, что
B ∙>=∙ A, поэтому в 15 строчке вполне осмысленная ветка else, связанная с
обнаружением ошибки.

Для LiME в Алгоритме важно то, что:

	- как и любой другой алгоритм переноса-свёртки он анализирует текст
	  снизу вверх, выделяя при этом сначала самое левое возможное выражение;

	- операция stack.pop() явно связана с семантикой выражения, и фактически
	  означает: если выталкиваемый символ - это унарный оператор, то его
	  надо применить к накопленному перед этим выталкиванием выражению, если
	  бинарный - то, к последнему и предпоследнему выражениям (это можно
	  отслеживать при помощи стека, или даже при помощи двух переменных);

	- повторение ветки (7:14) конструирует то, что названо l-основой
	  выражения, явное её выделение и передача информации о ней в
	  семантический анализатор позволяет в LiME использовать в выражениях
	  для различных конструкций левый контекст.

Чтобы Алгоритм заработал, нужно указать отношения <∙, ∙> и =∙ между символами.
Начнём с простых приоритетов. Каждому символу S можно сопоставить число p(S) и
отношения с точкой между A и B определять по отношению чисел p(A) и P(B):

	- A <∙ B == p(A) < p(B);
	- A ∙> B == p(B) > p(A);
	- A =∙ B == (p(A) == p(B)).

Для большинства символов эти числа указаны в таблице распознаваемых сканером
символов (Т.1). При таком подходе (классика Fortran, кстати) атомы имеют
самый большой приоритет.

Почти всё хорошо, только не понятно, какие операторные выражения должны
соответствовать конструкциям вида

	for(exp; exp; exp) (exp).

Или, в каких отношениях должны состоять унарные «-» и «^» с другими символами.
Ведь для чисел не может одновременно выполняться p(-) > p(*) - для унарного - и
p(-) < p(*) - для бинарного случая (в классическом Fortran нельзя было
записать унарный минус без скобок). Нужны модификации в Алгоритме.

			     2.  Унарные операторы

(Надо сказать, что операторы - это не самый точный термин, но, надеюсь, всем
понятно, что он означает).

Наивный подход к проблеме таков. Некоторые операторы можно трактовать, как
унарные, если известно, что предыдущая лексема была:

	- «начало разбора»
	- «;»
	- «(»
	- оператор

Приоритет этих операторов должен быть равным приоритету «!». На данный момент
предлагается считать возможными унарными операторами «-», «^» (для побитового
not). При необходимости этот набор можно легко расширить.

Алгоритм предполагает, что выдаваемые парсером в семантический анализатор
команды нужно формировать по исполнению stack.pop(). Поэтому, цепочка унарных
операторов будет сперва накоплена в стеке в ветви (2:6), а потом в обратном
порядке выдана в виде команд для семантического анализатора в повторениях ветки
(7:14), что соответствует традиционной политике, когда унарные операторы
оцениваются справа-налево.

Например (как из учебника; команды показаны условно; число N после букв l, e, u
- это ссылка на предыдущее выражение, отстоящее справа от текущего на N
позиций; выражения разделены пробелами; точный формат в 6. IO):

									     П.1

-	$ x * -^y + z $		- оставшийся вход
				- стек
				- команды движку (без уточнений)

-	x * -^y + z $
	$


-	* -^y + z $
	$ x


-	-^y + z $
	$ *
	E=x L=e1:*

-	^y + z $
	$ * u-
	E=x L=e1:* U=-

-	y + z $
	$ * u- u^
	E=x L=e1:* U=- U=^

-	+ z $
	$ * u- u^ y
	E=x L=e1:* U=- U=^

-	+ z $
	$
	x L=e1:* U=- U=^ y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+

-	z $
	$
	E=x L=e1:* U=- U=^ y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+

-	$
	$ + z
	E=x L=e1:* U=- U=^ y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+

-	$
	$
	E=x L=e1:* U=- U=^ E=y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+ E=z E=l2:e1

	       2.  Неявные лексемы операторов «@» и «@p».

Парсер «замечает» их в потоке операторов по особым правилам.

@p (parentheses apply - p-apply) вводится:
	- после атома перед «(»;
	- после «)» перед «(»;

@ (space apply - s-apply):
	- между двумя атомами;
	- после атома перед унарным оператором;
	- после «)» перед атомом.

Приоритет «@p» максимальный и равен приоритету «.». Приоритет «@»
непосредственно предшествует приоритету унарных операторов.

Благодаря этому выражения вида

	var x array(20) unsigned long int

не требуют специальных синтаксических конструкций для разбора и легко
превращаются в синтаксические деревья «операторного» вида (запись в виде
S-выражений).

	(@
		(@ var x)
		(@
			(@p array (20))
			(@ (@ unsigned long) int)))

Аналогично, выражения вида:

	for(x = 0; x < N; x += 1) (dosomething());

не требуют специального синтаксиса и превращаются в операторные деревья:

	(@p (@p for (...)) (dosomething()))

Если теперь предоставить программисту средство описывать преобразования над
промежуточным кодом, которые должны выполнятся по поступающим от парсера
командам (которые описывают связи подвыражений в более крупные выражения при
помощи операторов), то можно будет говорить о возможности программирования
конструкций управления потоком управления for, switch и прочих.

				 3.  L-Основы.

Фактически все КС-грамматики с просмотром на одну лексему вперёд неявно
выделяют накопленный слева контекст анализа текста так или иначе. Однако, ему не
придаётся особого значения. В LiME предпринимается попытка это значение придать
и воспользоваться им.

Допустим, разбирается конструкция:

	var name int;

Если подходить стандартно к разбору этого выражения (с учётом автоматически
внедрённого в поток лексем @), то сначала надо оценить «var», затем,
«name», а потом их связку. Но так как name ещё не объявлено, то сложно это
выражение оценить корректно (на самом деле, LiME, конечно же, знает, как это
сделать). Поэтому логичнее включить (в некотором смысле) специальный режим
анализа последующих за (@ var ...) выражений (которые сформировать
выражение на месте «...»).

В более сложном выражении такая необходимость более очевидна:

	var name.1 int;

Так как name ещё не объявлена, то семантический движок не может верно оценить
выражение «name.1»: его таблицы на момент объявления не содержат
достаточной для этого информации. Эта информация должна сформироваться в
процессе регистрации новой переменной при помощи конструкции «var». Поэтому
разбор (точнее, накопление) выражения «name.1» должно происходить в специальном
режиме, который может быть включен при обнаружении основы (@ var ...).

Аналогичная ситуация существует, например, и при трансляции оператора for:

	for(var i int = 0; i < N; i += 1) (sum += i);

Корректный семантический анализ тела цикла невозможен без информации о «i». И
чтобы её распространить, необходимо сперва обработать левую часть выражения:
«for(...)» - которая сформирует l-основу, и о которой семантический анализатор
узнаёт через специальную команду.

Аналогично в задающих сложные конструкции выражениях:

	ffmpeg i."input" c.v(libx264 fast pass.1) an f.mp4 y."/dev/null"

для корректного разбора этого выражения семантический анализатор должен знать,
что «i», «c», «v», «libx264» и прочие символы следует интерпретировать только
как атомы (или в соответствии с иным смыслом, предписываемым «ffmpeg»). Для
этого необходимо предпринять определённые действия, до того, как начнётся
оценка этих символов, и эти действия можно связать с обнаружением l-основы
(@ ffmpeg ...).

L-Основу легко сформировать. Она состоит из текущего бинарного оператора и
левого подвыражения. Оператор известен. А подвыражение формируется при
выталкивании терминалов (лексем) из стеках в строках (7:16) классического
алгоритма разбора.

4. Обработка ошибок.

Операторные грамматики хороши ещё и тем, что в них просто локализуются ошибки,
которые к тому же очень сложно допустить при написании текста (речь именно о
синтаксических ошибках; и то, что многие выражения синтаксически корректны,
может быть проблемой; но в случае LiME предполагается глубокий семантический
анализ).

Ситуация синтаксической ошибки при разборе операторного выражения возникает,
когда в потоке лексем встречаются две, которые не могут идти друг за другом,
или, говоря более формально, когда встречаются две несравнимые лексемы (символа)
A и B, для которых все три отношения: A <∙ B, A ∙> B, A =∙ B - не будут
выполняться. Например,

	a + b %|;

Приоритет «|» меньше «%», поэтому, можно было бы считать, что нужно начать
выталкивать из стека предшествующее «|» содержимое. Но это не верно, потому что
«%» и «|». И в этом месте нужно выдавать сообщение об ошибке.
Информацию о том, что сравнимо, а что нет, можно сохранить в матрице (если
влезет, можно в битовой).

На первом этапе разработки можно считать любую ошибку фатальной. В дальнейшем
разбор после ошибок можно восстанавливать достаточно просто (пропускать всё до
ближайшей «;» или корректной «)».

В этом есть одна тонкость. Символы «%» и «|» несравнимы только если «%» уже
записан в стек, а «|» следующий символ во входной цепочке. С формальной точки
зрения это означает, что в стек записываются несколько отличные символы от тех,
что берутся из входной цепочки. Это означает, что речь идёт уже о немного более
сложной грамматике, чем грамматика операторного предшествования (7.
Формализация).

			5.  Некоторые мелкие пояснения.

5.1. Может потребоваться пояснение, почему именно такие приоритеты выбраны для
«->» и «:». Предполагается, что основное место их применения - описание
логических выражений, необходимых в верификации кода. Нечто такое:

	Forall x Someptrset : x.inrange(0:N-2) && x & 1 == 0 ->
		Exists y Intptr :
			y.inrange(1:N-1) && (Exists x Someptrset : y == x - 1)

Другое возможное применение пары этих операторов - конструирование аналога
3-местному оператору «?:» из C. Например:

	fun ceilmax(a Num; b Num) =
		a > b && a < ceil -> a : (b < ceil -> b : ceil);

5.2. Операторы &&= и ||=. Они вполне осмысленны, и пришли в LiME из Ruby
(наверное, есть и в других языках). Используются они в нескольких частых
идиоматических ситуациях:

	- если надо установить значения по-умолчанию:

		x ||= y;

	- продвижение к следующему элементу:

		x &&= x.next;

5.3. Предлагается воспринимать «;», как бинарный оператор, сцепляющий два более
простых выражения в более сложное. Это делает грамматику проще, а семантику
точнее.

5.4. Два варианта оператора применения (apply) @ и @p (это относительно
стандартное обозначение для аппли(apply)-кации) выбраны, чтобы несколько
увеличить выразительность и ужесточить семантику. @p связывает обеспечивает
высокоприоритетную группировку некоторого выражения с тем выражением, что
оказывается в скобках.

То есть, когда записано

	var x array(string) array(20) int(4);

Понятно, что 20 связывается со вторым символом «array». Если бы @ был одного
приоритета, то выражение бы получилось таким (расставлены скобки):

	(((((var x) array) string) array) 20) ...

Что не корректно. Можно было бы предписать программисту расставлять скобки:

	var x (array string) (array 20) (int 4)

в стиле S-выражений. Но это менее читаемо, и менее модифицируемо, и более
громоздко, допустим, нужен двумерный массив. Можно сравнить:

	var x array(string) array(20;30) int(4)

	var x (array string) (array (20;30)) (int 4)

Ок. Отсюда вывод: хорошо иметь высокоприоритетный @, когда этот оператор
применяется к выражению в скобках. Этот приоритет можно было бы выразить в
грамматике, не вводя специальный оператор. Но со специальным оператором это
проще и он позволяет решить ещё одну задачу. Позволить ужесточать форму
выражений, когда надо. Если программисту нужно, чтобы условие для конструкции
for всегда было в скобках, то точнее будет, если он привяжет семантику этой
конструкции к оператору «@p», который связывает символ «for» и «выражение в ()».

В LiME возможно сохранить выражение для последующей обработки:

	exp fe = (i = 0; i < 20; i += 1)

у fe (пока без подробностей) будет тип «выражение в ()», и если бы «@» и «@p»
не различались, то у пользователя была бы возможность сконструировать такое
выражение:

	for fe

что может быть нежеланно (хотя, может и не быть - решать автору for). Для
уточнения синтаксиса выражений в таких случаях и вводятся различные
«@»-операторы. Такая техника может быть расширена и на другие случаи.
				     6.  IO

На вход синтаксический анализатор получает поток выражений, описывающих символы
(лексемы). В формате, описанном выше, в разделе IO для сканера. Напоминание: в
первых версиях компоненты системы предлагается разбить на несколько процессов,
чтобы изолировать домены ошибок и добиться между ними минимального
последовательного интерфейса.

Выдаёт он команды для семантического анализатора. Примерно они были указаны
выше, более точное описание ниже. Формат несколько сложнее формата лексем, но
тоже может быть без особого анализа прочитан при помощи нескольких вызовов
scanf. Всего должно быть несколько видов команд:

	- атом;
	- l-основа;
	- префиксный унарный оператор;
	- бинарный оператор (l-основа и правая часть);
	- открытие нового блока («(»);
	- закрытие текущего блока («)»).

Каждая такая команда вводит новое выражение сослаться на которое можно позже из
описания выражения:

	(L|U|E|B) «описание нового выражения»

«L» для обозначения l-основы, «U» - унарного оператора, «E» - выражения, «B» -
блока. Нумерация векторов, выражений и блоков может быть независимая. Но для
большей читаемости удобнее считать, что все команды семантическому анализатору
пронумерованы последовательно. Ссылка на предыдущую команду может быть дана
относительная, то есть:

	если K - номер текущей команды (явно не указанный), а N - ссылка, то это
	указание на N-K инструкцию.

Ссылка должна начинаться с соответствующей прописной буквы (для контроля
корректности). Такие обратные ссылки позволят немного сэкономить на кодировании,
потому что в большинстве случаев они будут короткими.

Описание некоторых выражений должно содержать описание лексемы. Описание этих
лексем может быть точно таким же, как на выходе сканера; то есть в виде
«E»-ссылки на существующую в таблице лексем, либо в виде «N»-введения новой
лексемы. Далее, это описание будет указываться как «lex».

«Невидимые» лексемы «@» и «@p» можно указывать на общих основаниях с
единственной особенностью в том, что для них нужно «выдумывать» координаты,
которые (достаточно естественно) можно считать равными координатам правой
лексемы.

Теперь команды по видам:

	- атомы
		E a lex

	- l-основа
		L e.ссылка lex

	- бинарный
		E l.ссылка e.ссылка

	- унарный оператор
		U lex			- введение оператора;
		E u.ссылка e.ссылка	- применение;

	- открытие нового блока
		B lex

	- закрытие :
		E b.ссылка e.ссылка lex

Синтаксический анализатор должен передавать в семантический анализатор и
информацию о текущем обрабатываемом файле при помощи копирования команды

	F «описание файла»

на выход.

Например, для

									     П.2

	./somesrc.lm

	var (x; y) int = (3*4)

должна получится последовательность:

	F 12."./somesrc.lm"

	E a		N.1 0.0 41 1.3."var"
	L e.1		N.2 0.4 38 "@p"

	B		N.3 0.0 39 "("
	E a		N.4 0.1 41 1.1."x"
	L e.1		N.5 0.1  0 ";"
	E a		N.6 0.2 41 1.1."y"
	E l.2 e.1
	E e.1 b.5	N.7 0.1 40 ")"

	E l.7 e.1

	L e.1		N.8 0.2 34 "@"
	E a		N.9 0.0 41 1.3."int"
	E l.2 e.1

	L e.1		N.10 0.4 1 "="

	B		E.3  0.2 "("
	E a		N.11 0.1 41 6.1."3"
	L e.1		N.12 0.1 29 "*"
	E a		N.13 0.1 41 6.1."4"
	E l.2 e.1
	E b.5 e.1	0.1 E.7 ")"

	E l.7 e.1

Несколько замечаний.

	- То, что все ссылки на выражения имеют вид e.1 (то же самое и в примере
	  П.1) не случайно.

	- Процесс разбора подобран так, что все лексемы, указываемые в командах,
	  выдаются в том же порядке, в котором и считываются с выхода
	  лексического анализатора. Это позволяет несколько сэкономить память,
	  время обработки и сложность системы на переупорядочивании. Также этим
	  обеспечивается дополнительный уровень проверки (сопоставить выход
	  сканера с потоком лексем на выходе парсера).

	- Выражения с унарными операторами составляются в два приёма, чтобы
	  и для выражений с унарными операторами выполнялись первые два
	  замечания.

Это обосновано в следующем разделе. Фактически, это позволяет избавиться от
ссылок на предыдущее выражение (так как, это всегда непосредственно предыдущее
выражение). Финальная alpha версия входного языка для семантического анализатора
LiME будет описана в конце следующего раздела.

				7.  Формализация

Понятно, что грамматика LiME должна иметь структуру, соответствующую описанным
выше командам и техническим особенностям. Сейчас её структура должна быть
понятной и очевидной.

В описании грамматики будут использованы соглашения:

	- X -> Y | Z | ... | W означает (традиционно) набор правил:

		X -> Y; X - Z; ...; X -> W;

	- запись A (B | C | ... | Y) Z означает:

		A B Z | A C Z | ... | A Y Z;

	- для символов вида X.«hex-число» (X.N1 : X.Nk) означает:

		(X.N1 | X.N2 | ... | X.Nk);

	- для символов вида X.y выражение X.{i; j; ...; k} означает:

		X.i, X.j, ..., X.k


Ок. Теперь сама грамматика. Начинаем с наивысшего приоритета
(символы-нетерминалы начинаются с заглавной буквы, терминалы (лексемы) в
кавычках):

	E.d	-> «atom»

	E.c	-> B E.0 «)»
	E.c	-> B «)»		// иногда выражение «()» нужно
	B	-> «(»

«.» и parentheses apply

	E.b	-> L.b.d (E.c : E.d)	// l-основа с точкой
	E.b	-> L.b.p (E.c)		// l-основа с «@p»
	L.b.d	-> (E.b : E.d) «.»
	L.b.p	-> (E.b : E.d) «@p»

унарные «^», «-», «!»

	E.a	-> U (E.a : E.d)
	U	-> «^» | «-» | «!»

@
	E.9	-> L.9 (E.a : E.d)
	L.9	-> (E.9 : E.c) «@»

умножение

	E.8	-> L.8 (E.9 : E.d)
	L.8	-> (E.8 : E.d) «*» | «/» | «%» | «<<» | «>>» | «&»

и так далее, всё однообразно в соответствии с таблицей T.1. Операторы
«присваивания» тоже задаются похожей структурой, которая левоассоциативна, во
многих случаях семантическому анализатору нужно знать информацию о левой части
выражения с присваиванием, чтобы верно оценить всё выражение. Например:

	var R matrix =
	(
		(0;	-12.4;	18.9;	11);
		(11;	-12.5;	6;	10);
		(x+y;	exp(x);	y;	0.1)
	)

здесь, обрабатывая правую часть присваивания, необходимо знать, что следует
формировать значение типа «matrix(N;M) type» (N, M, type система должна
вывести). Для этого движок должен сначала увидеть левую часть выражения.
Поэтому, фиксируем для «присваиваний». Традиционную же семантику исполнения этих
операторов справа-налево можно обеспечить средствами семантического анализатора
LiME.

	E.1	-> L.1 (E.2 : E.d)
	L.1	-> (E.1 : E.d) «=» | «*=» | прочие «=»-символы из Т.1 | «&&=»

Наконец, особый оператор

	E.0	-> L.0 (E.1 : E.d)
	L.0	-> (E:0 : E.d) «;»

и аксиома (символ «@» означает начало разбора и конец разбора, восстанавливается
по командам F от лексического анализатора).

	S	-> «$» (E.0 : E.d) «$»

Существует теорема (в любой книге по компиляторам должна быть, я использую
уральскую книгу А.П. Замятина и А.М. Шура «Языки, грамматики,
распознаватели») которая позволяет по грамматике попробовать построить отношения
<∙, =∙, ∙>. Если получится, то распознавать исходный текст можно АЛГОРИТМОМ:

0	for(stack.top != "@" || input(ip) != "@")
1	(

2		if(stack.top <∙=∙ input(ip))
3		(
4			stack.push(input(ip));
5			ip += 1
6		)

7		else if(stack.top ∙> input(ip))
8		(

9			val st = stack.top.pos;
10			var sp = st;
11			for(stack(sp-1) =∙ stack(sp)) (sp -= 1);

12			stack.replace(st:sp; leftof(stack(sp:st)))
13		)

14		else (error())
15	)

В отличии от Алгоритма АЛГОРИТМ определяет правило, по которому следует
редуцировать выражение и выдавать команду в семантический анализатор. В
АЛГОРИТМЕ это делается не по одному символу на вершине стека, а по правой части
некоторого правила, которая разыскивается в строках (9:11). После её обнаружения
нужно выдать соответствующую команду движку, а саму правую часть правила
заменить на символ из левой.

Ок. На этом спецификацию можно окончить, потому что остальное - технические
детали, но они важные, поэтому ещё немного усилий для анализа. Кроме того, не
помешает показать, что грамматика является грамматикой предшествования.

				   8.  Анализ

8.1. Грамматика без ε-правил (ничто не превращается в пустую строчку). Это
хорошо.

8.2. Для этого нужно построить для каждого символа в грамматике множества FIRST
и LAST, и по ним сделать выводы о <∙, =∙ и ∙>. Для нетерминала X

	- FIRST(X) = {символы, с которых начинаются цепочки, выводимые из X};
	- LAST(X) = {символы, на которые оканчиваются цепочки, выводимые из X}.

Вот описание этих множеств (плюс обозначает объединение):

	FIRST(E.d)	= {«atom»}
	LAST(E.d)	= {«atom»}

	FIRST(E.c)	= {B, «(»)}
	LAST(E.c)	= {«)»}

	FIRST(B)	= {«(»}
	LAST(B)		= {«(»}

	FIRST(E.b)	= {L.b.{d,p}, E.b, E.c, E.d} + FIRST(E.c) + FIRST(E.d)
	LAST(E.b)	= {E.c, E.d} + LAST(E.c) + LAST(E.d)

	FIRST(L.b.d)	= {E.b, ..., E.d} + FIRST(E.b) + FIRST(E.d)
	LAST(L.b.d)	= {«.»}

	FIRST(L.d.p)	= {E.b, ..., E.d} + FIRST(E.b) + ... + FIRST(E.d)
	LAST(L.d.p)	= {«@p»}

	FIRST(E.a)	= {U, «^», «-», «!»}
	LAST(E.a)	= {E.a, ..., E.d} + LAST(E.b) + ... + LAST(E.d)

	FIRST(U)	= {«^», «-», «!»}
	LAST(U)		= {«^», «-», «!»}

	FIRST(E.9)	= {L.9, E.9, ..., E.d} + FIRST(E.9) + ... + FIRST(E.d)
	LAST(E.9)	= {E.a, ..., E.d} + LAST(E.a) + ... + LAST(E.d)

	FIRST(L.9)	= {E.9, ..., E.d} + FIRST(E.9) + ... + FIRST(E.d)
	LAST(L.9)	= «@»

	FIRST(E.8)	= {L.8, E.8, ..., E.d} + FIRST(E.9) + ... + FIRST(E.d)
	LAST(E.8)	= {E.9, ..., E.d} + LAST(E.9) + ... + LAST(E.d)

	FIRST(L.8)	= {E.8, ..., E.d} + FIRST(E.8) + ... + FIRST(E.d)
	LAST(L.8)	= {«*», «/», «%», «<<», «>>», «&»}

И так дальше, по тому же принципу, что и для пары (E.8; L.8).  Далее, существует
определённое рассуждение, которое говорит, что зная FIRST и LAST отношения
предшествования можно строить так:

	- X =∙ Y только в том случае (if and only if - iff), если существует
	  правило вида W -> aXYb; в частности для рассматриваемой грамматики:

	  	- никакие два терминала (лексемы), не связаны отношением =∙;

		- нетерминал E.i (i != c) и терминал t, если приоритет t p(t)
		  меньше i связаны отношением =∙ - это следует из структуры
		  правил для L.i;

		- символы B, U и L.x не связаны отношением =∙.

	- X <∙ Y iff существует такой нетерминал Z, что X =∙ Z и Y в FIRST(Z); в
	  частности:

	  	- никакие два терминала не связаны отношением <∙, потому что нет
		  правил вида

		  	W -> a «терминал» Z b

		  и хотя кое-какие терминалы попадают в FIRST для кое-каких
		  нетерминалов, это не помогает;

		- никакие E.i и t (терминал) не состоят в отношении E.i <∙ t, по
		  аналогичной причине: правил вида

		  	W -> a E.i Z b

		  не существует.

	- X ∙> Y iff существуют такие Z1, Z2 такие, что Z1 =∙ Z2, X попадает в
	  LAST(Z1) и либо Z2 = Y, либо Y в FIRST(Z2).

Указанная грамматика вообще является грамматикой простого предшествования (что
хорошо, в смысле простоты и однозначности разбора), но это отдельное
доказательство, пока не нужное.

Из указанных частностей вытекают два упоминавшихся ранее свойства, которые
позволяют оптимизировать выходные команды.

	- Если в стек попадает терминал (лексема), то на следующем шаге разбора
	  он будет свёрнут с содержимым стека и информация о нём будет выдана в
	  семантический анализатор до того, как следующий терминал попадёт в
	  стек. Потому что, если терминалы ta и tb сравнимы, то только как
	  ta ∙> tb, и это поведёт АЛГОРИТМ по ветви (7:13).

	  Поэтому все лексемы на выходе синтаксического анализатора должны
	  появляться в том же порядке, что и на выходе лексического. Это
	  позволяет сохранять в них относительные координаты, а в более
	  оптимальных версиях транслятора LiME, вообще их не указывать явно, так
	  как семантический анализатор всегда будет знать, в какой момент
	  следует обращаться к следующей по порядку лексеме.

	- Если на вершине стека формируется E.i, то такой нетерминал будет при
	  анализе двух последующих терминалов t1, t2 на входе сканера, либо
	  свёрнут с t1 при переходе к t2, либо свёрнут с предыдущим содержимым
	  стека при просмотре t1. Это потому что, либо E.i =∙ t1, тогда E.i
	  будет свёрнут с t1 (7:13). Либо E.i ∙> t1, тогда E.i будет свёрнут с
	  содержимым стека. В других отношения E.i и t1 быть не могут.

	  Поэтому, если E.i появляется на вершине стека и соответствующая
	  команда выдаётся семантическому анализатору, то следующая команда
	  свёртки будет ссылаться на это предыдущее E.i.

	  Это позволяет убрать ссылки вида «e.номер» из входного языка
	  семантического анализатора. Это важно, потому что в часто
	  встречающихся ситуациях, движок LiME должен будет записывать
	  синтаксические деревья (в виде последовательности команд) для
	  последующего их воспроизведения. И чем экономнее будет их запись, тем
	  лучше.

	- Дополнительно, можно заметить, что символы B, U и L.x сворачиваются
	  всегда по одному (нет правил, содержащих их вместе). И в свёртке
	  всегда участвует символ, расположенный ближе всего к вершине стека.
	  Поэтому ссылки вида {b,u,l}.«номер» также не нужны в инструкциях,
	  воспринимаемых движком (ядром) LiME.

	  Если ввести понятие «последняя закрытая {B,U,L}-инструкция (команда)»,
	  то есть, инструкция, на которую уже встретилась ссылка в одной из
	  последующих E-команд (что соответствует свёртке соответствующего
	  символа (B, U или L.x) на вершине стека в подвыражение, то
	  {b,u,l}-ссылка всегда будет ссылаться на последнюю из открытых
	  {B,U,L}-команд. За открытием-закрытием (подобно скобкам) ядро может
	  следить при помощи стека, поэтому номера в самих инструкциях не нужны.

	  Все {B,U,L}-инструкции можно заталкивать в один стек при их открытии
	  (обнаружении в потоке команд), и выталкивать с вершины при закрытии,
	  когда встречается команда с {b,u,l}-ссылкой. Если всё корректно, то на
	  вершине этого стека должна быть информация об инструкции
	  соответствующего ссылке типа.

			       9.  Оптимальный IO

По этому всему, в интерфейсе между парсером и движком можно использовать такие
команды:

	- атомы
		E a lex

	- l-основа
		L lex			- подразумевается ссылка на e.1
	- бинарный
		E l			- подразумевается ссылка на e.1 и на
					  последнюю открытую L-инструкцию

	- унарный оператор
		U lex			- введение оператора;
		E u			- применение, подразумевается e.1 и
					  последняя открытая U-инструкция.

	- открытие нового блока
		B lex
	- закрытие :
		E b lex			- подразумевается e.1 и ссылка на
					  последнюю открытую B-инструкцию, то
					  есть, скобку.

Ух! Оптимизация средствами математики свершилась. Пример П.2 должен с этими
уточнениями переводится в такую последовательность инструкций:

	F 12."./somesrc.lm"

	E a		N.1 0.0 41 1.3."var"
	L		N.2 0.4 38 "@p"

	B		N.3 0.0 39 "("
	E a		N.4 0.1 41 1.1."x"
	L		N.5 0.1  0 ";"
	E a		N.6 0.2 41 1.1."y"
	E l
	E b		N.7 0.1 40 ")"

	E l

	L		N.8 0.2 34 "@"
	E a		N.9 0.0 41 1.3."int"
	E l

	L 		N.10 0.4 1 "="

	B		E.3  0.2 "("
	E a		N.11 0.1 41 6.1."3"
	L 		N.12 0.1 29 "*"
	E a		N.13 0.1 41 6.1."4"
	E l
	E b		0.1 E.7 ")"

	E l

Отсутствие номеров должно упростить структуру frontend-а для C99 и повысить
эффективность использования памяти: номера не избавляли бы от необходимости
запоминать команды.

						 СЕМАНТИЧЕСКИЙ АНАЛИЗАТОР (ЯДРО)

Ладно. Надо начинать в любом случае. Итак, про семантику рассказ будет в том же
стиле, что и синтаксис: сначала неформальное описание алгоритмов с главным
акцентом на причины предлагаемых решений. А потом будет приведено формальное
описание денотационной и операторной семантики (если понадобится). Некоторые
моменты ещё до конца не ясны, они отмечены как (Q: ...). Предложения
приветствуются.

				  1.  Введение

Задачей ядра является построение простого (и, можно сказать, традиционного, на
что есть свои математические причины) для последующего перевода в машинный код
(в частности, в код процессоров MCp) представления программы в списка триад.
Структура этих триад в LiME наследуется от промежуточного представления кода в
системе LCC. LCC - популярная основа для большого числа Си-компиляторов для
процессоров разнообразных архитектур, что указывает на разумность внутреннего
представления программ, применяемых в этой системе.

Кроме того, эта форма очень близка к классическому SSA-представлению программ,
за исключением того, что позволяет явно размечать код метками и вместо, так
называемых, φ-узлов (http://llvm.org/docs/LangRef.html#i-phi) использовать
инструкции перехода.

Для LiME это удобно тем, что потенциально позволяет программировать различные
конструкции с передачей управления. φ-узлы отличаются тем, что в них необходимо
полностью описывать «проходящие» через ветвление значения. А этой информации у
программиста на этапе реализации конструкций может и не быть. Так «for»
может быть реализован в виде (примерно):

	for(init exp; cond exp; next exp) (body exp).

Когда эти выражения будут связываться одно с другим, очень сложно выразить,
какой поток данных должен идти между итерациями от «body» к следующему «body».
Это можно сделать только рассматривая конкретную реализацию всех четырёх
выражений. Поэтому для описания «for» в общей форме удобнее использовать
конструкции перехода по меткам, а φ-узлы (если потребуется; скорее всего,
потребуется) восстанавливать уже на этапе оптимизации и генерации кода.

Итак, внутреннее представление близко к более простому (так уж получилось, что
многие знают о llvm, поэтому приходится с ним сравнивать) по сравнению с языком
llvm представлению в виде триад из LCC. Дополнительную простоту представлению в
LCC обеспечивает, например, наличие отдельных узлов для констант. Конечно, опыт
llvm мы тоже пытаемся учесть в LiME.

LiME получает информацию о структуре выражений от различных frontend-ов в виде
последовательности, описанной в (парсер: 9). По каждой такой инструкции, ядро
должно в своих таблицах найти реализацию трансформации реализаций выражений,
которые в этой инструкции подразумеваются в реализацию нового выражения. Поиск
осуществляется на основе типов, обрабатываемых выражений.

Пока не будет найдено лучшее название, соответствующие синтаксическим
выражениям, которые заданы на входном (выходном для парсера) языке ядра LiME,
значения будем называть k-выражения (от kernel). Если говорить строго формально
в рамках текущего положения дел в учении о семантике языков программирования,
изложенному в книге издательства MIT:

	Design Concepts in Programming Languages (2008)

то k-выражения являются λ-абстракциями функций, с областью определений в домене
Store (не думал, что когда-нибудь напишу такое). K-Выражение может выглядеть
так:

	k.link		la = sym.123;	// ссылки на таблицу символов
	k.link		lb = sym.456;
	addr.4p		pa = la;
	addr.4p		pb = lb;
	rd.4u		a = pa;
	rd.4u		b = pb;
	add.4u		t = a : b;	// «:» - разделитель половинок
	k.link		la1 = sym.123;
	addr.4p		pa1 = la1;
	rd.4u		a1 = pa1;
	mul.4u		u = t : a1;
	k.pin		u;		// «контакт» выражения

для исходного выражения:

	(a + b) * a

указанное k-выражение не оптимизировано. Некоторые коментарии:

	- Формат подобран так, чтобы читать текстовое представление этих
	  инструкций было просто при помощи scanf (пока не решается задача о
	  скорости компиляции; справится бы с самим фактом) варианта C99.

	  прочитать сначала команду по буквам ("%[a-z]"), потом разобрать
	  суффикс ("%c%c"), потом символ до = ("%[a-zA-Z0-9]") и т.д.

	- Все символы в выражениях - это просто ссылки. Перед «=» должно стоять
	  всегда новый символ, после «=» нечто уже объявленное ранее. Это просто
	  метки, не имеющие смысла. Семантика описывается самой структурой,
	  получающегося графа (или λ-выражения, какой кому больше термин
	  нравится).

	  Загрузка такого представления программы должна сводится к (примерно,
	  без особых случаев):

	  	- чтению мнемоники и формированию кода инструкции в новом узле;

		- чтению метки перед «=» и проверкой, что такой метки в текущем
		  участке кода ещё не было;

		- регистрации метки в каком-нибудь ассоциативном массиве со
		  ссылкой на созданный узел;

		- поиск в этом массиве ссылок на узлы с метками, стоящими после
		  «=», и заполнение ими полей kids[0] и kids[1] в созданном
		  узле.

	- K-Выражение - это граф, поэтому и вывод его прост. Нужно идти по
	  списку узлов (нужен какой-то порядок поэтому между узлами в виде
	  списка или массива), каждому назначать метку и печатать её до «=», а
	  потом по ссылкам на другие узлы определять то, что напечатать после
	  «=». Если всё корректно узлы уже должны быть поименованы.

	- Некоторые мнемоники описывают инструкции для самого ядра, и не должны
	  выдаваться кодогенератору: link, pin, ...

			   1.1.  Введение.  Ветвления

K-Выражения похожи на SSA-выражения своей формой. SSA - это single static
assignment - то есть такая форма, в которой значение каждой переменной
назначается один раз и не меняется. Под переменными подразумеваются переменные
SSA-формы, а не переменные программы, которая в эту форму переводится. В
принципе, да, k-выражения похожи на SSA.

В SSA для описания ветвлений используются, так называемые, phi-узлы. Надо
сказать, что источником практической мудрости по SSA-выражениям для меня служит
описание языка LLVM:

	http://llvm.org/docs/LangRef.html

phi-узлы отмечают точки входа в некоторый линейный участок из нескольких других,
из которых на эту точку передаётся управление. phi-узел при этом «знает» откуда
было передано управление, и для каждого такого варианта выбирает определённую
связь переменных в целевом линейном участке с переменными в исходном линейном
участке, где расположена инструкция «br», передающая на phi-узел управление.
Идея очень похожа, кстати, на под-параграфы Мультиклета, и мы тоже должны будет
проводить такой анализа.

Такое поведение соответствует SSA-стилю, когда переменным присваивается
однократно в ходе линейного исполнения. Можно выразить вычисление, не используя обращения к памяти.

Однако, добавить phi-узлы общего вида в k-выражения не получится (Q: это, может
быть и возможно, но я сейчас не знаю, как это сделать). Причина в том, что (об
этом будет рассказано ниже) семантика синтаксических выражений LiME должна, как
предлагается, выражаться через их связь с k-выражениями.

Проблему можно показать на примере задания семантики для оператора «for». В этом
случае возникает вопрос: как в общем виде получать списки переменных для
связывания в целевых и исходных линейных участках при задании ветвлений
(которые, естественно, являются необходимым элементом «for» в семантике C).
Ведь, тот же «for» ограничен только информацией о выражениях своего тела и
условий итерации. Не понятно, как выход из цикла на корректный phi-узел; потому
что phi-узел должен быть сформирован в рамках анализа «for»; в котором ещё
ничего не известно о следующем за ним линейном участке.

Если сделать эти все рассуждения явно функциональными, то получится нечто такое
(я не пишу все стрелки):

	for (Exp; Exp; Exp) Exp Store -> Store
	for (iexp; cexp; nexp) body state = loop (cexp; nexp) body (iexp state)

	loop (Exp; Exp) Exp Store -> Store
	loop (cexp; nexp) body state
		= if (cexp.val state)
			then loop (cexp; nexp) body (nexp (body (cexp state)))
			else cexp state

Вот. Примерно так (может, несколько наивно, но близко к модели с ячейками
памяти). Несколько замечаний:

	- всё же k-выражения хочется сделать более близкими к модели ячеек
	  памяти, а не к вычислениям с трэдингом (threading) или с монадами;
	  операции с памятью лучше подходят для описания сложных вычислений
	  из-за возможности легко и однообразно создавать далёкие зависимости по
	  данным в коде (уточнение вида зависимостей можно оставить
	  компилятору; теоретически, ему же можно оставить и преобразование кода
	  в некую threading-версию, которая может быть удобнее для оптимизаций);

	  ух, я извиняюсь за технические термины, но за ними ничего сложного не
	  стоит, и они все хорошо изложены в книге, на которую я ссылаюсь;

	- явное введение состояния в семантику программы оправдано тем, что в
	  итоге придётся переходить к программированию в распределённых
	  системах, где могут эволюционировать несколько состояний одновременно;
	  такая семантика - подготовка к внедрению RiDE.

Из этого видно: раз детали о выражениях не известны (Q: есть ли другие
варианты?), то надо предполагать, что каждое выражение связано со всем текущим
состоянием системы, а не только с какими-то конкретными переменными. Поэтому при
программировании перехода (аналог хвостового вызова функции) в k-выражениях, с
учётом особенности их предназначения, нужно подразумевать переход на некий
phi-узел, в котором все переменные в некой модели хранилища (которая может быть
SSA: например, операции записи можно рассматривать как создание нового
содержимого памяти из старого, см. формализм абстрактных машин состояний; и в
которую НЕ входят метки узлов, связывающие k-выражение в единое целое)
тождественно отображаются на список переменных в целевом «линейном» k-выражении.

Замечание:

	- кстати, сама модель вычислений MCp очень похожа на то, что есть в этих
	  самых Abstract State Machines Гуревича. Это может быть полезно для PR;

	- кстати, ядро LiME тоже можно считать вариантом такой машины.

Таким образом, для описания ветвлений в языке k-выражений нужно два вида
конструкций:

	- метки, для указания цели перехода, которые подразумевают, что после
	  них сразу же стоит phi-узел, с тождественным отображением переменных:

		mark	m.x;

	  имеет смысл иметь именно такое текстовое представление метки, чтобы
	  анализ потока инструкций был однообразным;

	- конструкции ветвления:

		br	C : m.x;	// по какому-нибудь условию C
		brl	m.t : m.l;	// переход со связью (это сall)

	- ветвления могут понадобится и для описания некоторых внутренних
	  конструкций, поэтому могут понадобится «ядерные» варианты ветвлений:

		k.br
		k.brl

Замечание:

	- Имя с точкой означает, что метки принадлежат некому классу в
	  некоторой конфигурации программы, которую я тут называю Store.

	- Достаточно иметь только условное ветвление (Q: экономия на копейках?).
	  Система может заранее формировать две константы: 0 и 1 для обозначения
	  false и true. И тогда условный переход может быть закодирован так:

	  	cnst1b	t = c.true;
		br	t : m.x;

Обработка меток. Метки - особые сущности, со следующими правилами обработки.

	- Если встречается mark предыдущую систему связей между узлами нужно
	  сбрасывать.

	- Если встречается br, то предыдущую систему связий так же нужно
	  сбрасывать.

	- При встрече mark соответствующую метку нужно заносить в специальную
	  структуру под именем, стоящим после «l.» (имя должно быть атомом); при
	  этом:

	  	- в структуре под этим именем могут быть известны br, которые
		  ссылаются на эту метку; нужно соответствующую запись в
		  структуре с метками пометить как разрешённую.

	- При встрече br или brl в структуру надо занести соответствующую запись
	  о метке, не помечая её, как разрешённую.

	- Когда выражение прочитано, это ошибка иметь метки, которые не
	  помечены, как разрешённые.

	- Когда выражение прочитано, имена меток, указанные при помощи «mark»,
	  должны быть забыты, и на последующую обработку выражение может быть
	  отправлено с заменой всех имён меток на указатели на определённую
	  струкруту с метками.

	- При повторном выводе k-выражения с метками в виде текста, метки могут
	  получить последовательную нумерацию.

Некоторые метки необходимо именовать (цели goto, имена функций и т.д.). Для
этого, их надо помещать в пространство символов. Как-нибудь так:

	mark	m.1;
	link	sym.123 = m.1;


		       1.2 Введение. Соответствие с LCC.

Полезно попробовать описать набор потенциальных узлов LiME, которыми
предполагается кодировать семантику функций.

Результаты работы волшебной команды

	./ops c=1 s=4 i=4 l=4 h=4 f=4 d=4 x=4 p=4

с комментариями. Сначала о результате продолжительных измышлений. Не получится
обойтись не более, чем двумя параметрами - ссылками на другие узлы. Нужна
параметризация и ссылкой на тип. Для арифметических операций это не особо важно,
но есть ещё конструкции для работы с составными типами: cnst, соответствующие
ARGB, INDIRB, ASGNB (работа с составными типами данных). Возможно, в будущем
этот же механизм потребуется и для работы с шаблонами в Си++ или
высокоуровневыми типами или функциями (higher order types, functions).

Поэтому теперь предполагается, что узел (по максимуму) имеет такую конфигурацию:

	code.t x = y : z

где t, y, z - ссылки на другие узлы. При чём t должна быть ссылкой на
какой-нибудь тип, который конструируется при помощи конструктора типа (не путать
с конструкторами C++; конструктор типа - это нечто вроде списка: «hash» string
long, где «hash» - атом, string и long - ссылки на другие типы; это нужно для
сопоставления уникальным способом синтаксических выражений и типов в таблице; по
конструкторам можно осуществлять поиск по этой самой таблице; ну и ещё кое-что
делать, в текущем контексте не важное).

Так. Что ещё? Ещё нам понадобятся списки. Чтобы сосредоточить все
неравномерности и неоднородности относительно разбора узлов (штук вида code.t x
= y : z) в одном месте, предлагается этим местом назначить любимый узел link.
Который и так достаточно неоднороден, ибо должен уметь в dag вычисления
вставлять ссылки на объекты, отличающиеся от узлов:

	A.x - на атом с номером x;
	C.x - на константу в таблице констант с номером x;
	S.x - на символ в таблице символов с номером x;
	T.x - на тип с номером x в соответствующей таблице;
	L.x - ссылка на метку в таблице меток.

Во время работы ядра, link должен уметь связываться с подвыражениями, которые
служат основами для конструирования более сложного выражения на основании этих
подвыражений и некоторого оператора. Это формат

	R.x - ссылка на подставленный в процессе сопоставления с образцом
	операнд оператора (вообще, в литературе эти штуки называют рандами и
	раторами, поэтому и R).

Это всё унарные формы link. Бинарную форму link можно использовать как
раз для составления списков.

	link	a = A.1;	// допустим, это ссылка на атом «list»
	link	b = T.10;	// допустим, это ссылка на тип int
	link	c = a : b;	// список из двух элементов. Это может
				// быть хорошо согласовано, потому что a
				// и b можно считать списками из одного
				// элемента. link строит списки.

Так. Вооружившись этим, переходим к описанию соответствия
LiME и LCC-конструкций.

1.	CNSTF4=4113
	CNSTI1=1045 CNSTI4=4117
	CNSTP4=4119
	CNSTU1=1046 CNSTU4=4118

	Эти конструкции нужно выводить из такого представления:

	link	c = C.x;

	x - это номер константы в таблице констант.

	В таблицу констант константы попадают в процессе обработки таких
	цепочек:

	link	t = T.x
	link	a = A.y;
	link	r = a : tail;	// tail - это какой-то дополнительно
				// накопленный хвост списка
	cnst.T	C.z = r;

	x, y - это номера в таблицах констант и атомов, соответственно.
	T - это атом, описывающий ссылку в таблицу типов (4i, 4f и т.д.
	В общем случае, может быть нечто более сложное: struct28x)

	list - конструкция, которая составляет список из элементов (нам
	потребуется составлять списки из нескольких видов значений: типов,
	атомов, некоторых инструкций. Списки должны быть типизированными: в
	списке атомов не должно быть типов и т.д.). В данном случае она должна
	составлять текстовое представление константы из атомов. Список будет
	длиннее одного элемента пока только в случае константы с типом F,
	константа будет представлена в виде списка: «целая часть» «дробная»
	«экспонента».

	Но стоит помнить, что константы бывают и сложные: структуры, массивы. В
	этих случаях без списков значений не обойтись.

	Это достаточно легко потом собрать в константу, завести новый атом под
	это дело, или ещё что-то сотворить. В таблице констант будет ссылка на
	тип константы, по которому можно будет восстановить суффикс операции.

2.	ARGB=41
	ARGF4=4129
	ARGI4=4133
	ARGP4=4135
	ARGU4=4134

	С ARGB пока не понятно, это оставим до работ над сложными типами данных.
	ARGB в LCC используется для указания аргумента-структуры. Остальные
	конструкции будут выражаться конструкцией:

	arg.T	a = prevargs : val
	arg.T	a = val

	T	- это ссылка на тип (не обязательно чисто числовая);
	val	- значение, которое следует сделать следующим аргументом
		  функции;
	arglist - предыдущий накопленный список аргументов (опыт работы
		  над LCC говорит о том, что неплохо иметь именно
		  список);
	a	- это ссылка на текущий узел arg, но так как у него есть
		  в kids[0] ссылка на предыдущий arg, то это как раз и
		  получается ссылка на список.

	Пример:

	link	f = C.1;
	link	i = C.2;
	arg.4f	a = f;
	arg.4i	b = a : i

	Да, тут тоже будет неоднородность в кодировании инструкции. Можно было
	бы, конечно, предусмотреть какой-нибудь null, как указатель на пустой
	список. Но если думать дальше, о двоичном представлении всех этих узлов,
	то возникнет вопрос: а что такое null и как его закодировать? Это
	специальный атом? Или это ноль?  Сложно. Иметь же просто два разных вида
	инструкции (два разных двоичных op-кода для разного формата) кажется
	более простым решением.

3.	ASGNB=57
	ASGNF4=4145
	ASGNI1=1077 ASGNI4=4149
	ASGNP4=4151
	ASGNU1=1078 ASGNU4=4150

	ASGNB пока оставляем в стороне. Для остального код такой:

	wr.T	addr : val

	Штука ничего не возвращает.

4.	INDIRB=73
	INDIRF4=4161
	INDIRI1=1093 INDIRI4=4165
	INDIRP4=4167
	INDIRU1=1094 INDIRU4=4166

	INDIRB пока в стороне. Для остального:

	rd.T	x = addr

5.	CVFF4=4209
	CVFI4=4213

	CVIF4=4225
	CVII1=1157 CVII4=4229
	CVIU1=1158 CVIU4=4230

	CVPU4=4246

	CVUI1=1205 CVUI4=4277
	CVUP4=4279
	CVUU1=1206 CVUU4=4278

	Эти операции должны быть параметризованы двумя типами.

	link	T = T.x;
	link	t = T.y;
	cv.T	x = u : val	// вполне допустимо и однозначно: T без
				// «.» - это ссылка на узел; T. -
				// префикс для поиска в таблице типов.

	Преобразование из типа T в t, оба берутся из таблицы типов.

6.	NEGF4=4289
	NEGI4=4293

	neg.T	x = y

	На самом деле MCp не умеет такую операцию выполнять, но у него есть
	замечательная инструкция insub, которая используется в данном случае.
	Это чуть более эффективно, чем если бы мы заменили neg на:

	link z = C.0;	// ссылка на константу с нулём
	sub.T	x = y : z;


7.	CALLB=217
	CALLF4=4305
	CALLI4=4309
	CALLP4=4311
	CALLU4=4310
	CALLV=216

	Актуальной будет только инструкция CALLV. LCC вставляет CALLx
	(для других x) прямо в граф (dag) выражения, а MCp так не умеет.
	CALL обязательно должен идти отдельным параграфом. Поэтому
	сейчас CALLx пилиятся на пары параграфов, один с CALLV, другой с
	чтением возвращаемого значения из специального символа,
	связанного с адресом (#SP,4), по которому записывается
	возвращаемое значение.

	Нам это не нужно, и это будет сделано всё явно на другом уровне
	трансляции исходника в промежуточное представление. Всегда нужно будет
	генерировать CALLV.

	Генерировать будет необходимо по таким узлам:

	brl	targets;		// branch with link
	brl	args : targets;

	На самом деле вызов функции - это ветвление с сохранением в кадре
	вызываемой функции тем или иным способом (на ARM через регистр,
	например) адреса возврата. Обычно, этот адрес - адрес следующей
	инструкции. Но в MCp - это адрес параграфа, и не обязательно следующего.
	И его надо указывать явно. Поэтому:

		- targets - это список из двух значений: адрес целевой
		  функции и адрес возврата, который надо записать в
		  стека;

		- args - список аргументов.

	LCC (как и GCC или LLVM) нас не поймёт. И ему всегда нужно будет просто
	сказать CALLV с определённым адресом точки входа в функцию.

	Но на уровне трансляции Си в наше промежуточное представление нам
	понадобится именно такой формат. Для последующих оптимизаций понадобится
	иметь ссылку на список аргументов, а не просто считать, что brl
	происходит только с цепочкой ранее встретившихся аргументов,
	обозначенных узлами arg.T.

	Поэтому так (если кто-то предложит более элегантный метод, буду только
	лишь рад этому).

	Здесь опять две инструкции для удобства кодируются однообразно.  Пример:

	link	4i = T.1;
	arg.4i	a = v1;
	arg.4i	b = a : v2;

	link	fn = S.1234;	// символ, связанный меткой кода функции
	addr	fa = fn;	// адрес этой метки
	link	ra = L.1;	// метка адреса возврата, которая уже
				// адрес
	link	ts = fa : ra;
	brl	b : ra

	label	L.1;

8.	RETF4=4337
	RETI4=4341
	RETP4=4343
	RETU4=4342
	RETV=248

	Не понадобится. Ядро будет генерировать явный код записи возвращаемого
	значения по специальному символу, и явный переход на эпилог функции,
	который будет пробрасывать вычисление дальше, в соответствии с targets.

9.	ADDRGP4=4359

	ADDRFP4=4375

	ADDRLP4=4391

	Информация об области видимости символа у нас будет записана в самом
	символе. Адрес всегда имеет один и тот же тип - указатель.  Можно
	считать, что он будет всегда записан в таблицу под именем T.ptr.
	Поэтому, просто будет конструкция:

	addr	a = s;	// s должен быть через link настроен на
			// некоторой символ.

10.	ADDF4=4401
	ADDI4=4405
	ADDP4=4407
	ADDU4=4406

	Это элементарно.

	add.T x = y : z;

11.	SUBF4=4417
	SUBI4=4421
	SUBP4=4423
	SUBU4=4422

	Элементарно

	sub.T x = y : z;

12.	LSHI4=4437
	LSHU4=4438

	Элементарно

	lsh.T x = y : z;

13.	MODI4=4453
	MODU4=4454

	Модель процессора, для которой мы работаем, не умеет делить
	целочисленно. Деление и остаток берутся через вызов внешней функции, для
	чего mcp.c производит трансформацию дерева. Но логичнее просто
	генерировать нужный dag на уровне front-end-а C и ядра LiME. Это и будет
	сделано. Ничего транслировать в MODx не нужно.

14.	RSHI4=4469
	RSHU4=4470

	BANDI4=4485
	BANDU4=4486

	BORI4=4517
	BORU4=4518

	BXORI4=4533
	BXORU4=4534

	Элементарно

	rsh.T x = y : z;
	and.T x = y : z;
	or.T x = y : z;
	xor.T x = y : z

15.	BCOMI4=4501
	BCOMU4=4502

	Это операция инверсии битов - «~» в Си.

	not.T x = y : z

16.	DIVF4=4545

	Элементарно

	div.T x = y : z;

17.	DIVI4=4549
	DIVU4=4550

	Как и MOD это нужно делать через вызов процедуры. Этот вызов будет
	сгенерирован в ядре по информации от фронтенда Си. Ничего в эти DIVx
	переводить не надо.

18.	MULF4=4561
	MULI4=4565
	MULU4=4566

	Элементарно

	mul.T x = y : z;

19.	EQF4=4577
	EQI4=4581
	EQU4=4582

	GEF4=4593
	GEI4=4597
	GEU4=4598

	GTF4=4609
	GTI4=4613
	GTU4=4614

	LEF4=4625
	LEI4=4629
	LEU4=4630

	LTF4=4641
	LTI4=4645
	LTU4=4646

	NEF4=4657
	NEI4=4661
	NEU4=4662

	Это операции условного ветвления. В них нужно будет превращать такие
	конструкции (они выбраны с учётом требований последующей оптимизации).

	{eq, ge, gt, le, lt, ne}.T	r = x : y;	// сравнение
	br				r : target;	// условный
							// переход

	target - это адрес перехода (либо ссылка на L.n, либо нечто вычисляемое
	в процессе вычисления, в отличии от brl тут только одна цель).

	Обработка этой конструкции должна быть примерно такой: смотрим по
	таблице на первую ссылку в br, и по коду операции, сохранённому в узле,
	генерируем соответствующий CCx.

	Когда мы будем переписывать mcp.c, или сразу писать генератор из LiME в
	ассемблер, всё будет проще.

19.	JUMPV=584

	Немного не элементарно, потому что это другая инструкция с той же
	мнемоникой (для удобства программиста), что и br. При чтении нужно будет
	проверять число аргументов.

	br target

20.	LABELV=600

	Это нужно будет генерировать по конструкции

	label	L.x

	Ранее, в спецификации это называлось mark. Но что-то мне сложно
	разрушить даже в самом себе существующую традицию именования разных штук
	в программировании. Метка - это label.


	     2 Алгоритм.  Почему не один из классических подходов?

Так. Теперь возникает вопрос о том, как переводить поток синтаксических
выражений в некие цепочки (или деревья) кода. Есть пара классических подходов к
преобразованию синтаксических деревьев или там выражений в синтаксической
алгебры в программы.

	   2.1 Алгоритм.  Почему не классика.  Почему не Dragon Book

Первый классический способ (книга Ахо, Ульмана, Сети и Лэм «Компиляторы»), когда
строится AST (синтаксическое дерево), а потом снизу вверх по нему собирается
некое выражение, описывающее результирующую программу. Если необходимо построить
инструмент для описания разнообразных языков программирования, этот метод не
особо хорош.

Потому что:

	- AST фиксированы для каждой конкретной грамматики. В принципе, это
	  не так уж и страшно. Любое такое дерево можно было бы переводить в
	  s-выражение, и уже работать с ним.

	- В каждом узле AST нужно осуществлять сложный анализ вариантов.
	  Допустим, обрабатывается узел + и нужно во время этой обработки
	  анализировать большое число сочетаний разных типов значений, которые
	  могут быть связаны этим +. Не понятно, в какой универсальной форме
	  можно описывать такой анализ.

	  Конечно. Для каждого конкретного языка этот анализ может быть
	  запрограммирован отдельно. Но даже в отдельном языке количество
	  вариантов может быть очень большим. Возьмём С++ с перегрузкой
	  операторов или даже Си, с довольно большим количеством базовых типов и
	  нетривиальными правилами их продвижения (type promotion).

	  Но даже если такой анализ написать, то он окажется бесполезным в
	  контексте другого языка. При том, что, допустим double или float
	  арифметика, что в Fortran, что в C одинаковая.

Даже на примере LCC получается громоздко. А потом для разных языков придётся
писать свой обход дерева разбора, что довольно трудоёмко, не модульно и, в
общем, нет никакого желания это делать. Если делать, то получится GCC или LLVM.
Объёмы кода этих систем можно оценить и понять, что это практически неподъёмно
для небольших коллективов.

	   2.2 Алгоритм.  Почему не классика.  Почему не SCIP и DCPL

Здесь я буду многословен и сумбурен, потому что у меня плохо развита интуиция
относительно функциональных языков программирования. Каких-то вещей я могу не
понимать. Если что, ОБЯЗАТЕЛЬНО меня поправляйте.

Второй классический способ (книга Турбака, Гиффорда и Шелдона «DCPL»). Это когда
определяется синтаксическая алгебра языка (фактически, структура AST дерева) и
определяются функции, которые выражения в этой алгебре отображают на выражения в
целевом языке. Функции при этом описываются на каком-нибудь языке с
lambda-абстракциями и структурным сопоставлением (pattern matching).

Последний нужен, в основном, для деконструкции типов (или доменов, которые тоже
типы). Это важно, потому что когда возникает некоторое значение, чтобы обобщить
какой-то разбор вариантов. Бывают суммы типов. Например:

	Expression = Int + Float + Double

И когда в анализе встречается Expression, то возможен разбор вариантов по такой
схеме сопоставления:

	match (e Expression) (
		(Int >-> Expression) i = analyzeint(i);
		(Float >-> Expression) f = analyzefloat(f);
		...
	)

Domain -> SumDomain обозначает вложение типа. Ну, а разбор вариантов понятен.
Когда Expression - это вложенный Int, то делаем одно, когда Float - другое.

Такой подход кажется более гибким, чем первый, потому что можно понаписать
полиморфных функций (когда реализация зависит от типа), которые бы срабатывали
по-разному в зависимости от анализируемого участка AST-дерева (или, другими
словами, синтаксического дерева). Но проблема в том, что не получается, потому
что нельзя у функции перепрограммировать match.

Кроме того, этот match сложная по семантике конструкция, для которой нужен
сложный синтаксис. Да и семантика у неё непростая, например, нужно иметь
автоматическое связывание именованных переменных с элементами структуры
разбираемого домена. На примитивном (для упрощения последующих стадий
оптимизации и генерации кода) языке k-выражений такое описывать очень сложно:
нужно кроме конструкторов типов (что прямолинейно и просто) учиться описывать
деконструкторы (что обратно, и требует некой процедуры, именуемой унификация).
При чём для этой процедуры нужно подготовить некую структуру данных, в которой
были бы элементы-переменные, с котором нужно связывать значения. И это сложно.

А после унификации, нужно ещё иметь механизм, который позволит по найденному
значению с определённым типом вызывать полиморфную функцию (но это, кажется,
не сложно, собственно, эта возможность и привлекала в этом подходе).

Но самая большая проблема в подходе - это, конечно же match-и внутри функций,
которые должны быть достаточно универсальными, чтобы работать на всевозможных
комбинациях аргументов. А для этого надо явно вводить дополнительные типы,
например, какие-нибудь UIntVal = UChar + UInt, а потом разбирать и их в
длинных-длинных цепочках сопоставления.

Чуть менее проблема, но проблема ещё в том, что тип полиморфной функции
обрабатывающей некую комбинацию из текущего накопленного значения,
соответствующего переведённому коду и из цепочки ещё необработанных
синтаксических выражений, должен быть определён заранее. А это означает, что мы
должны предусмотреть все возможные в разборе типы наперёд. Но что в таком случае
делать со структурами и массивами Си? Скорее всего, их нужно кодировать
алгебраическими типами, но работа с алгебраическими типами - это дополнительные
сложности.

Наверное, человек с богатым опытом программирования на Haskell мог бы изящно
решить эти проблемы. Но я не вижу изящного решения. Не понятно, как можно
определить некую функцию с сигнатурой:

	translate: SyntaxNode* -> IntermediateCode

Таким образом, чтобы сопоставления и выбор семантики по образцу можно было
сделать достаточно динамическими. Фактически, если поступать так, то
промежуточный код, которым оперирует ядро LiME должен представлять полноценный
функциональный язык программирования с очень навроченной системой типов. И на
нём пришлось бы написать просто в другом виде функцию обхода по синтаксическому
дереву. Со всеми вытекающими сложностями в виде:

	- Это только один язык программирования. Повторно использовать
	  конструкции не получится.

	- Придётся описывать сложную систему типов и длинные (длинные - это в
	  ширину, или глубокие) цепочки сопоставления типов.

	- А в итоге всё выльется в тот же самый метод обхода AST из первого
	  метода. Можно просто написать на Haskell. Но с этого будут получены
	  всё те же недостатки метода 1:

	  	- негибкость;
		- большой объём кода;

		- непонятно, как вводить новые типы; перегрузка операторов в том
		  стиле, как это делается в C++ - это сложно в такой системе:
		  	- нужны какие-то универсальные типы, которые выражают
			  другие универсальные типы (или как?).

		- предыдущее можно переформулировать так: строитель
		  результирующего промежуточного кода, созданный по такой
		  технологии, не может быть самомодифицирующейся программой, а
		  этого хочется, особенно, когда дело дойдёт до желания вводить
		  в транслируемом языке новые типы данных;

		- на самом деле функциональные языки -- это суровая Гарвардская
		  школа с процессорами гарвардской архитектуры, когда код -- это
		  не данные. Или, точнее, данные -- это не код. И функция по их
		  суровым true-представлениям -- это не динамическая сущность, а
		  некая фиксированная точка, являющаяся решением определённого
		  уравнения. То есть, транслятор не может быть
		  самонастраивающимся. Это минус, потому что сложно выразить
		  порождение новых типов в такой системе. Я не понимаю, как это
		  сделать. В том же DCPL работа с типами вынесена на специальную
		  подсистему, оперирующую правилами вывода типов, отдельную от
		  синтаксического ядра языка.

	- Будет три алгоритма вывода того, что следует делать дальше:

		- вызов полиморфной функции;
		- унификация и связывание переменных в процессе сопоставления
		  вариантов;
		- вывод типов.

	- Никакой научной новизны. А хочется.

В общем, хочется как-то упростить всё.

		  2.3 Алгоритм.  Потоковый подход.  Философия

Можно попробовать переформулировать задачу. Вместо того, чтобы рассматривать
трансляцию, как перевод AST в целевой промежуточный язык, то есть, рассматривать
процедуру трансляции как математическую функцию, можно рассмотреть её как
процесс вывода снизу вверх целевого промежуточного представления по событиям,
которые представляет цепочка синтаксических операций.

Каждое событие вносит новую информацию, из которой выводится продолжение
выражения и новое окружение для следующего этапа вывода. Получается такой поток
вывода, похожий на системы с потоками данных. Только вместо новых данных у нас
новые синтаксические конструкции и возникающие новые элементы в цепочке
построения промежуточного представления (семантики) программы.

Так. С одной стороны. Этот процесс может напоминать синтаксически-управляемую
трансляцию по аннотированной грамматике с восходящим разбором. Если исходить из
такой интуиции, то возникают такие вопросы, связанные с тем, чем должен быть
LiME:

	- Как описать этот процесс без явной спецификации грамматики и
	  аннотацией к ней, чтобы механизм был универсальный и подходил для
	  front-end-ов разных языков? Чтобы front-end-ы оставались максимально
	  простыми в разработке. И чтобы в ядро LiME не приходилось передавать
	  сложную информацию о часто сложных грамматических конструкциях.

	- Как сделать это описание выразимым на примитивном языке промежуточного
	  кода LiME; при чём таким способом, чтобы в процессе трансляции можно
	  было бы формировать новые аннотации? Это было бы полезно для
	  реализации языков, позволяющих определять новые типы данных (а это
	  почти все интересные нам языки: C/C++, Fortran, LiME).

	- Как запустить процесс вывода целевого выражения.

Ок. Можно смотреть и с другой стороны. Можно смотреть на этот процесс, как на
процесс восходящего (от примитивных типов) вывода некого значения с типом:
программа, делающая нечто (изоморфизм Карри-Говарда, всё такое прочее). То есть,
фактически можно вести речь о системе выводов типов. Так как нужно вывести ещё и
определённое значение - промежуточный код - то, речь должна идти о системе с
зависимыми типами. Но пока я не полезу в эти математико-логические дебри. Пока
необходимо разобраться со всем на чисто техническом уровне, а потом уже
подтягивать его к существующей теории.

Ок. Такой подход позволит иметь лишь один механизм вывода целевого
промежуточного представления, а именно, вывод в системе типов (пока в очень
простой). Он же позволит расширять систему типов по мере вывода программы (это,
вроде, системы типов позволяют делать), и создавать необходимые нам новые типы и
новые цепочки вывода. Сложные типы, которые нам понадобятся:

	- функции;
	- структуры;
	- объединения;
	- массивы.

Ок. Давайте попробуем это всё уточнить не в рамках теории типов, а просто в виде
конкретных алгоритмов. А потом поднимем это до современных теоретических высот.

			    2.4 Алгоритм.  Механика

Так. Сначала надо понять, что такое типы. Потом надо понять, что мы будем
выводить, из чего и как. Затем понять, в каких условиях алгоритм будет
детерминированный. Наконец, несколько примеров.

		    2.4.1 Алгоритм.  Механика.  Простые типы

На типы (насколько я понимаю; или насколько этого нам пока достаточно) можно
смотреть как на некие метки для значений. Эти метки определяют, условия поиска
и формирования некого представления, когда у нас уже есть значения некоторых
типов, которые мы хотим скомбинировать в значение новое. Разные типы надо
различать, а для этого необходима некоторая основа с заложенными в неё
различиями (если у нас нет материала, по которому можно сказать A отличается от
B, то мы вообще не особо можем что-то различить). Поэтому типы начинаются с
атомов.

Я пишу очень конкретно здесь, понятно, что скорее всего существует и более общая
теория, но наша главная цель - конкретная система трансляции, а в теории мы её
потом впишем. Итак.

	       2.4.1.1 Алгоритм.  Механика.  Простые типы.  Атомы

Наши атомы - это числа от 0 до ((2<<30) - 1). В силу своей человечности нам
проще записывать эти атомы в виде последовательностей различных букв (включая
цифры и всякую пунктуацию). Поэтому атомы ассоциируются в специальной таблице с
такими представлениями.

Один атом соответствует одной последовательности байтов с определённым оттенком
(hint). Оттенки нужны, потому что в различных языках с различными front-end-ами,
одинаковые последовательности байтов могут иметь различное значения и должны,
поэтому, трактоваться как различные атомы. Повторюсь, смысл атомов -- быть
различными и выражать концепцию «штука A отличается от штуки B». Одинаковые
цепочки байтов, которые необходимо трактовать различно в C:

	- 12345
	- "12345"

Таблица атомов загружается в ядро LiME при загрузке программного модуля. Модуль
представляет собой простой текстовый файл, в котором игнорируются различные
пробельные символы. Ядро ожидает таблицу атомов в начале модуля, в формате:

	A = ( «AtomNode;»'* AtomNode )

Element'* стандартно означает список из 0 или более Element-ов (с апострофа
будем начинать спецсимволы; «» будем использовать вместо скобок). Каждый
AtomNode имеет формат:

	A «'[0-9A-Za-z']»'+ = hint.size."Byte'*"

'[...'] - стандартно обозначает один из символов диапазона «...». '+ стандартно
обозначает повторение одного или более символов. Ужас до знака «=» - это метка
атома. Все метки должны быть уникальными, потому что каждая метка обозначает
соответствующий узел. Byte -- любой байт. Каждое выражение AtomNode должно
создавать в таблице атомов информацию о новом атоме, поэтому в каждом выражении
после «=» должен стоять уникальный атом. Если условия на уникальность меток и
самих атомов не выполнены для какого-то узла, это внутренняя фатальная ошибка
компиляции, можно писать о ней большими буквами и прерывать процесс.

В lib/lime/module.h будет определена функция

	loadatab(AtomTab t, FILE * f,
		unsigned *const remap, unsigned * remapcnt)

Которая загружает секцию A = ( ) из потока f, заполняя таблицу отображения
номеров атомов (это для дозагрузки ещё одного блока атомов поверх уже
загруженного).

	      2.4.1.2 Алгоритм.  Механика.  Простые типы.  L-узлы

На типы существует множество взглядов. Например, на тип можно смотреть как на
нечто, являющимся аппроксимацией некоторых значений из некоторого множества.
Например, int - это аппроксимация элементов группы

	{ -2147483648, ..., 0, ...  2147483648 }

Можно строить на основе этой идеи всякие порядки: X лучше приближает Y. И
выводить из этого разную интересную логику. Но это нам не нужно.

В DCPL типы сперва рассматриваются, как уточняющее смысл программы нечто. Но
потом рассматриваются и полиморфные системы типов, которые позволяют
генерировать функции под конкретные типы. Но тут тоже нечто не совсем то, что
нам нужно. Некоторые кусочки мы, конечно, должны будем из обобщённых
проектировать на конкретные типы, но в этом нет нужного нам акта поиска и
конструирования нового кода. Это специализация существующий функции. В общем, я
не понимаю, как вписать то, что нам нужно в эту модель. Потому что, обобщённые
функции надо как-то написать, а потом ещё специализировать через match-и по
типам, и?.. Снова возникает вопрос: а как собрать-то тот код, который надо
специализировать? В общем, похоже, эти полиморфные радости пока нам не особо
помогут.

Поэтому начнём с простых, мономорфных типов, то есть, когда каждому выражению
соответствует определённый тип.

Мономорфность автоматически не гарантирует совсем уж тривиальности. Потому что
сложные мономорфные типы бывают. Например, структура - это тип, определяемый
списком других типов. Или функция - это тип, который определяется списком из
списка типов аргументов и типа возвращаемого значений.

Так. Типы бывают сложные. А основная роль у типов в компиляторе Си (и в LiME
тоже) -- это вывод необходимых представлений данных в памяти и вывод кода по
синтаксическим конструкциям, связывающим некоторые подвыражения. Очевидно, что
при различной комбинации типов у «A» и «B», нужно вывести различные выражения
для «A+B». Давайте уж до конца уточню. Например, если A - char, а B - это short,
то надо привести A к int, B к int (разными конструкциями), а потом уже
складывать в int. Или пример со структурами. Для разных структур (разных типов,
задающих структуру), выражение «A.B» может означать разное. А если B - это ещё и
переменная, то понятно, что типизация тут не самая простая, а вывод
промежуточного кода должен многое учитывать.

Ок. Хватит болтовни. Со всем вышесказанным в голове, приступим к делу. Так как
типы нужны сложные, то необходимо как-то их описывать. Универсальным описанием
являются S-выражения (см. «DCPL»). S-выражение - это просто произвольные
деревья, которые записываются так:

	(A B C D (E F G) H I J (K (L M (N O P Q))) R S T)

Можно на эти S-выражения смотреть как на список разных элементов, в том числе и
других S-подвыражений. То есть, список на верхнем уровне в примере выше состоит
из 12 элементов, два из которых -- S-подвыражения. Парсить такое описание --
отдельное удовольствие. Дополнительное удовольствие -- это подстановка одних
S-выражений в другие. Если делать классическим методом, придётся вводить
lambda-абстракции. Мы пойдём более примитивным путём, дающим более свободы.
S-выражения будем строить при помощи узлов L (они уже совсем не похожи на link,
теперь это просто намёк на List, Lisp, RefaL и всякие такие прочие вещи).

Классический способ представления списков -- при помощи двух конструкторов и
двух де-конструкторов:

	конструкторы:
		null	- пустой список;
		cons	- приписывание к списку элемента сначала;

	де-конструкторы:
		head	- первый элемент списка;
		tail	- остаток списка.

То есть, список -- это пара элементов, второй из которых -- это другой список.
Представление соответствует представлению на Си в виде:

	struct List { Value head; struct List * tail; }

В качестве Value могут быть разные элементы, в том числе S-подвыражения.
Собственно, head из этого извлекает head, а tail -- tail.

Это хорошо формализованный подход (см. «DCPL»), но он громоздкий, само дерево
S-выражения нужно представлять в виде бинарного дерева. Есть более удобный
для нас способ представления таких S-выражений.

Например, в Refal (или Python, или Prolog) подобные выражения деревья (деревья)
представляют в виде линейных структур, массивов, например. С конструкторами и
де-конструкторами:

	конструкторы:
		null	- пустое выражение;
		value	- превращение значения в примитивное S-выражение;
		braces	- превращает S-выражение в S-выражение в скобках;
		extend	- конкатенация двух выражений;

	де-конструкторы (достаточно только nth):

		nth	- подвыражение на определённой позиции;
		slice	- сечение: получение из выражения (S1 ... SN) выражения
			  (Si ... Sj).

Ну и так далее. Удобнее работать со вторым вариантом, потому что Refal успешно
применялся для (так называемой) суперкомпиляции, а в нём выражения построены
примерно в таком духе, а не в духе списков, как бинарных выражений.

L-узлы -- штука разнообразная. Здесь будет только часть форматов. Правила
конструирования S-выражений в LiME. Начнём с вариантов value:

	- Любой помеченный узел «node x = ...» может сразу быть использован,
	  как примитивное (без внутренних скобок) S-выражение.

	- L может превратить в примитивное S-выражение один из элементов в
	  таблице атомов или таблице типов по его номеру:

	  	L.na	x = atomid;
		L.nt	y = typeid

	- Имеет смысл дать доступ в таблицы атомов и типов не только по номерам,
	  но ещё по содержимому этих таблиц.

	  	- Конструкция

			L.la	x = hint.size."bytes"

		  создаёт примитивное S-выражение со ссылкой на соответствующий
		  атом. Атом должен быть загружен в таблицу типов. Она должна
		  быть эквивалентной конструкции «L.na x = Num» для
		  соответствующего «hint.size."bytes"». Что-то у меня режим
		  словоблудия включен. Ладно, пример:

		  	A = ( A x = 1.2."34" );
			T = (
				L.na	x = 0;
				L.la 	y = 1.2."34";
				L.la 	z = 0.1."a"
			)

		x и y -- это одинаковые S-выражения, состоящие из одного атома.
		Последнее выражение «link.A z = ...» ошибочно.  L.la - это,
		фактически, lookup по таблице атомов.

		- Конструкция

			L.lt	x = exp;

		  где, exp - это некоторое S-выражение из других типов и
		  атомов, создаёт примитивное S-выражение со ссылкой на
		  соответствующий тип в таблице типов. Тип должен существовать.
		  Например:

		  	A = ( A x = 1.1."4"; A y = 1.1."I" );
			T = (
				L.na	x = 0;
				L.na	y = 1;
				L	z = x : y;
				type	t = z
			)
			...
			N = (
				L.la	x = 1.1."4";
				L.na	y = 1;
				L	z = x : y;
				L.lt	t = z;
				L.nt	s = T.0
			)

		  t и s -- одинаковые S-выражения. L.lt - это lookup по
		  таблице типов.

	- Из примитивных S-выражений L должен позволять собирать составные.
	  Разумно это сделать в формате структуры самого S-выражения. Читать
	  такие структуры придётся несколько нетривиально, зато писать будет
	  проще, что важно для описания форм. Конструкция:

	  	L x = a : b : (c : (d : e)) : f
	  
	  приписывая указанные S-выражени друг к другу, и заключая в скобки
	  соответствующие части. В примере выше, в «T = ( )» z задаёт
	  выражение «I 4». Если продолжить пример:

	  	N = (
			L.na	x = 0;
			L.na	y = 1;
			L	z = x : y;
			L	w = x : z;
			L	a = w : w
			...
		)

	  «a» будет ссылкой на узел с S-выражением: (4 4 I 4 4 I).  Если
	  продолжать пример выше (с ...):

	  	N = (
			...
			L	c = z : (b);
			...
		)

	  «с» будет ссылаться на узел, представляющий выражение: (4 I (4 4 I)).

Уфх. С конструированием S-выражений, кажется, всё. Понадобится ещё декомпозиция.
Нужно брать некоторое подвыражение, S-выражения s. В такой форме:

	L.n 	x = s : i : j : k : (H : 20) : (30 : T) : ...

Можно читать (Python-стиль):

	s[i][j][k][:20][30:][...

Если продолжать пример выше:

	N = (
		...
		L.n e = c : 2 : 0
	)

то «e» будет указывать на узел, задающий S-выражение (4). Ядро LiME при чтении
L.n будет интерпретировать числа (которые оно будет получать в виде атомов и
проверять их на то, что это числа), и два специальных атома «H» и «T» как
специальные значения. Чтобы подставить нечто в список координат, нужно будет
использовать другие ветки. «(H:n)» выбирает элементы из списка от начала до
n-ого включительно. «(n:T)» - элементы с n+1 до конца.

С этими двумя конструкциями:

	head s - это «L.n h = s : (H : 0)»
	tail s - это «L.n t = s : (0 : T)»

Если вдруг понадобится.

	 2.4.1.2 Алгоритм.  Механика.  Простые типы.  Сводка по L-узлам

Краткий список вариантов L-узлов для справки:

Конструкторы:
	L.na	x = Num;
	L.nt	x = Num;

	L.la	x = Atom;
	L.lt	x = Expression;

	L	x = a : b : c (d : e) : f; 
Деконструкторы:
	L.n	x = y : i : j : (H : k) : (l : T) : m;

Теперь дальше.

	       2.4.1.2 Алгоритм.  Механика.  Простые типы.  Типы

Простой тип - это уникальное S-выражение из атомов и других (тут важно, что
других; мы пока не занимаемся решением рекурентных соотношений) типов, имеющее
свой порядковый номер.

Например, «unsigned int» может быть представлен выражением «("U" "4")» (я не
пишу длину атомов (которая понятна), и hint-ы, которые можно считать здесь
нулевыми).

Или какая-нибудь структура:

	struct { unsigned int x; unsigned int y; }

может выражаться, как (в некотором неверном приближении):

	("struct" ("x" ("U" "4")) ("y" ("U" "4"))).

Такое выражение не верное, потому что для типов важно отношение равенства
(точнее, важно отношение «быть подтипом», но пока у нас типы самые простые, и у
них есть только равенство).

Два типа имеет смысл считать равными, если совпадают их S-выражения с точностью
до элементов и структуры. Поэтому, если «unsigned int» зарегистрирован, как тип
с номером N (запишем это T.N), то тип:

	("struct" ("x" T.N) ("y" T.N))

Будет отличаться от вышеуказанного. Но при этом оба выражения задают какие-то
типы, и, в принципе, может быть определена функция, приводящая первый тип ко
второму, но это уже будет именно нетривиальная функция, определённая на домене
типов.

Ок. Пока нам важно только точное совпадение типов. Собственно, дальше всё уже
просто. Типы записываются в таблицу «T = ( )», выражениями:

	T «'[0-9a-zA-Z']'+» = «'[0-9a-zA-Z']'+»

где второе имя (штука после «=») - это ссылка на S-выражение, описывающее тип.
Например:

	A = (
		A a = 0.1."U";
		A b = 0.1."4";
		A c = 0.6."struct";
		A x = 1.1."x";
		A y = 1.1."y"
	);
	T = (
		L.na	u = 0;
		L.na	4 = 1;
		L.na	s = 2;
		L.na	x = 3;
		L.na	y = 4;

		L	uie = u : 4;	// это не L.n узел. 4 - ссылка на атом
		T	tui = uie;

		L	se = s : (x : tui) : (y : tui);
		T	ts = se
	)

Получаем два типа: T.0 (соответствующий «unsigned int») и T.1 для

	struct { unsigned int x; unsigned int y; }


	     2.4.2 Алгоритм.  Механика.  Формы.  2.3.2.1 Философия

Ок. Продолжим. Итак, сейчас надо описать, как простые типы помогут выводить
промежуточное представление кода из входного синтаксического языка. Входной язык
у нас представлен конструкциями:

	B	lex
	U	lex
	L	lex
	E a	lex
	E b
	E u
	E l

Перед приходом такой инструкции на вход, у нас есть накопленное промежуточное
представление. Накоплено оно в виде дерева, отдельные ветви, которого, лежат на
стеке, который растёт или сокращается в результате обработки синтаксических
выражений. Ок. Хорошо. Ветки растут в моменты сокращения стека, тогда они
сливаются. Соответственно, новые ростки появляются в момент расширения стека.
Дерево, естественно, растёт от ветвей к корню, представляющему всю программу.

С расширением всё относительно просто. Вопрос в том, как сливать ветви. Потому
что сливать необходимо множество вариантов. Когда написано «a + b», пространство
комбинаций возможных значений для поддерева «a» и поддерева «b» обширны (даже
потенциально бесконечны, если подходить формально, потому что каждая структура в
C задаёт отдельный тип, на который можно создать указатель, тоже отдельного
типа, а указатели вполне можно складывать).

Было бы хорошо, если бы не пришлось при этом прописывать весь этот анализ
вариантов в большом-большом match-блоке, который статичный, и который нельзя бы
было изменять со стороны пользователя (потому что хочется вводить расширения
языка для экспериментов с моделями параллелизма и памяти).

Ладно. Так. Существует подобный метод. Например, есть такая штука - система
типов Хиндли/Милнера, в которой из текущего окружения выводятся типы для
различных символов, описывающих функцию. При этом явно правила вывода не
прописываются, они отчасти заложены в сам алгоритм, а отчасти вводятся в
окружение при анализа выражений с известными операторами.

Типы для символов нам выводить не надо, но сама концепция может оказаться
полезной. Концепция того, что есть некое текущее окружение, в него набросана
различная информация о том, какие шаги вывода целевого выражения можно сделать в
текущий момент, и мы делаем постепенно этот вывод.

Вопрос в том, как представлять эти возможные варианты или (вероятно, точнее
сказать) направления вывода или (вероятно, точнее сказать) роста дерева
промежуточного представления кода.

Сделать это можно, если для каждого такого варианта мы укажем:

1.	когда в этом направлении можно растить IR (intermediate
	representation);

2.	что мы получим в результате;

3.	и что мы прирастим к текущему выражению IR.

Это можно сделать в стиле RiDE. Всё это можно выразить в виде правила, на
абстрактном уровне описываемом, примерно таким выражением:

	r.1 r.2 ... r.N = IR c.1 c.2 ... c.K

Где r.i - это некие результаты приписывания IR к текущему выражению, а само
приписывание можно осуществить по выполнению условий c.j. То есть, как только
текущее выражение имеет набор c.j, в качестве результатов очередного шага
вывода, мы можем приписать к этим (условно говоря) «выходам» IR, переправив эти
выходы на входы IR, чтобы получить новые выходы и продолжить вывод.

Теперь надо уточнить эту абстрактную схему.

	      2.4.2.2 Алгоритм.  Механика.  Формы. Тела 

Итак. У нас есть формы. У форм есть IR часть, которая должна быть вставлена в
выращиваемое выражение. Будем называть эту часть телом.

При подстановке в выражение форма может порождать новые формы, поэтому тела надо
оформлять специально, и заключать в некоторый вариант скобок. Для самих форм
содержимое их тел должно быть невидимым, и весь поток данных между ними должен
идти через c.i-тые (которые мы назовём ногами) и r.j-тые (которые мы назовём
руками). Форма встаёт ногами на руки других форм, пропускает через своё тело
данные, порождая, возможно, другие формы, и выдаёт результаты на своих руках.
(Формы, тела, руки и ноги - это, в общем-то, вполне математические термины. У
полилинейных форм, aka тензоры, есть руки и ноги).

Раз форма должна порождать другие формы, то надо как-то отмечать, где одна форма
начинается, и где она заканчивается. Для этого и нужны скобки.

	- F.b (begin) начать новую форму;
	- F.e (end) закончить, вернуться к обработке предыдущей.

На формы нужны ссылки, чтобы можно было ими манипулировать в дальнейшем:
регистрировать в областях видимости, чтобы их замечало ядро при поиске по
синтаксическим событиям, или просто порождать, если это требуется для
продолжения вычисления.

Ок. Естественно, формы живут в таблице «F = ( )» (тут возникает вопрос, может
быть вообще эти таблицы не имеют особого смысла? И можно свалить всё в кучу? Но
пока так). Пример:

	F = (
		...
		F.b fx = legs;
		...
		F.b fx = legs;
		...
		F.e;
		...
		F.e;
		...
	)

С началом обработки новой формы создаются новые таблицы для имён:

	- узлов;
	- форм;
	- прочих объектов (метки нужны и, может быть, что-нибудь ещё).

Речь именно о новых таблицах, а не о таблицах вложенных. Поэтому fx и legs в
двух указанных случаях идентифицируют разные объекты.

Ок. С телами, кажется, всё.

	     2.4.2.3 Алгоритм.  Механика.  Формы.  Сводка по узлам

На текущий момент описаны такие конструкции ядра LiME ({} отмечают
необзятальную часть):

	A	{ x = } hint.size."bytes";
	T	{ x = } exp;

	L.na	x = Num;
	L.nt	x = Num;

	L.la	x = hint.size."bytes";
	L.lt	x = exp;

	L	x = a : b : (c : d : (e : f)) : g;

	L.n	x = y : i : j : (H : k);

	F.b	x = legs;
	F.e

	      2.4.2.4 Алгоритм.  Механика.  Формы.  Руки и ноги.

Так. Описать условия, по которым форма (на самом деле, хотелось бы другого
названия, потому что, происходящее скорее похоже на сборку белка по цепочке ДНК,
может, лучше называть всё не формами, а какими-нибудь... эмс?... Но пока формы)
включается в выражение можно при помощи типов.  Собственно, для этого они и
нужны. При помощи типов же можно описать структуру рук формы, то есть
результатов её включения в выражение, к которым можно подключить другие формы.

Вот. Собственно. Ноги могут быть похожими на описание аргументов какой-нибудь
привычной процедуры. Ногами может быть просто список из типов и атомов. Атомы
нужны для уточнения контекста, в который может вписываться форма.

Списки мы можем составлять при помощи «L.»-примитивов. Составляются они в том же
духе, что и для типов.

Руки - это результаты включения тела формы в выводимое выражение. Поэтому имеет
смысл обозначать эти результаты прямо в теле формы. Для этого предназначена
конструкция P (pin). Для неё надо указать тип результата (сама она вывести его
не может, потому что это зависит от семантики самого языка программирования, а
не от LiME). Формат такой:
	
	L.nt	t = 0;
	add.t	x = y : z;
	P.t	x

Пример:

	A = ( A 0.1."U"; A 0.1."F"; A 0.1."4"; A 0.1."-" );
	T = (
		L.na	f = 1;
		L.na	4 = 2;

		L	4f = f : 4;
		T	4f
	);
	F = (
		L.nt	4f = 0;
		L.na	u = 0;
		L.na	m = 3;

		L	y = u : m : 4f;	// это U - T.0
		L	l = (y);	// нужен список из ног, через окружение
					// у в скобки получим список из одного
					// элемента (U - T.0)

		F.b	f = l;
		L.fl	ls;		// список ног, которыми форма стоит на
					// других формах

		L.n	x = ls : 0 : 2;	// первая нога, соответствующая U - T.0,
					// третья компонента

		L.n	e = x : 0;	// которая является парой (значение тип)
		L.n	t = x : 1;

		neg.t	r = e;		// семантика

		L.la	v = 0.5."value";
		L	p = v : (r : t);
		P	p;
		
		F.e
	)

	      2.4.2.5 Алгоритм.  Механика.  Формы.  Процесс вывода

		  2.4.2.6 Алгоритм.  Механика.  Формы.  Пример

Так. Что дальше?
