СПЕЦИФИКАЦИЯ LiME. Версия 1.dev (в разработке).

									    ЦЕЛЬ

Сделать систему трансляции, которая давала бы программисту несколько
инструментов, которые, как показывает практика современного программирования,
востребованы и позволяют повысить производительность труда:

	- система типов с автоматическим выводом (возможно, в некоторой
	  ограниченной форме);

	- средства определения пользовательские конструкции для управления
	  потоком вычисления (чтобы создавать собственные реализации
	  for/if/switch, что может быть полезно в разработке приложений для
	  неоднородных систем);

	- замыкания, как более гибкую в сравнении с ООП систему декомпозиции и
	  композиции кода (тут можно сослаться на опыт Go);

	- специализацию кода во время исполнения, что, как известно ('C:
	  http://pdos.csail.mit.edu/papers/tickc-poletto-phd.pdf) существенно
	  повышает эффективность программ;

	- императивную семантику, которая предоставляет программисту большую
	  гибкость в построении различных структур событий (имеется в виду
	  математический аппарат для описания вычислительных процессов);

	- модель исполнения ориентированную на процессы, а не на потоки;
	  процессы (в том числе и программно-изолированные) удобнее и
	  эффективнее в задачах управления ресурсами по сравнению с нитями, и не
	  уступают последним в эффективности при выполнении многозадачных
	  вычислений;

	- средства статического анализа кода и верификации;

	- оптимизирующий компилятор, позволяющий разрабатывать
	  высокопроизводительные приложения для супер-компьютеров;

	- основные алгоритмы системы должны быть достаточно простыми для
	  быстрого их переноса на различные платформы, в том числе, с небольшим
	  объёмом оперативной памяти (cкажем, 256KiB); основными названы те, что
	  позволяют получить из исходного кода машинный.

В той или иной степени некоторые из этих инструментов реализованы в различных
системах программирования, однако все они не собраны ни в одной. Поэтому
возникает идея разработать подобную систему трансляции.

Побочным эффектом при её реализации должна стать возможность достаточно простой
организации frontend-ов некоторых традиционных языков программирования (C99,
Fortran, etc) поверх системы LiME. Определение базовых типов и конструкций для
описания потока управления на уровне пользователя должны свести задачу
построения таких frontend-ов к созданию:

	- кода, переводящего исходный текст программы в исходный текст на LiME,
	  возможно, в несколько оптимизированной форме, сходной с той, что сам
	  LiME (LiME is Metaprogramming Engine, поэтому сам) генерирует на этапе
	  синтаксического анализа;

	- реализаций тех или иных операторов, если они ещё не реализованы, в
	  рамках семантического движка LiME.

Примерно так.

								  СТРУКТУРА LiME

Здесь описан текущий высокоуровневый взгляд на систему.

LiME состоит из нескольких компонент, каждая из которых между своими
составными частями имеет обратные связи.

	- сканер: лексический анализатор с вполне классической структурой, с
	  небольшими отличиями (если не считать ключевые слова) от лексики Си;
	  лексический анализатор передаёт на синтаксическую стадию анализа поток
	  лексем вида («:» - условный разделить, главное, что речь о тройках):

	  	тип лексемы : значение : позиция в тексте;

	  под «типом лексемы» понимается:

	  	- идентификатор,
		- константа,
		- одна из групп операторов;

	- парсер: синтаксический анализатор простых операторных выражений, для
	  которого тоже достаточно простых алгоритмов; решётка приоритетов
	  операторов похожа на используемую в Go (в Си она слишком большая,
	  часто приходится вспоминать, но это нам не помешает);

	  неклассическая особенность: синтаксический анализатор может
	  «придумывать» некоторые операторы по фиксированной схеме;
	  синтаксический анализатор передаёт в семантический анализатор

	  список «команд» примерно такого вида:

		новый номер выражения = атом;

	  	новый номер выражения = унарный оператор : номер подвыражения;

		новый номер левого «вектора»
			= номер левого подвыражения
			: бинарный оператор

		новый номер выражения
			= номер левого «вектора»
			: номер правого подвыражения

	  «=» и «:» - это малозначимое форматирование; такой интерфейс не совсем
	  традиционный, но тут всё строго;

	  такие нетрадиционности необходимы, чтобы в LiME можно было
	  программировать, например, такие конструкции (в ней нет ключевых
	  слов и встроенных операторов):

	  	for(var (x.1; x.2) = range2d(0:N-1; 0:M-1))
		(
			sum += field(x.1; x.2)
		)

	  frontend-ы других языков программирования могут взаимодействовать со
	  следующей, основной частью всей системы через генерацию такого вида
	  «команд»;

	- движок: семантический анализатор - основная часть системы, которая на
	  основе команд, описывающих связи выражений с операторами строит
	  промежуточное представление программы, пригодное для генерации кода;

	  пока такое промежуточное представление предполагается делать в виде
	  кода из тетрад (в основном), то есть, элементов вида:

	  	код операции «метка» =
			«ссылка на аргумент 1» «ссылка на аргумент 2»

	  это текстовое представление, доступное программисту, поэтому
	  желательно, чтобы оно было таким; метки удобны для программиста,
	  а этот формат удобно разбирать; двоичное представление
	  последовательности таких выражений, конечно, триадное; пример:

	  	a = x + y | z

		addr	pa = a;		// идея разделения получения адреса
		addr	px = x;		// значения, его загрузки и собственно
		addr	py = y;		// вычисления взята из LCC; это
		addr	pz = z;		// позволяет упростить кодировку
		ld.u8	vx = px;	// операции (or, add работают только со
		ld.u8	vy = py;	// значениями; addr - с символами;
		ld.u8	vz = pz;	// ld - c адресами; можно проверять
	  	or.u8	t1 = y, z;	// корректность); опыт работы с LCC
		add.u8	t2 = x, t;	// позволяет сказать, что в одну
		st.u8	pa = t2;	// инструкцию всё это свернуть просто

	  задача движка брать такие участки кода, которые в процессе трансляции
	  он же связывает с подвыражениями и, руководствуясь специальными
	  таблицами, используя информацию о типах подвыражений и операторе
	  выводить тип составного выражения и соответствующий ему участок кода;

	  в коде могут быть специальные директивы для самого синтаксического
	  анализатор, которые он должен выполнять; например, директивы для
	  введения новых переменных или типов;

	  	.var	a = unsignedlonglong;

	  выполнение этой директивы должно сделать запись о символе a с
	  соответствующим типом в специальных таблицах SE;

	  такое представление программы, в котором большинство конструкций
	  проинтерпретировано должно передаваться дальше; набор необходимых
	  директив нужно обсуждать;

Дальнейшие участки проработаны не так хорошо. Какой-то код сгенерировать
возможно пользуясь опытом, полученным от LCC, так как далеко отходить от
традиционной структуры промежуточного представления не планируется. Но как
сгенерировать более оптимальный код - это вопрос будущего.

	- верификатор: где-то здесь должна быть система верификации, которая
	  получает достаточно информации от SE, чтобы выполнить определённые
	  проверки кода; хотя бы на выходы за границы; возможно, эта часть
	  должна быть тесно связана с семантикой, но на сегодняшний день
	  представляется, что информации о размерах типов может быть достаточно
	  для решения проблемы контроля выходов за границы памяти; это место
	  тоже надо обсуждать;

	- оптимизатор, получающий от FE представление программы в промежуточном
	  виде, в котором нет управляющих директив для семантического движка;
	  например, информации о взаимосвязи типов; предполагается, что
	  оптимизатор не нуждается в информации о том, например, что некая
	  структура данных была выведена из выражения

	  	array(20) list hash(string) int.2

	  вопрос, одако в том, какие знания о программе необходимы для успешной
	  оптимизации; достаточно ли знать только представление в виде потока
	  данных, из которого можно вывести всё остальное?

	  представляется, что оптимизатору не требуется обратная связь с
	  фасадом;

	- генератор кода для целевой машины; должен получать от FE некоторое
	  описание программы, и генерировать по нему ассемблерный код.

Представляется, что во время runtime-специализации кода его семантика не должна
меняться. То есть, например, в функции вычисления, допустим, факториала целые
числа не должны неожиданно превратится в вещественные.

Хотя, может быть, именно такое поведение и требуется программистам: много раз
приходилось слышать, что eval - это очень хорошо. Это тоже открытый вопрос на
данный момент.

Эти сомнения не влияют на особенности реализации C99 поверх LiME. Это всё более
продвинутые алгоритмы на будущее.

Итак. Теперь к каждой части подробнее. Нужно понимать, что изложенное ниже не
является окончательной версией спецификации. Просто в ходе научных (это следует
подчеркнуть, наука в данном случае - поиск нового) исследований была получена
такая конструкция. Многое может быть изменено в сторону усложнения или
упрощения.

						 ЛЕКСИЧЕСКИЙ АНАЛИЗАТОР (СКАНЕР)

1. Входной алфавит.

Конечно, сканер должен поддерживать строковые константы. Строковые константы
интерпретируются как цепочки байтов определённой длинны. Они могут быть
дополнены нулём во время семантического анализа для нужд компилятора Си99, но
на уровне сканера они представляются как массивы байтов определённой длинны.

Внутри строк могут встречаться любые символы (цепочки байтов).
Последовательности байтов могут задаваться и через привычные
escape-последовательности: «\t», «\r», «\n», и т.д. Кроме этого, предлагается
задавать цепочки байтов произвольной длины последовательностью «\x([0-0a-f]+)».
Например:

	uint(40) shasum = "\x(f444e5be3f26f57c4fcfa7d32a0379adf70c9473)"

Лексический анализатор поддерживает однострочные комментарии, начинающиеся
последовательностью «//». В комментарии может встречаться любая
последовательность байтов.

Вне строк и комментариев допустимыми символами считаются лишь следующие из
набора ASCII:

	- TAB - LF 	09 - 0A
	- « » - " 	20 - 22
	- +		2B
	- «-» - >	2D - 3E
	- A - Z		41 - 5A
	- ^		5E
	- a - z		61 - 7A
	- |		7C

Некоторых привычных символов здесь нет, можно считать их зарезервированными для
будущих версий, если вдруг понадобятся.

Сканер выделяет в последовательности символов несколько типов лексем:

	- атомы-символы (примитивные идентификаторы): последовательности
	  латинских букв и цифр [a-zA-Z0-9]+; атомы сравниваются с учётом
	  регистра; хотя гуру языков программирования аргументируют за
	  нечувствительность к регистру, практика показывает, что X и x лучше
	  трактовать как разные символы, особенно в вычислительных программах;
	  традиционное _ не включено в алфавит символов, потому что в
	  LiME предусматриваются другие способы давать сложные идентификаторы
	  переменным; например, для описания символов в C99 или во внешних
	  библиотеках можно использовать нечто вроде:

	  	id."classic_c_symbol_with_a_lot_of_underscores"
		id.cpp."SomeClass::overloadedMethod(int, ClassY, float)"

	- атомы-константы: строки и целые числа в записи по основаниям 10 и 16;
	  числа передаются лексическим анализатором на другие уровни трансляции
	  в формате длинных чисел без потери разрядов;

	- операторы различного приоритета:

									     Т.1
		0 ;
		1 = *= /= %= >>= <<= &= += -= |= ^= ||= &&=
		2 ->
		3 «:»
		4 ||
		5 &&
		6 == != < <= > >=
		7 + - | ^
		8 * / % << >> &
		9
		a !
		b .

	- скобки: ()

Некоторые особенности.

1. Немного нетрадиционно обрабатываются вещественные константы. Предполагается
сделать их составными и выводить уже на этапе семантического анализа. Возможно,
не самый лучший дизайн, но константы записываются в коде программы редко, можно
необычность в виде:

	0.6 E(3) * 3.1415 // == 1884.9

и потерпеть. Это сделано для обеспечения двух возможностей. Первая - возможность
давать переменным структурированные имена:

	var (x.1 = 21.3; x.2 = 4; x.4.5 = 3.1415; x.2.alpha = "alpha");

А потом работать с группами этих переменных. Это часто бывает необходимо в
циклах, когда что-нибудь такое приходится писать:

	x_0 = x_1;
	x_1 = x_2;
	x_2 = next(x_0; x_1; x_2);

В LiME поэтому хочется предусмотреть возможность записи:

	x.(0; 1; 2) = (x.(1; 2); next(x));

Но для этого, чтобы не усложнять семантику и не отказываться от однозначности,
необходимо на общих основаниях воспринимать записи вида:

	12345.6789

деревьями вида

	(. 12345 6789)

Из такой конструкции можно вывести вещественное значение.

Другая составляющая мотивации всегда трактовать точку всегда как оператор и
иметь возможность описывать конструкции вида x.1 коренится в желании обеспечить
программисту конструирование сложных объектов в стиле командной строки UNIX.
Здесь тонкость в том, что конструируется многопараметрический объект, который
громоздко было бы описывать со множеством знаков препинания, при том, что
описание в виде командной строки в виде списка ограниченного набора конструкций
может быть достаточно мощным и адекватным.

Для такого конструирования необходимо без дополнительной (относительно)
пунктуации задавать конструкции, состоящие из основной команды, флагов и пар
(ключ; значение). Например, задающая определённый способ воспроизведения видео
конструкция

	screen -S mp mplayer ~/Downloads/87* \
		-vf crop=280:210,scale=320:240 -ao null -osdlevel 0 \
		-display :32.1 -fixed-vo -loop 0

в условиях, когда «.» всегда оператор может быть записана с учётом доступных в
LiME синтаксиса и семантики так:

	screen S.mp mplayer "~/Downloads.87*"
		vf(crop(280:210) scale(320:240)) ao.null
		osdlevel.0 display.32.1 vo.fixed loop.0

Не идеально, но менее громоздко, чем даже вариант с именоваными параметрами для
функций/конструкторов/подобных вещей:

	screen(S = mp; mplayer("~/Downloads.87*";
		vf = (crop(280:210) scale(320:240); ao = null; osdlevel = 0;
		display = "32.1"; vo = fixed; loop = 0))

Возможно, такая обработка «.» плохая идея, но:

	- это никак не повлияет на поведение frontend для C99, который сразу
	  может выдавать значения с привязанным к ним типом, описывающим
	  константы более точно; естественно LiME должен понимать отличия целых
	  чисел от вещественных, и такой механизм возможен;

	- никто не пробовал так делать в языках программирования, поэтому,
	  ответить на вопрос, насколько идея удачна и насколько плоха, сложно, в
	  ней есть недостатки, но и достоинства кроме упомянутых выше; например,
	  можно формировать ip-адреса без дополнительного синтаксиса:

	  	87.224.213.1

	  такие конструкции могут быть однозначно интерпретированы в LiME;

	- в Perl не такой же, но похожий механизм есть; Perl спорный, но тем не
	  менее, широко распространённый язык.

2. Предполагается различать атомы нестрогим способом. Для синтаксического
анализа, основанного на операторной грамматике, отличать (условно)
идентификаторы от констант не нужно. А семантическому анализатору достаточно
иметь подсказку о том, какой вид имеет атом. Например, если лексический
анализатор подскажет семантическому, что 12345 - последовательность
десятичных цифр, то такая

	var 12345 unsigned int = 20;

конструкция может быть отброшена на этапе семантического анализа с сообщением о
том, что 12345 неподходящий вид атома для идентификатора. Такой подход позволяет
выражать и более сложные константы относительно экономным способом. Например,
ipv6 адреса:

	ping fc00.bad.c0de.0(fill).1

Эта предлагаемая особенность тоже не особо проверенная временем, поэтому выводы
о верности решения можно сделать только после определённой практики, но можно
сказать, что нечто похожее есть в языках для оболочек операционных систем. Когда
записано:

	wget -r --tries=10 http://fly.srk.fer.hr/ -o log

То все выражения получают свой смысл лишь в контексте исполнения wget, оставаясь
до передачи в wget просто строками. В LiME это может быть записано с примерно
той же семантикой в виде:

	wget r tries.10 "http://fly.srk.fer.hr/" o.log

3. IO

На вход сканер получает поток байтов, на выходе генерирует поток команд. В
первых, экспериментальных, версиях системы предлагается пожертвовать скоростью
трансляции в пользу удобства отладки и минимизации доменов ошибок. Поэтому
сканер предлагается сделать отдельным процессом, который передаёт
синтаксическому анализатору команды в виде конструкций (подобраны так, чтобы их
можно было легко читать при помощи scanf):

	- F «описание файла» для указания очередного файла с исходным текстом;
	- (E.номер|N.«новый номер») l.c «спецификация» для указания очередной
	  лексемы.

«Описание файла» может иметь такой вид:

	«длина пути в байтах»."«сами задающие путь байты»"

«l.c» - это координаты лексемы в виде +l строк +c байтов относительно
предыдущей лексемы или начала файла.

Описание лексемы может начинаться двумя способами:

	E.номер
	N.«новый номер»

«E» ссылается на уже записанную в таблицу лексем лексему. В записи должны быть
сохранены все параметры из полной спецификации, необходимые для дальнейшей
обработки. В «E»-случае спецификация лексемы должна состоять из сторокового представления лексемы.

«N» должна задавать новую запись в таблице, номер должен быть ранее не
использованным. Тут возможен перекрёстный контроль корректности с проверкой на
стороне потребителя.

Спецификация лексемы должна иметь структуру вида:

	тип уточнение

тип - число, задающее вид лексемы:

	- для операторов - это номер:


		 0	;

		 1	=
		 2	*=
		 3	/=
		 4	%=
		 5	>>=
		 6	<<=
		 7	&=
		 8	+=
		 9	-=
		10	|=
		11	^=
		12	||=
		13	&&=

		14	->

		15	:

		16	||

		17	&&

		18	==
		19	!=
		20	<
		21	<=
		22	>
		23	>=

		24	+
		25	-
		26	|
		27	^

		28	*
		29	/
		30	%
		31	<<
		32	>>
		33	&

		34	@		- s-apply, вводится парсером

		35	!
		36	-		- унарный, вводится парсером
		37	^		- унарный, вводится парсером

		38	.
		39	@p		- p-apply, вводится парсером

		40	(
		41	)

	- для атомов - это 42		- вот теперь хорошо.

Уточнение - дополнительная информация. Для операторов - это строковое (в «"»)
представление этого оператора для перекрёстной проверки корректности и
читаемости. Для атомов - это такая структура:

		«тип атома».«длина в байтах»."«сами байты»"

Тип атома задаётся битовой строкой, где каждый бит означает (биты записаны
числами):

	1 - атом может быть строкой
	2 - атом может быть десятичным числом
	4 - атом может быть шестнадцатеричным числом
	8 - атом является строкой

Например:

	src/somefile
	x x

	F 12."src/somefile"
	N.0 0.0 41 1.1."x"
	E.0 0.2 "x"

Кажется, обо всех тонкостях сканера сказано.

					      СИНТАКСИЧЕСКИЙ АНАЛИЗАТОР (ПАРСЕР)

Можно было бы задать грамматику LiME в виде BNF и сказать, что вот она и есть.
Что можно её использовать для автоматического построения синтаксического
анализатора при помощи средств, генерирующих LL(1), LR(1) или LALR(1)
анализаторы. Но в таком случае разбор бы зависел от относительно (хоть алгоритмы
известны) сложных дополнительных программных средств. Кроме того, для увеличения
выразительности и «мощности» семантического анализа необходимо добится
определённых свойств в порядке свёрток. А BNF сама по себе не даст представления
о том, почему правила именно такие.

Поэтому хочется подвести к формальной грамматике LiME неформальным и более
содержательным описанием через определение необходимых деталей алгоритма. После
чего, грамматика будет формализована «естественным» образом.

Парсер LiME основан на разборе с переносом-свёрткой при помощи стека. За основу
алгоритма взят классический алгоритм (Fortran) разбора по граматике операторного
предшествования.

	http://en.wikipedia.org/wiki/Operator-precedence_grammar

Это очень простой и эффективный алгоритм, однако, оригинальный его вариант не
позволяет строить достаточно выразительные конструкции. Поэтому в LiME
применяется его модификация:

	- в некоторых случаях парсер воспринимает операторы «-», «^» (для
	  побитового not) как префиксные унарные;

	- в некоторых случаях парсер вставляет в поток лексем вспомогательные
	  лексемы, трактующиеся как бинарные операторы: «@» (space apply) и
  	  «@p» (parentheses apply);

	- парсер замечает то, что называется (за неимением лучшего термина)
	  «левой основной» (l-основой) - это пара из указателя на левое
	  подвыражение при обработке бинарного оператора и сам оператор;

	  реакция на такую l-основу в семантическом анализаторе
	  предусматривается для задания контекста в правом подвыражении дерева,
	  то есть, для переопределения привязок операторов к их реализациям в
	  виде наборов тетрадных инструкций.

Эти ухищрения нужны в основном для того, чтобы без лишней пунктуации описывать
сложные типы данных и конструкции управления потоком управления. Примеры:

	- список двумерных массивов из ассоциативных массивов для пар
	  строка : запись о человеке

	  var L list array(20;20) array(string) record(age uint; name string)

	  в Си++ это был бы ужас из угловых скобок;

	- запуск команды через оболочку «естественным» способом (как пример
	  конструирования сложного объекта):

	  val p = unixpipe();
	  val proc = (1=p; ffmpeg f.v4l2 i."/dev/video0" af.null vf.grayscale);
	  var sum int = 0;
	  p.bytes.foreach(x byte) (sum += x < 20 && x < 40);
	  proc.wait();
	  echo "число не-таких-уж-ярких-пикселей %d".fmt(sum)

	- сложные управляющие конструкции:

	  x = switch
	  (
	  	y == a -> b;
		y == z -> (val t = sin(z)/exp(y); pin = t*t + 1);
		false -> 3.1415926
	  )

	- возможно, это поможет писать и SQL запросы без дополнительной
	  пунктуации (LINQ пример востребованности такой техники).

Теперь подробнее о каждом элементе синтаксического анализатора LiME.

			  1.  Базовый алгоритм разбора

Алгоритм (далее так и буду на него ссылаться) разбора по оператороной грамматике
можно записать так:

0	for(stack.top != "$" || input(ip) != "$")
1	(

2		if(stack.top <∙=∙ input(ip))
3		(
4			stack.push(input(ip));
5			ip += 1
6		)

7		else if(stack.top ∙> input(ip))
8		(
9			for(var R = true)
10			(
11				var t = stack.pop();
12				R = stack.top <∙=∙ t
13			)
14		)

15		else (error())
16	)

Отношения <∙, =∙, ∙> - это отношения между символами, которые показывают, какое
выражение должно выделятся из потока лексем первым. Это три отдельных
отношения, поэтому может быть так, что A <∙ B, но при этом не выполнятся, что
B ∙>=∙ A, поэтому в 15 строчке вполне осмысленная ветка else, связанная с
обнаружением ошибки.

Для LiME в Алгоритме важно то, что:

	- как и любой другой алгоритм переноса-свёртки он анализирует текст
	  снизу вверх, выделяя при этом сначала самое левое возможное выражение;

	- операция stack.pop() явно связана с семантикой выражения, и фактически
	  означает: если выталкиваемый символ - это унарный оператор, то его
	  надо применить к накопленному перед этим выталкиванием выражению, если
	  бинарный - то, к последнему и предпоследнему выражениям (это можно
	  отслеживать при помощи стека, или даже при помощи двух переменных);

	- повторение ветки (7:14) конструирует то, что названо l-основой
	  выражения, явное её выделение и передача информации о ней в
	  семантический анализатор позволяет в LiME использовать в выражениях
	  для различных конструкций левый контекст.

Чтобы Алгоритм заработал, нужно указать отношения <∙, ∙> и =∙ между символами.
Начнём с простых приоритетов. Каждому символу S можно сопоставить число p(S) и
отношения с точкой между A и B определять по отношению чисел p(A) и P(B):

	- A <∙ B == p(A) < p(B);
	- A ∙> B == p(B) > p(A);
	- A =∙ B == (p(A) == p(B)).

Для большинства символов эти числа указаны в таблице распознаваемых сканером
символов (Т.1). При таком подходе (классика Fortran, кстати) атомы имеют
самый большой приоритет.

Почти всё хорошо, только не понятно, какие операторные выражения должны
соответствовать конструкциям вида

	for(exp; exp; exp) (exp).

Или, в каких отношениях должны состоять унарные «-» и «^» с другими символами.
Ведь для чисел не может одновременно выполняться p(-) > p(*) - для унарного - и
p(-) < p(*) - для бинарного случая (в классическом Fortran нельзя было
записать унарный минус без скобок). Нужны модификации в Алгоритме.

			     2.  Унарные операторы

(Надо сказать, что операторы - это не самый точный термин, но, надеюсь, всем
понятно, что он означает).

Наивный подход к проблеме таков. Некоторые операторы можно трактовать, как
унарные, если известно, что предыдущая лексема была:

	- «начало разбора»
	- «;»
	- «(»
	- оператор

Приоритет этих операторов должен быть равным приоритету «!». На данный момент
предлагается считать возможными унарными операторами «-», «^» (для побитового
not). При необходимости этот набор можно легко расширить.

Алгоритм предполагает, что выдаваемые парсером в семантический анализатор
команды нужно формировать по исполнению stack.pop(). Поэтому, цепочка унарных
операторов будет сперва накоплена в стеке в ветви (2:6), а потом в обратном
порядке выдана в виде команд для семантического анализатора в повторениях ветки
(7:14), что соответствует традиционной политике, когда унарные операторы
оцениваются справа-налево.

Например (как из учебника; команды показаны условно; число N после букв l, e, u
- это ссылка на предыдущее выражение, отстоящее справа от текущего на N
позиций; выражения разделены пробелами; точный формат в 6. IO):

									     П.1

-	$ x * -^y + z $		- оставшийся вход
				- стек
				- команды движку (без уточнений)

-	x * -^y + z $
	$


-	* -^y + z $
	$ x


-	-^y + z $
	$ *
	E=x L=e1:*

-	^y + z $
	$ * u-
	E=x L=e1:* U=-

-	y + z $
	$ * u- u^
	E=x L=e1:* U=- U=^

-	+ z $
	$ * u- u^ y
	E=x L=e1:* U=- U=^

-	+ z $
	$
	x L=e1:* U=- U=^ y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+

-	z $
	$
	E=x L=e1:* U=- U=^ y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+

-	$
	$ + z
	E=x L=e1:* U=- U=^ y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+

-	$
	$
	E=x L=e1:* U=- U=^ E=y E=u2:e1 E=u4:e1 E=l6:e1 L=e1:+ E=z E=l2:e1

	       2.  Неявные лексемы операторов «@» и «@p».

Парсер «замечает» их в потоке операторов по особым правилам.

@p (parentheses apply - p-apply) вводится:
	- после атома перед «(»;
	- после «)» перед «(»;

@ (space apply - s-apply):
	- между двумя атомами;
	- после атома перед унарным оператором;
	- после «)» перед атомом.

Приоритет «@p» максимальный и равен приоритету «.». Приоритет «@»
непосредственно предшествует приоритету унарных операторов.

Благодаря этому выражения вида

	var x array(20) unsigned long int

не требуют специальных синтаксических конструкций для разбора и легко
превращаются в синтаксические деревья «операторного» вида (запись в виде
S-выражений).

	(@
		(@ var x)
		(@
			(@p array (20))
			(@ (@ unsigned long) int)))

Аналогично, выражения вида:

	for(x = 0; x < N; x += 1) (dosomething());

не требуют специального синтаксиса и превращаются в операторные деревья:

	(@p (@p for (...)) (dosomething()))

Если теперь предоставить программисту средство описывать преобразования над
промежуточным кодом, которые должны выполнятся по поступающим от парсера
командам (которые описывают связи подвыражений в более крупные выражения при
помощи операторов), то можно будет говорить о возможности программирования
конструкций управления потоком управления for, switch и прочих.

				 3.  L-Основы.

Фактически все КС-грамматики с просмотром на одну лексему вперёд неявно
выделяют накопленный слева контекст анализа текста так или иначе. Однако, ему не
придаётся особого значения. В LiME предпринимается попытка это значение придать
и воспользоваться им.

Допустим, разбирается конструкция:

	var name int;

Если подходить стандартно к разбору этого выражения (с учётом автоматически
внедрённого в поток лексем @), то сначала надо оценить «var», затем,
«name», а потом их связку. Но так как name ещё не объявлено, то сложно это
выражение оценить корректно (на самом деле, LiME, конечно же, знает, как это
сделать). Поэтому логичнее включить (в некотором смысле) специальный режим
анализа последующих за (@ var ...) выражений (которые сформировать
выражение на месте «...»).

В более сложном выражении такая необходимость более очевидна:

	var name.1 int;

Так как name ещё не объявлена, то семантический движок не может верно оценить
выражение «name.1»: его таблицы на момент объявления не содержат
достаточной для этого информации. Эта информация должна сформироваться в
процессе регистрации новой переменной при помощи конструкции «var». Поэтому
разбор (точнее, накопление) выражения «name.1» должно происходить в специальном
режиме, который может быть включен при обнаружении основы (@ var ...).

Аналогичная ситуация существует, например, и при трансляции оператора for:

	for(var i int = 0; i < N; i += 1) (sum += i);

Корректный семантический анализ тела цикла невозможен без информации о «i». И
чтобы её распространить, необходимо сперва обработать левую часть выражения:
«for(...)» - которая сформирует l-основу, и о которой семантический анализатор
узнаёт через специальную команду.

Аналогично в задающих сложные конструкции выражениях:

	ffmpeg i."input" c.v(libx264 fast pass.1) an f.mp4 y."/dev/null"

для корректного разбора этого выражения семантический анализатор должен знать,
что «i», «c», «v», «libx264» и прочие символы следует интерпретировать только
как атомы (или в соответствии с иным смыслом, предписываемым «ffmpeg»). Для
этого необходимо предпринять определённые действия, до того, как начнётся
оценка этих символов, и эти действия можно связать с обнаружением l-основы
(@ ffmpeg ...).

L-Основу легко сформировать. Она состоит из текущего бинарного оператора и
левого подвыражения. Оператор известен. А подвыражение формируется при
выталкивании терминалов (лексем) из стеках в строках (7:16) классического
алгоритма разбора.

4. Обработка ошибок.

Операторные грамматики хороши ещё и тем, что в них просто локализуются ошибки,
которые к тому же очень сложно допустить при написании текста (речь именно о
синтаксических ошибках; и то, что многие выражения синтаксически корректны,
может быть проблемой; но в случае LiME предполагается глубокий семантический
анализ).

Ситуация синтаксической ошибки при разборе операторного выражения возникает,
когда в потоке лексем встречаются две, которые не могут идти друг за другом,
или, говоря более формально, когда встречаются две несравнимые лексемы (символа)
A и B, для которых все три отношения: A <∙ B, A ∙> B, A =∙ B - не будут
выполняться. Например,

	a + b %|;

Приоритет «|» меньше «%», поэтому, можно было бы считать, что нужно начать
выталкивать из стека предшествующее «|» содержимое. Но это не верно, потому что
«%» и «|». И в этом месте нужно выдавать сообщение об ошибке.
Информацию о том, что сравнимо, а что нет, можно сохранить в матрице (если
влезет, можно в битовой).

На первом этапе разработки можно считать любую ошибку фатальной. В дальнейшем
разбор после ошибок можно восстанавливать достаточно просто (пропускать всё до
ближайшей «;» или корректной «)».

В этом есть одна тонкость. Символы «%» и «|» несравнимы только если «%» уже
записан в стек, а «|» следующий символ во входной цепочке. С формальной точки
зрения это означает, что в стек записываются несколько отличные символы от тех,
что берутся из входной цепочки. Это означает, что речь идёт уже о немного более
сложной грамматике, чем грамматика операторного предшествования (7.
Формализация).

			5.  Некоторые мелкие пояснения.

5.1. Может потребоваться пояснение, почему именно такие приоритеты выбраны для
«->» и «:». Предполагается, что основное место их применения - описание
логических выражений, необходимых в верификации кода. Нечто такое:

	Forall x Someptrset : x.inrange(0:N-2) && x & 1 == 0 ->
		Exists y Intptr :
			y.inrange(1:N-1) && (Exists x Someptrset : y == x - 1)

Другое возможное применение пары этих операторов - конструирование аналога
3-местному оператору «?:» из C. Например:

	fun ceilmax(a Num; b Num) =
		a > b && a < ceil -> a : (b < ceil -> b : ceil);

5.2. Операторы &&= и ||=. Они вполне осмысленны, и пришли в LiME из Ruby
(наверное, есть и в других языках). Используются они в нескольких частых
идиоматических ситуациях:

	- если надо установить значения по-умолчанию:

		x ||= y;

	- продвижение к следующему элементу:

		x &&= x.next;

5.3. Предлагается воспринимать «;», как бинарный оператор, сцепляющий два более
простых выражения в более сложное. Это делает грамматику проще, а семантику
точнее.

5.4. Два варианта оператора применения (apply) @ и @p (это относительно
стандартное обозначение для аппли(apply)-кации) выбраны, чтобы несколько
увеличить выразительность и ужесточить семантику. @p связывает обеспечивает
высокоприоритетную группировку некоторого выражения с тем выражением, что
оказывается в скобках.

То есть, когда записано

	var x array(string) array(20) int(4);

Понятно, что 20 связывается со вторым символом «array». Если бы @ был одного
приоритета, то выражение бы получилось таким (расставлены скобки):

	(((((var x) array) string) array) 20) ...

Что не корректно. Можно было бы предписать программисту расставлять скобки:

	var x (array string) (array 20) (int 4)

в стиле S-выражений. Но это менее читаемо, и менее модифицируемо, и более
громоздко, допустим, нужен двумерный массив. Можно сравнить:

	var x array(string) array(20;30) int(4)

	var x (array string) (array (20;30)) (int 4)

Ок. Отсюда вывод: хорошо иметь высокоприоритетный @, когда этот оператор
применяется к выражению в скобках. Этот приоритет можно было бы выразить в
грамматике, не вводя специальный оператор. Но со специальным оператором это
проще и он позволяет решить ещё одну задачу. Позволить ужесточать форму
выражений, когда надо. Если программисту нужно, чтобы условие для конструкции
for всегда было в скобках, то точнее будет, если он привяжет семантику этой
конструкции к оператору «@p», который связывает символ «for» и «выражение в ()».

В LiME возможно сохранить выражение для последующей обработки:

	exp fe = (i = 0; i < 20; i += 1)

у fe (пока без подробностей) будет тип «выражение в ()», и если бы «@» и «@p»
не различались, то у пользователя была бы возможность сконструировать такое
выражение:

	for fe

что может быть нежеланно (хотя, может и не быть - решать автору for). Для
уточнения синтаксиса выражений в таких случаях и вводятся различные
«@»-операторы. Такая техника может быть расширена и на другие случаи.
				     6.  IO

На вход синтаксический анализатор получает поток выражений, описывающих символы
(лексемы). В формате, описанном выше, в разделе IO для сканера. Напоминание: в
первых версиях компоненты системы предлагается разбить на несколько процессов,
чтобы изолировать домены ошибок и добиться между ними минимального
последовательного интерфейса.

Выдаёт он команды для семантического анализатора. Примерно они были указаны
выше, более точное описание ниже. Формат несколько сложнее формата лексем, но
тоже может быть без особого анализа прочитан при помощи нескольких вызовов
scanf. Всего должно быть несколько видов команд:

	- атом;
	- l-основа;
	- префиксный унарный оператор;
	- бинарный оператор (l-основа и правая часть);
	- открытие нового блока («(»);
	- закрытие текущего блока («)»).

Каждая такая команда вводит новое выражение сослаться на которое можно позже из
описания выражения:

	(L|U|E|B) «описание нового выражения»

«L» для обозначения l-основы, «U» - унарного оператора, «E» - выражения, «B» -
блока. Нумерация векторов, выражений и блоков может быть независимая. Но для
большей читаемости удобнее считать, что все команды семантическому анализатору
пронумерованы последовательно. Ссылка на предыдущую команду может быть дана
относительная, то есть:

	если K - номер текущей команды (явно не указанный), а N - ссылка, то это
	указание на N-K инструкцию.

Ссылка должна начинаться с соответствующей прописной буквы (для контроля
корректности). Такие обратные ссылки позволят немного сэкономить на кодировании,
потому что в большинстве случаев они будут короткими.

Описание некоторых выражений должно содержать описание лексемы. Описание этих
лексем может быть точно таким же, как на выходе сканера; то есть в виде
«E»-ссылки на существующую в таблице лексем, либо в виде «N»-введения новой
лексемы. Далее, это описание будет указываться как «lex».

«Невидимые» лексемы «@» и «@p» можно указывать на общих основаниях с
единственной особенностью в том, что для них нужно «выдумывать» координаты,
которые (достаточно естественно) можно считать равными координатам правой
лексемы.

Теперь команды по видам:

	- атомы
		E a lex

	- l-основа
		L e.ссылка lex

	- бинарный
		E l.ссылка e.ссылка

	- унарный оператор
		U lex			- введение оператора;
		E u.ссылка e.ссылка	- применение;

	- открытие нового блока
		B lex

	- закрытие :
		E b.ссылка e.ссылка lex

Синтаксический анализатор должен передавать в семантический анализатор и
информацию о текущем обрабатываемом файле при помощи копирования команды

	F «описание файла»

на выход.

Например, для

									     П.2

	./somesrc.lm

	var (x; y) int = (3*4)

должна получится последовательность:

	F 12."./somesrc.lm"

	E a		N.1 0.0 41 1.3."var"
	L e.1		N.2 0.4 38 "@p"

	B		N.3 0.0 39 "("
	E a		N.4 0.1 41 1.1."x"
	L e.1		N.5 0.1  0 ";"
	E a		N.6 0.2 41 1.1."y"
	E l.2 e.1
	E e.1 b.5	N.7 0.1 40 ")"

	E l.7 e.1

	L e.1		N.8 0.2 34 "@"
	E a		N.9 0.0 41 1.3."int"
	E l.2 e.1

	L e.1		N.10 0.4 1 "="

	B		E.3  0.2 "("
	E a		N.11 0.1 41 6.1."3"
	L e.1		N.12 0.1 29 "*"
	E a		N.13 0.1 41 6.1."4"
	E l.2 e.1
	E b.5 e.1	0.1 E.7 ")"

	E l.7 e.1

Несколько замечаний.

	- То, что все ссылки на выражения имеют вид e.1 (то же самое и в примере
	  П.1) не случайно.

	- Процесс разбора подобран так, что все лексемы, указываемые в командах,
	  выдаются в том же порядке, в котором и считываются с выхода
	  лексического анализатора. Это позволяет несколько сэкономить память,
	  время обработки и сложность системы на переупорядочивании. Также этим
	  обеспечивается дополнительный уровень проверки (сопоставить выход
	  сканера с потоком лексем на выходе парсера).

	- Выражения с унарными операторами составляются в два приёма, чтобы
	  и для выражений с унарными операторами выполнялись первые два
	  замечания.

Это обосновано в следующем разделе. Фактически, это позволяет избавиться от
ссылок на предыдущее выражение (так как, это всегда непосредственно предыдущее
выражение). Финальная alpha версия входного языка для семантического анализатора
LiME будет описана в конце следующего раздела.

				7.  Формализация

Понятно, что грамматика LiME должна иметь структуру, соответствующую описанным
выше командам и техническим особенностям. Сейчас её структура должна быть
понятной и очевидной.

В описании грамматики будут использованы соглашения:

	- X -> Y | Z | ... | W означает (традиционно) набор правил:

		X -> Y; X - Z; ...; X -> W;

	- запись A (B | C | ... | Y) Z означает:

		A B Z | A C Z | ... | A Y Z;

	- для символов вида X.«hex-число» (X.N1 : X.Nk) означает:

		(X.N1 | X.N2 | ... | X.Nk);

	- для символов вида X.y выражение X.{i; j; ...; k} означает:

		X.i, X.j, ..., X.k


Ок. Теперь сама грамматика. Начинаем с наивысшего приоритета
(символы-нетерминалы начинаются с заглавной буквы, терминалы (лексемы) в
кавычках):

	E.d	-> «atom»

	E.c	-> B E.0 «)»
	E.c	-> B «)»		// иногда выражение «()» нужно
	B	-> «(»

«.» и parentheses apply

	E.b	-> L.b.d (E.c : E.d)	// l-основа с точкой
	E.b	-> L.b.p (E.c)		// l-основа с «@p»
	L.b.d	-> (E.b : E.d) «.»
	L.b.p	-> (E.b : E.d) «@p»

унарные «^», «-», «!»

	E.a	-> U (E.a : E.d)
	U	-> «^» | «-» | «!»

@
	E.9	-> L.9 (E.a : E.d)
	L.9	-> (E.9 : E.c) «@»

умножение

	E.8	-> L.8 (E.9 : E.d)
	L.8	-> (E.8 : E.d) «*» | «/» | «%» | «<<» | «>>» | «&»

и так далее, всё однообразно в соответствии с таблицей T.1. Операторы
«присваивания» тоже задаются похожей структурой, которая левоассоциативна, во
многих случаях семантическому анализатору нужно знать информацию о левой части
выражения с присваиванием, чтобы верно оценить всё выражение. Например:

	var R matrix =
	(
		(0;	-12.4;	18.9;	11);
		(11;	-12.5;	6;	10);
		(x+y;	exp(x);	y;	0.1)
	)

здесь, обрабатывая правую часть присваивания, необходимо знать, что следует
формировать значение типа «matrix(N;M) type» (N, M, type система должна
вывести). Для этого движок должен сначала увидеть левую часть выражения.
Поэтому, фиксируем для «присваиваний». Традиционную же семантику исполнения этих
операторов справа-налево можно обеспечить средствами семантического анализатора
LiME.

	E.1	-> L.1 (E.2 : E.d)
	L.1	-> (E.1 : E.d) «=» | «*=» | прочие «=»-символы из Т.1 | «&&=»

Наконец, особый оператор

	E.0	-> L.0 (E.1 : E.d)
	L.0	-> (E:0 : E.d) «;»

и аксиома (символ «@» означает начало разбора и конец разбора, восстанавливается
по командам F от лексического анализатора).

	S	-> «$» (E.0 : E.d) «$»

Существует теорема (в любой книге по компиляторам должна быть, я использую
уральскую книгу А.П. Замятина и А.М. Шура «Языки, грамматики,
распознаватели») которая позволяет по грамматике попробовать построить отношения
<∙, =∙, ∙>. Если получится, то распознавать исходный текст можно АЛГОРИТМОМ:

0	for(stack.top != "@" || input(ip) != "@")
1	(

2		if(stack.top <∙=∙ input(ip))
3		(
4			stack.push(input(ip));
5			ip += 1
6		)

7		else if(stack.top ∙> input(ip))
8		(

9			val st = stack.top.pos;
10			var sp = st;
11			for(stack(sp-1) =∙ stack(sp)) (sp -= 1);

12			stack.replace(st:sp; leftof(stack(sp:st)))
13		)

14		else (error())
15	)

В отличии от Алгоритма АЛГОРИТМ определяет правило, по которому следует
редуцировать выражение и выдавать команду в семантический анализатор. В
АЛГОРИТМЕ это делается не по одному символу на вершине стека, а по правой части
некоторого правила, которая разыскивается в строках (9:11). После её обнаружения
нужно выдать соответствующую команду движку, а саму правую часть правила
заменить на символ из левой.

Ок. На этом спецификацию можно окончить, потому что остальное - технические
детали, но они важные, поэтому ещё немного усилий для анализа. Кроме того, не
помешает показать, что грамматика является грамматикой предшествования.

				   8.  Анализ

8.1. Грамматика без ε-правил (ничто не превращается в пустую строчку). Это
хорошо.

8.2. Для этого нужно построить для каждого символа в грамматике множества FIRST
и LAST, и по ним сделать выводы о <∙, =∙ и ∙>. Для нетерминала X

	- FIRST(X) = {символы, с которых начинаются цепочки, выводимые из X};
	- LAST(X) = {символы, на которые оканчиваются цепочки, выводимые из X}.

Вот описание этих множеств (плюс обозначает объединение):

	FIRST(E.d)	= {«atom»}
	LAST(E.d)	= {«atom»}

	FIRST(E.c)	= {B, «(»)}
	LAST(E.c)	= {«)»}

	FIRST(B)	= {«(»}
	LAST(B)		= {«(»}

	FIRST(E.b)	= {L.b.{d,p}, E.b, E.c, E.d} + FIRST(E.c) + FIRST(E.d)
	LAST(E.b)	= {E.c, E.d} + LAST(E.c) + LAST(E.d)

	FIRST(L.b.d)	= {E.b, ..., E.d} + FIRST(E.b) + FIRST(E.d)
	LAST(L.b.d)	= {«.»}

	FIRST(L.d.p)	= {E.b, ..., E.d} + FIRST(E.b) + ... + FIRST(E.d)
	LAST(L.d.p)	= {«@p»}

	FIRST(E.a)	= {U, «^», «-», «!»}
	LAST(E.a)	= {E.a, ..., E.d} + LAST(E.b) + ... + LAST(E.d)

	FIRST(U)	= {«^», «-», «!»}
	LAST(U)		= {«^», «-», «!»}

	FIRST(E.9)	= {L.9, E.9, ..., E.d} + FIRST(E.9) + ... + FIRST(E.d)
	LAST(E.9)	= {E.a, ..., E.d} + LAST(E.a) + ... + LAST(E.d)

	FIRST(L.9)	= {E.9, ..., E.d} + FIRST(E.9) + ... + FIRST(E.d)
	LAST(L.9)	= «@»

	FIRST(E.8)	= {L.8, E.8, ..., E.d} + FIRST(E.9) + ... + FIRST(E.d)
	LAST(E.8)	= {E.9, ..., E.d} + LAST(E.9) + ... + LAST(E.d)

	FIRST(L.8)	= {E.8, ..., E.d} + FIRST(E.8) + ... + FIRST(E.d)
	LAST(L.8)	= {«*», «/», «%», «<<», «>>», «&»}

И так дальше, по тому же принципу, что и для пары (E.8; L.8).  Далее, существует
определённое рассуждение, которое говорит, что зная FIRST и LAST отношения
предшествования можно строить так:

	- X =∙ Y только в том случае (if and only if - iff), если существует
	  правило вида W -> aXYb; в частности для рассматриваемой грамматики:

	  	- никакие два терминала (лексемы), не связаны отношением =∙;

		- нетерминал E.i (i != c) и терминал t, если приоритет t p(t)
		  меньше i связаны отношением =∙ - это следует из структуры
		  правил для L.i;

		- символы B, U и L.x не связаны отношением =∙.

	- X <∙ Y iff существует такой нетерминал Z, что X =∙ Z и Y в FIRST(Z); в
	  частности:

	  	- никакие два терминала не связаны отношением <∙, потому что нет
		  правил вида

		  	W -> a «терминал» Z b

		  и хотя кое-какие терминалы попадают в FIRST для кое-каких
		  нетерминалов, это не помогает;

		- никакие E.i и t (терминал) не состоят в отношении E.i <∙ t, по
		  аналогичной причине: правил вида

		  	W -> a E.i Z b

		  не существует.

	- X ∙> Y iff существуют такие Z1, Z2 такие, что Z1 =∙ Z2, X попадает в
	  LAST(Z1) и либо Z2 = Y, либо Y в FIRST(Z2).

Указанная грамматика вообще является грамматикой простого предшествования (что
хорошо, в смысле простоты и однозначности разбора), но это отдельное
доказательство, пока не нужное.

Из указанных частностей вытекают два упоминавшихся ранее свойства, которые
позволяют оптимизировать выходные команды.

	- Если в стек попадает терминал (лексема), то на следующем шаге разбора
	  он будет свёрнут с содержимым стека и информация о нём будет выдана в
	  семантический анализатор до того, как следующий терминал попадёт в
	  стек. Потому что, если терминалы ta и tb сравнимы, то только как
	  ta ∙> tb, и это поведёт АЛГОРИТМ по ветви (7:13).

	  Поэтому все лексемы на выходе синтаксического анализатора должны
	  появляться в том же порядке, что и на выходе лексического. Это
	  позволяет сохранять в них относительные координаты, а в более
	  оптимальных версиях транслятора LiME, вообще их не указывать явно, так
	  как семантический анализатор всегда будет знать, в какой момент
	  следует обращаться к следующей по порядку лексеме.

	- Если на вершине стека формируется E.i, то такой нетерминал будет при
	  анализе двух последующих терминалов t1, t2 на входе сканера, либо
	  свёрнут с t1 при переходе к t2, либо свёрнут с предыдущим содержимым
	  стека при просмотре t1. Это потому что, либо E.i =∙ t1, тогда E.i
	  будет свёрнут с t1 (7:13). Либо E.i ∙> t1, тогда E.i будет свёрнут с
	  содержимым стека. В других отношения E.i и t1 быть не могут.

	  Поэтому, если E.i появляется на вершине стека и соответствующая
	  команда выдаётся семантическому анализатору, то следующая команда
	  свёртки будет ссылаться на это предыдущее E.i.

	  Это позволяет убрать ссылки вида «e.номер» из входного языка
	  семантического анализатора. Это важно, потому что в часто
	  встречающихся ситуациях, движок LiME должен будет записывать
	  синтаксические деревья (в виде последовательности команд) для
	  последующего их воспроизведения. И чем экономнее будет их запись, тем
	  лучше.

	- Дополнительно, можно заметить, что символы B, U и L.x сворачиваются
	  всегда по одному (нет правил, содержащих их вместе). И в свёртке
	  всегда участвует символ, расположенный ближе всего к вершине стека.
	  Поэтому ссылки вида {b,u,l}.«номер» также не нужны в инструкциях,
	  воспринимаемых движком (ядром) LiME.

	  Если ввести понятие «последняя закрытая {B,U,L}-инструкция (команда)»,
	  то есть, инструкция, на которую уже встретилась ссылка в одной из
	  последующих E-команд (что соответствует свёртке соответствующего
	  символа (B, U или L.x) на вершине стека в подвыражение, то
	  {b,u,l}-ссылка всегда будет ссылаться на последнюю из открытых
	  {B,U,L}-команд. За открытием-закрытием (подобно скобкам) ядро может
	  следить при помощи стека, поэтому номера в самих инструкциях не нужны.

	  Все {B,U,L}-инструкции можно заталкивать в один стек при их открытии
	  (обнаружении в потоке команд), и выталкивать с вершины при закрытии,
	  когда встречается команда с {b,u,l}-ссылкой. Если всё корректно, то на
	  вершине этого стека должна быть информация об инструкции
	  соответствующего ссылке типа.

По этому всему, в интерфейсе между парсером и движком можно использовать такие
команды:

	- атомы
		E a lex

	- l-основа
		L lex			- подразумевается ссылка на e.1
	- бинарный
		E l			- подразумевается ссылка на e.1 и на
					  последнюю открытую L-инструкцию

	- унарный оператор
		U lex			- введение оператора;
		E u			- применение, подразумевается e.1 и
					  последняя открытая U-инструкция.

	- открытие нового блока
		B lex
	- закрытие :
		E b lex			- подразумевается e.1 и ссылка на
					  последнюю открытую B-инструкцию, то
					  есть, скобку.

Ух! Оптимизация средствами математики свершилась. Пример П.2 должен с этими
уточнениями переводится в такую последовательность инструкций:

	F 12."./somesrc.lm"

	E a		N.1 0.0 41 1.3."var"
	L		N.2 0.4 38 "@p"

	B		N.3 0.0 39 "("
	E a		N.4 0.1 41 1.1."x"
	L		N.5 0.1  0 ";"
	E a		N.6 0.2 41 1.1."y"
	E l
	E b		N.7 0.1 40 ")"

	E l

	L		N.8 0.2 34 "@"
	E a		N.9 0.0 41 1.3."int"
	E l

	L 		N.10 0.4 1 "="

	B		E.3  0.2 "("
	E a		N.11 0.1 41 6.1."3"
	L 		N.12 0.1 29 "*"
	E a		N.13 0.1 41 6.1."4"
	E l
	E b		0.1 E.7 ")"

	E l

Отсутствие номеров должно упростить структуру frontend-а для C99 и повысить
эффективность использования памяти: номера не избавляли бы от необходимости
запоминать команды.

					       СЕМАНТИЧЕСКИЙ АНАЛИЗАТОР (ДВИЖОК)
